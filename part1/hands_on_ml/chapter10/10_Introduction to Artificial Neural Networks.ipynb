{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텐서뽀개기 Part1  2017/07/25(화) 3회차 모임\n",
    "### Hands on Machine learning scikit_learn_and_Tensorflow\n",
    "\n",
    "- 스터디 : 캐글뽀개기 - 텐서뽀개기\n",
    "- 페이스북 : <https://www.facebook.com/groups/kagglebreak/>\n",
    "- github : <https://github.com/KaggleBreak/tensorbreak>\n",
    "- 구글드라이브 : \n",
    "<https://drive.google.com/drive/folders/0B2l0iH28o85xM3A3TVhGdkFHb3M>\n",
    "\n",
    "\n",
    "### 10장. Introduction to Artificial Neural Networks\n",
    "\n",
    "- 지적인 기계를 만드는 방법에 대한 영감을 얻기 위해 뇌의 구조를 보는 것은 논리적인 것 같습니다. \n",
    "- 인공 신경망(ANN)에 영감을 주었던 핵심 아이디어입니다. 그러나, 비행기가 새들로부터 영감을 받았지만, 날개를 펄럭일 필요가 없습니다. \n",
    "- 유사하게, ANN은 점차적으로 생물학적으로는 상당히 다른 것으로 되었습니다. 어떤 연구자들은 심지어 우리가 생물학적으로 유추 가능한 시스템으로 창의성을 제한하지 않도록 생물학적 유추를 완전히 삭제해야 한다고 주장합니다 (예: \"뉴런\"보다는 \"단위\"라고 말함)\n",
    "\n",
    "- ANN은 Deep Learning의 핵심입니다. 그들은 다양하고 강력하며 확장성이 뛰어나므로 수십억 개의 이미지 (예 : Google 이미지)를 분류하고, 음성 인식 서비스 (예 : Apple Siri)를 강화하고, 수천만 명의 사용자 (예 : YouTube)를 보거나 수백만 가지의 과거 게임을 검토한 다음 (DeepMind의 AlphaGo) Go의 게임에서 세계 챔피언을 물리 칠 수있는 방법을 배우십시오.\n",
    "- 이 장에서는 인공 신경망을 처음 ANN 아키텍처를 간략히 살펴본 다음 MLP (Multi-Layer Perceptron)를 제시하고 TensorFlow를 사용하여 MNIST 숫자 분류 문제를 해결합니다.\n",
    "\n",
    "### From biological to Artificial neurons\n",
    "\n",
    "-  신경 생리학자인 Warren McCulloch와 수학자 Walter Pitts에 의해 1943년에 처음으로 소개되었다. 그들의 획기적인 논문에서 그들은 생물학적 뉴런이 동물 두뇌에서 함께 작동하여 복잡한 계산을 수행하는 방법에 대한 단순화 된 계산 모델을 제시했습니다. 이것은 최초의 인공 신경망 구조였습니다. 그 이후로 많은 다른 아키텍처가 발명되었습니다.\n",
    "\n",
    "- 1960 년대까지 ANN의 초기 성공은 곧 우리가 진정으로 지적인 기계와 대화 할 것이라는 대폭적인 믿음을 이끌어 냈습니다. 약속이 실현되지 않을 것이라는 것이 명백해지자 (적어도 상당 기간 동안) 자금은 다른 곳으로 날아 갔고 ANN은 길게 어두운 시대로 들어갔다. \n",
    "\n",
    "- 1980 년대 초에는 새로운 네트워크 아키텍처가 발명되고 더 나은 교육 기술이 개발됨에 따라 ANN에 관심이 다시 생겨났습니다. 그러나 1990 년대에는 서포트 벡터 머신 (제 5 장 참조)과 같은 강력한 대체 기계 학습 기술이 더 나은 결과와 보다 강력한 이론적 기반을 제공하는 것처럼 보였으므로 대부분의 연구자가 선호했습니다. 마지막으로 ANN에 대한 또 다른 관심의 물결을 목격하고 있습니다. 이전 파도처럼 이 파도가 사라질까요? 이 점이 다르다는 것과 우리 삶에 훨씬 더 중대한 영향을 미칠 것이라고 믿을만한 몇 가지 이유가 있습니다.\n",
    "\n",
    "    1. 현재 신경 네트워크를 훈련시키는 데 사용할 수 있는 방대한 양의 데이터가 있으며 ANN은 매우 크고 복잡한 문제에 대해 다른 ML 기술을 자주 능가합니다.\n",
    "    2. 1990 년대 이후 컴퓨팅 파워가 엄청나게 증가한 덕분에 합리적인 시간에 대형 신경 네트워크를 학습 할 수 있었습니다.\n",
    "    3. 훈련 알고리즘이 개선되었습니다. 공평하기 때문에 그들은 1990 년대에 사용 된 것들과 약간 다릅니다 만, 이러한 비교적 작은 비틀기는 엄청난 긍정적 영향을 미칩니다.\n",
    "    4. ANN의 이론적 한계 중 일부는 실제로는 양성으로 판명되었습니다. 예를 들어, 많은 사람들은 ANN 교육 알고리즘이 지역 최적 조건에 머물러 있기 때문에 운명을 정해야 한다고 생각했으나 실제로는 거의 사용되지 않습니다 (또는 해당되는 경우 지역 최적화는 일반적으로 매우 유사합니다. 글로벌 최적).\n",
    "    5. ANN은 자금 조달과 진보의 선순환으로 들어간 것처럼 보입니다. ANN을 기반으로 한 놀라운 제품은 정기적으로 헤드 라인 뉴스를 만들어 더 많은 발전과 더 놀라운 제품을 탄생 시켰습니다.\n",
    "\n",
    "\n",
    "### Biological neurons\n",
    "- 우리가 인공 뉴런에 대해 논의하기 전에 생물학적 뉴런 (그림 10-13에 표시)을 간략하게 살펴 봅시다. \n",
    "\n",
    "- 동물의 대뇌 피질 (예 : 뇌)에서 주로 발견되는 비정상적인 세포로, 세포체 핵과 세포의 복잡한 성분의 대부분과 수상 돌기(dendrites)라고 불리는 많은 분지 확장과 축삭(axon)이라고 불리는 한 개의 매우 긴 확장을 포함하고있다. 축색 돌기의 길이는 세포체보다 몇 배나 길거나 수십만 배까지 길어질 수 있습니다. \n",
    "\n",
    "- 말단 근처에서 축삭 돌기는 텔로 덴드리아(telodendria)라고 불리는 많은 가지로 나뉘며,이 지점의 끝에는 다른 뉴런의 수상 돌기(또는 세포체에 직접 연결되어있는) 인 시냅스 터미널 (또는 시냅스)이라고하는 소규모 구조물이 있습니다. \n",
    "\n",
    "- 생물학적 뉴런은 이 시냅스를 통해 다른 뉴런의 신호라고 불리는 짧은 전기 충격을 받습니다. 뉴런이 수 밀리 초 이내에 다른 뉴런으로부터 충분한 수의 신호를 수신하면 자신의 신호를 발령합니다.\n",
    "\n",
    "- 수상 돌기(input, 신경세포에서 보내는 신호를 전달 받는 부분), 축삭 돌기(Output, 다른 신경세포에 신호를 전달하는 부분), 활동 전이, 시냅스들이 가중치, 뉴런들이 1천억개 존재하고 100조개의 연결이 존재한다고 합니다.\n",
    "\n",
    "<img src ='./img/10_1.png'>\n",
    "\n",
    "- 따라서 개별적인 생물학적 뉴런은 오히려 간단한 방식으로 행동하는 것처럼 보이지만, 수십억 개의 뉴런으로 연결된 각각의 뉴런이있는 수십억 개의 방대한 네트워크로 구성됩니다. \n",
    "\n",
    "- 고도로 복잡한 계산은 매우 단순한 뉴런의 방대한 네트워크에 의해 수행 될 수 있습니다. 복잡한 개미가 단순한 개미의 결합 된 노력에서 나타날 수있는 것처럼. 생물학적 신경망 (BNN4)의 구조는 여전히 활발히 연구되고 있지만, 뇌의 일부분이 매핑되어 있으며, 뉴런은 종종 연속적인 계층으로 구성되는 것처럼 보입니다.\n",
    "\n",
    "\n",
    "### Logical computations with neurons\n",
    "\n",
    "- 워렌 맥컬록 (Walren McCulloch)과 월터 피츠 (Walter Pitts)는 생물학적 뉴런의 아주 간단한 모델을 제안했다.\n",
    "\n",
    "- 이 모델은 인공 뉴런으로 알려졌으며 하나 이상의 바이너리 (on / off) 입력과 하나의 바이너리 출력이 있다. 인공 뉴런은 일정 수 이상의 입력이 활성화 되었을 때 출력을 활성화 합니다. McCulloch와 Pitts는 그러한 단순화된 모델을 사용하더라도 원하는 모든 논리적 명제를 계산하는 인공 뉴런 네트워크를 구축하는 것이 가능하다는 것을 보여주었습니다. \n",
    "\n",
    "- 예를 들어, 입력의 적어도 두 개가 활성화되었을 때 뉴런이 활성화되었다고 가정하고 다양한 논리 연산을 수행하는 몇 개의 인공 신경망을 구축해 봅시다 (그림 10-3 참조).\n",
    "\n",
    "<img src ='./img/10_2.png'>\n",
    "\n",
    "    - 왼쪽의 첫 번째 네트워크는 단순히 identity 기능입니다 : 뉴런 A가 활성화되면 뉴런 C도 활성화됩니다 (뉴런 A에서 두 개의 입력 신호를 받기 때문에). 그러나 뉴런 A가 오프이면 뉴런 C가 오프됩니다.\n",
    "\n",
    "    - 두 번째 네트워크는 논리 AND를 수행합니다. 신경 C는 뉴런 A와 B가 활성화 된 경우에만 활성화 됩니다 (단일 입력 신호로는 뉴런 C를 활성화 할 수 없습니다).\n",
    "\n",
    "    - 세 번째 네트워크는 논리 OR을 수행합니다. 즉, 뉴런 A 또는 뉴론 B 중 하나가 활성화되거나 활성화 된 경우 뉴런 C가 활성화됩니다.\n",
    "\n",
    "    - 마지막으로, 입력 연결이 뉴런의 활동 (생물학적 뉴런의 경우)을 억제 할 수 있다고 가정하면 네 번째 네트워크는 약간 더 복잡한 논리 명제를 계산합니다. 뉴런 C는 뉴런 A가 활성화 되어 있고 뉴런 B가 꺼져 있습니다. 뉴런 A가 항상 활성화되어 있으면 논리적 NOT을 얻습니다. 즉, 뉴런 B가 꺼져있을 때 뉴런 C가 활성화되고 반대의 경우도 마찬가지입니다.\n",
    "\n",
    "- 위의 네트워크가 결합되어 복잡한 논리 표현식을 계산하는 방법을 쉽게 상상할 수 있습니다 (이 장의 마지막 부분에있는 실습 참조).\n",
    "\n",
    "\n",
    "### The Perceptron\n",
    "\n",
    "- Perceptron은 F. Rosenblatt가 1957 년에 발명 한 가장 단순한 ANN 아키텍처 중 하나입니다. LTU (Linear Threshold Unit)라고 하는 약간 다른 인공 뉴런 (그림 10-4 참조)을 기반으로 합니다. \n",
    "\n",
    "- 입력 및 출력은 이제 숫자가 되고 (바이너리 온 / 오프 값 대신) 각 입력 연결은 가중치와 연결됩니다 . LTU (z = w1x1 + w2x2 + ⋯ + wnxn = wTx)의 가중치 합을 계산하면 그 합계에 단계 함수를 적용하여 결과를 출력합니다. step(wTx)\n",
    "\n",
    "<img src ='./img/10_3.png'>\n",
    "\n",
    "- 단일 선형 이진 분류에 단일 LTU를 사용할 수 있습니다. \n",
    "\n",
    "- 입력의 선형 조합을 계산하고 결과가 임계 값을 초과하면 양수 클래스를 출력하거나 그렇지 않은 경우 Logistic Regression 분류기 또는 선형과 같이 음수 클래스를 출력합니다 (SVM). \n",
    "\n",
    "- 예를 들어, 하나의 LTU를 사용하여 꽃잎의 길이와 너비를 기반으로 아이리스 꽃을 분류 할 수 있습니다 (이전 장에서했던 것처럼 추가 바이어스 기능 x0 = 1 추가). LTU를 훈련한다는 것은 w0, w1 및 w2에 대한 올바른 값을 찾는 것을 의미합니다 (훈련 알고리즘은 아래에서 설명합니다).\n",
    "\n",
    "- 퍼셉트론은 LTU의 단일 층으로 구성되며, 각 뉴런은 모든 입력에 연결됩니다. 이러한 연결은 종종 입력 뉴런이라고하는 특수 통과 뉴런을 사용하여 표현됩니다. 입력 된 모든 입력을 출력합니다. 또한 추가 바이어스 특성이 일반적으로 추가됩니다 (x0 = 1). 이 바이어스 특성은 일반적으로 항상 1을 출력하는 바이어스 뉴런이라는 특별한 유형의 뉴런을 사용하여 표현됩니다.\n",
    "\n",
    "- 그림 10-5에서는 2 개의 입력과 3 개의 출력을 갖는 퍼셉트론을 나타냅니다. \n",
    "\n",
    "<img src ='./img/10_4.png'>\n",
    "\n",
    "- 퍼셉트론은 어떻게 훈련 받았습니까? F. Rosenblatt가 제안한 Perceptron 교육 알고리즘은 Hebb의 규칙에 크게 영향을 받았습니다. 도널드 헤브 (Donald Hebb)는 1949년에 출판 된 그의 책 \"행동의 조직\"에서 생물학적 뉴런이 종종 다른 뉴런을 촉발시킬 때 이 두 뉴런 사이의 연결이 더욱 강하게 성장한다고 제안했다.\n",
    "\n",
    "- 이 아이디어는 S. Löwel의 캐치 프레이즈 (catching phrase)에 의해 나중에 요약되었다. 이 규칙은 나중에 Hebb의 규칙 (또는 Hebbian 학습)으로 알려지게되었습니다. 두 개의 뉴런 간의 연결 무게는 동일한 출력을 가질 때마다 증가합니다.\n",
    "\n",
    "- 퍼셉트론은 네트워크에서 발생한 오류를 고려한 이 규칙의 변형을 사용하여 교육을 받습니다. 잘못된 출력으로 이어지는 연결을 강화하지는 못합니다. 보다 구체적으로 말하면, 퍼셉트론은 한 번에 하나의 훈련 인스턴스를 공급 받고, 각 인스턴스에 대해 예측을합니다. 잘못된 예측을 산출 한 모든 출력 뉴런에 대해 올바른 예측에 기여한 입력으로부터 연결 가중치를 강화합니다. 규칙은 식 10-2와 같습니다.\n",
    "\n",
    "- Hebbian Learning [http://www.aistudy.com/neural/hebbian_learning.htm]\n",
    "\n",
    "<img src ='./img/10_5.png'>\n",
    "\n",
    "- 각 출력 뉴런의 결정 경계는 선형이므로 Perceptron은 복잡한 패턴을 학습할 수 없습니다 (Logistic Regression 분류기와 유사함). 그러나, 훈련 인스턴스가 선형으로 분리 가능한 경우, F. Rosenblatt는이 알고리즘이 솔루션으로 수렴된다는 것을 입증했습니다. 이를 퍼셉트론 수렴 정리 (Perceptron convergence theorem)라고합니다.\n",
    "\n",
    "- Scikit-Learn은 단일 LTU 네트워크를 구현하는 Perceptron 클래스를 제공합니다. 예를 들어 아이리스 (Iris) 데이터 세트 (예 : 4 장에서 소개)에서 예상대로 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To support both python 2 and python 3\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"ann\"\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True):\n",
    "    path = os.path.join(PROJECT_ROOT_DIR, \"img\", CHAPTER_ID, fig_id + \".png\")\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format='png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Perceptron(alpha=0.0001, class_weight=None, eta0=1.0, fit_intercept=True,\n",
       "      n_iter=5, n_jobs=1, penalty=None, random_state=42, shuffle=True,\n",
       "      verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### The Perceptron\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data[:, (2, 3)]  # petal length, petal width\n",
    "y = (iris.target == 0).astype(np.int)\n",
    "\n",
    "per_clf = Perceptron(random_state=42)\n",
    "per_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.4,  0.2],\n",
       "       [ 1.3,  0.2],\n",
       "       [ 1.5,  0.2],\n",
       "       [ 1.4,  0.2],\n",
       "       [ 1.7,  0.4],\n",
       "       [ 1.4,  0.3],\n",
       "       [ 1.5,  0.2],\n",
       "       [ 1.4,  0.2],\n",
       "       [ 1.5,  0.1],\n",
       "       [ 1.5,  0.2],\n",
       "       [ 1.6,  0.2],\n",
       "       [ 1.4,  0.1],\n",
       "       [ 1.1,  0.1],\n",
       "       [ 1.2,  0.2],\n",
       "       [ 1.5,  0.4],\n",
       "       [ 1.3,  0.4],\n",
       "       [ 1.4,  0.3],\n",
       "       [ 1.7,  0.3],\n",
       "       [ 1.5,  0.3],\n",
       "       [ 1.7,  0.2],\n",
       "       [ 1.5,  0.4],\n",
       "       [ 1. ,  0.2],\n",
       "       [ 1.7,  0.5],\n",
       "       [ 1.9,  0.2],\n",
       "       [ 1.6,  0.2],\n",
       "       [ 1.6,  0.4],\n",
       "       [ 1.5,  0.2],\n",
       "       [ 1.4,  0.2],\n",
       "       [ 1.6,  0.2],\n",
       "       [ 1.6,  0.2],\n",
       "       [ 1.5,  0.4],\n",
       "       [ 1.5,  0.1],\n",
       "       [ 1.4,  0.2],\n",
       "       [ 1.5,  0.1],\n",
       "       [ 1.2,  0.2],\n",
       "       [ 1.3,  0.2],\n",
       "       [ 1.5,  0.1],\n",
       "       [ 1.3,  0.2],\n",
       "       [ 1.5,  0.2],\n",
       "       [ 1.3,  0.3],\n",
       "       [ 1.3,  0.3],\n",
       "       [ 1.3,  0.2],\n",
       "       [ 1.6,  0.6],\n",
       "       [ 1.9,  0.4],\n",
       "       [ 1.4,  0.3],\n",
       "       [ 1.6,  0.2],\n",
       "       [ 1.4,  0.2],\n",
       "       [ 1.5,  0.2],\n",
       "       [ 1.4,  0.2],\n",
       "       [ 4.7,  1.4],\n",
       "       [ 4.5,  1.5],\n",
       "       [ 4.9,  1.5],\n",
       "       [ 4. ,  1.3],\n",
       "       [ 4.6,  1.5],\n",
       "       [ 4.5,  1.3],\n",
       "       [ 4.7,  1.6],\n",
       "       [ 3.3,  1. ],\n",
       "       [ 4.6,  1.3],\n",
       "       [ 3.9,  1.4],\n",
       "       [ 3.5,  1. ],\n",
       "       [ 4.2,  1.5],\n",
       "       [ 4. ,  1. ],\n",
       "       [ 4.7,  1.4],\n",
       "       [ 3.6,  1.3],\n",
       "       [ 4.4,  1.4],\n",
       "       [ 4.5,  1.5],\n",
       "       [ 4.1,  1. ],\n",
       "       [ 4.5,  1.5],\n",
       "       [ 3.9,  1.1],\n",
       "       [ 4.8,  1.8],\n",
       "       [ 4. ,  1.3],\n",
       "       [ 4.9,  1.5],\n",
       "       [ 4.7,  1.2],\n",
       "       [ 4.3,  1.3],\n",
       "       [ 4.4,  1.4],\n",
       "       [ 4.8,  1.4],\n",
       "       [ 5. ,  1.7],\n",
       "       [ 4.5,  1.5],\n",
       "       [ 3.5,  1. ],\n",
       "       [ 3.8,  1.1],\n",
       "       [ 3.7,  1. ],\n",
       "       [ 3.9,  1.2],\n",
       "       [ 5.1,  1.6],\n",
       "       [ 4.5,  1.5],\n",
       "       [ 4.5,  1.6],\n",
       "       [ 4.7,  1.5],\n",
       "       [ 4.4,  1.3],\n",
       "       [ 4.1,  1.3],\n",
       "       [ 4. ,  1.3],\n",
       "       [ 4.4,  1.2],\n",
       "       [ 4.6,  1.4],\n",
       "       [ 4. ,  1.2],\n",
       "       [ 3.3,  1. ],\n",
       "       [ 4.2,  1.3],\n",
       "       [ 4.2,  1.2],\n",
       "       [ 4.2,  1.3],\n",
       "       [ 4.3,  1.3],\n",
       "       [ 3. ,  1.1],\n",
       "       [ 4.1,  1.3]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[1:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = per_clf.predict([[2, 0.5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/numpy/ma/core.py:6385: MaskedArrayFutureWarning: In the future the default for ma.minimum.reduce will be axis=0, not the current None, to match np.minimum.reduce. Explicitly pass 0 or None to silence this warning.\n",
      "  return self.reduce(a)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/numpy/ma/core.py:6385: MaskedArrayFutureWarning: In the future the default for ma.maximum.reduce will be axis=0, not the current None, to match np.maximum.reduce. Explicitly pass 0 or None to silence this warning.\n",
      "  return self.reduce(a)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1oAAAGECAYAAAAvCVHoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQohi9v8BQIzCK+DegIgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10b63f080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = -per_clf.coef_[0][0] / per_clf.coef_[0][1]\n",
    "b = -per_clf.intercept_ / per_clf.coef_[0][1]\n",
    "\n",
    "axes = [0, 5, 0, 2]\n",
    "\n",
    "x0, x1 = np.meshgrid(\n",
    "        np.linspace(axes[0], axes[1], 500).reshape(-1, 1),\n",
    "        np.linspace(axes[2], axes[3], 200).reshape(-1, 1),\n",
    "    )\n",
    "X_new = np.c_[x0.ravel(), x1.ravel()]\n",
    "y_predict = per_clf.predict(X_new)\n",
    "zz = y_predict.reshape(x0.shape)\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(X[y==0, 0], X[y==0, 1], \"bs\", label=\"Not Iris-Setosa\")\n",
    "plt.plot(X[y==1, 0], X[y==1, 1], \"yo\", label=\"Iris-Setosa\")\n",
    "\n",
    "plt.plot([axes[0], axes[1]], [a * axes[0] + b, a * axes[1] + b], \"k-\", linewidth=3)\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "custom_cmap = ListedColormap(['#9898ff', '#fafab0'])\n",
    "\n",
    "plt.contourf(x0, x1, zz, cmap=custom_cmap, linewidth=5)\n",
    "plt.xlabel(\"Petal length\", fontsize=14)\n",
    "plt.ylabel(\"Petal width\", fontsize=14)\n",
    "plt.legend(loc=\"lower right\", fontsize=14)\n",
    "plt.axis(axes)\n",
    "\n",
    "#save_fig(\"perceptron_iris_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Perceptron 학습 알고리즘이 Stochastic Gradient Descent와 매우 유사하다는 것을 알고있을 것입니다. 실제로 Scikit-Learn의 Perceptron 클래스는 다음과 같은 하이퍼 매개 변수와 함께 SGDClassifier를 사용하는 것과 같습니다. loss = \"perceptron\", learning_rate = \"constant\", eta0 = 1 (학습 속도) 및 penalty = None (규정 없음) .\n",
    "\n",
    "- 로지스틱 회귀 분류기와 달리 퍼셉트론은 클래스 확률을 출력하지 않으며 단지 하드 임계 값을 기반으로 예측을 수행합니다. 이것은 Perceptrons에 대한 Logistic Regression을 선호하는 좋은 이유 중 하나입니다.\n",
    "\n",
    "- \"Perceptrons\"라는 제목의 1969 년 논문에서, M. Minsky와 S. Papert는 Perceptrons의 심각한 약점, 특히 사소한 문제 (예 : Exclusive OR (XOR) 분류)를 해결할 수 없다는 사실을 강조했다. 문제는 그림 10-6의 왼쪽을 참조하십시오). 물론 이것은 다른 선형 분류 모델 (Logistic Regression 분류기)에서도 마찬가지이지만 연구자들은 Perceptrons에서 더 많은 것을 기대했으며 실망감은 컸다. 결과적으로 많은 연구자들이 연결주의를 완전히 삭제했다. 신경 네트워크의 연구) 논리, 문제 해결 및 검색과 같은 높은 수준의 문제에 찬성합니다.\n",
    "\n",
    "- 그러나 여러 가지 퍼셉트론을 겹쳐서 퍼셉트론의 한계를 해결할 수 있습니다. 결과 ANN을 MLP (Multi-Layer Perceptron)라고합니다. 특히 MLP는 그림 10-6 오른쪽에 표시된 MLP의 출력을 입력의 각 조합에 대해 입력 (0, 0) 또는 (1)로 계산하여 확인할 수 있으므로 XOR 문제를 해결할 수 있습니다 , 1) 네트워크는 0을 출력하고, 입력 (0, 1) 또는 (1, 0)을 출력하면 1을 출력합니다.\n",
    "\n",
    "<img src ='./img/10_6.png'>\n",
    "\n",
    "### Multi-Layer Perceptron and Backpropagation\n",
    "\n",
    "- MLP는 하나의 (패스 스루) 입력 레이어, 숨겨진 레이어라고하는 하나 이상의 LTU 레이어 및 출력 레이어라고하는 LTU의 최종 레이어로 구성됩니다 (그림 10-7 참조). 출력 레이어를 제외한 모든 레이어는 바이어스 뉴런을 포함하며 다음 레이어에 완전히 연결됩니다. ANN에 두 개 이상의 숨겨진 레이어가있는 경우이를 DNN (Deep Neural Network)이라고합니다.\n",
    "\n",
    "<img src ='./img/10_7.png'>\n",
    "\n",
    "- 수년 동안 연구자들은 성공하지 못하고 MLP를 훈련시키는 방법을 찾는데 어려움을 겪었습니다. 그러나 1986 년 D. Rumelhart et al. backpropagation training algorithm을 도입한 획기적인 기사 7을 발표했습니다. 오늘 우리는 reverse-mode autodiff (Gradient Descent는 4 장에서 소개되었고 autodiff는 9 장에서 논의 됨)를 사용하여 Gradient Descent로 설명 할 것입니다.\n",
    "\n",
    "- 각 훈련 인스턴스에 대해 알고리즘은 네트워크에 피드를 제공하고 각 연속 레이어의 모든 뉴런 출력을 계산합니다 (예상을 만들 때와 마찬가지로 순방향 전달입니다). 그런 다음 네트워크의 출력 오류 (예 : 원하는 출력과 네트워크의 실제 출력 간의 차이)를 측정하고 마지막 숨겨진 계층의 각 뉴런이 각 출력 뉴런의 오류에 기여한 정도를 계산합니다. 그런 다음 이전에 숨겨진 계층의 각 뉴런에서 발생한 오류 기여도를 측정합니다.\n",
    "\n",
    "- 알고리즘이 입력 레이어에 도달 할 때까지 계속됩니다. 역 통과는 네트워크에서 오류 그라디언트를 역방향으로 전파함으로써 네트워크의 모든 연결 가중치에 대한 오류 그라데이션을 효율적으로 측정합니다 (따라서 알고리즘의 이름). 부록 D에서 역 모드 자동 디코딩 알고리즘을 체크 아웃하면, 역 전파의 순방향 및 역방향 패스가 단순히 역방향 모드 자동 확산을 수행한다는 것을 알 수 있습니다. 역 전파 알고리즘의 마지막 단계는 이전 측정 된 오류 기울기를 사용하여 네트워크의 모든 연결 가중치에 대한 그라데이션 하강 단계입니다.\n",
    "\n",
    "- 각 학습 인스턴스에 대해 역전파 알고리즘은 먼저 예측 (순방향 통과)을 수행하고 오류를 측정 한 다음 각 계층을 역순으로 통과하여 각 연결 (역 통과)에서 오류 기여도를 측정하고 최종적으로 오류를 줄이기 위해 연결 가중치를 약간 조정합니다 (그래디언트 하강 단계).\n",
    "\n",
    "- 이 알고리즘이 제대로 작동하려면 작성자는 MLP의 아키텍처를 크게 변경했습니다. 즉, 단계 함수를 σz = 1 / 1 + exp - z로 바꿉니다. 계단 함수에는 평면 세그먼트만 포함되어 있기 때문에 필수적이었습니다. 그래디언트 디센트가 고정되어있는 반면, 로지스틱 함수는 어디에서나 잘 정의 된 비제로 파생 값을 갖기 때문에 필수적이었습니다. 모든 단계. backpropagation 알고리즘은 물류 기능 대신 다른 활성화 함수와 함께 사용될 수 있습니다. 두 가지 다른 인기있는 정품 인증 기능은 다음과 같습니다.\n",
    "\n",
    "### Activation Function\n",
    "\n",
    "- 하이퍼 볼릭 탄젠트 함수는 logistic 함수처럼 \"S\"모양이며 연속적이고 차별화가 가능하지만 출력 값의 범위는 -1에서 1까지입니다 (예 : 로지스틱 함수) 각 레이어의 출력을 더 많거나 적게 정규화 (즉, 0을 중심으로)하는 경향이 있습니다. 이렇게 하면 수렴 속도가 빨라집니다.\n",
    "\n",
    "- ReLU 함수 (9 장에서 소개) : ReLU z = max (0, z) 그것은 연속적이지만 불행하게도 z = 0에서 구별 할 수 없습니다. 그러나 실제로는 매우 잘 작동하며 계산이 매우 빠르다는 이점이 있습니다. 또한 최대 출력 값이 없다는 사실은 그라디언트 디센트 (그라디언트 채도) 중 일부 문제를 줄이는 데 도움이됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logit(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def relu(z):\n",
    "    return np.maximum(0, z)\n",
    "\n",
    "def derivative(f, z, eps=0.000001):\n",
    "    return (f(z + eps) - f(z - eps))/(2 * eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA5YAAAF3CAYAAADejNRwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10ca302e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "z = np.linspace(-5, 5, 200)\n",
    "\n",
    "plt.figure(figsize=(11,4))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.plot(z, np.sign(z), \"r-\", linewidth=2, label=\"Step\")\n",
    "plt.plot(z, logit(z), \"g--\", linewidth=2, label=\"Logit\")\n",
    "plt.plot(z, np.tanh(z), \"b-\", linewidth=2, label=\"Tanh\")\n",
    "plt.plot(z, relu(z), \"m-.\", linewidth=2, label=\"ReLU\")\n",
    "plt.grid(True)\n",
    "plt.legend(loc=\"center right\", fontsize=14)\n",
    "plt.title(\"Activation functions\", fontsize=14)\n",
    "plt.axis([-5, 5, -1.2, 1.2])\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(z, derivative(np.sign, z), \"r-\", linewidth=2, label=\"Step\")\n",
    "plt.plot(0, 0, \"ro\", markersize=5)\n",
    "plt.plot(0, 0, \"rx\", markersize=10)\n",
    "plt.plot(z, derivative(logit, z), \"g--\", linewidth=2, label=\"Logit\")\n",
    "plt.plot(z, derivative(np.tanh, z), \"b-\", linewidth=2, label=\"Tanh\")\n",
    "plt.plot(z, derivative(relu, z), \"m-.\", linewidth=2, label=\"ReLU\")\n",
    "plt.grid(True)\n",
    "#plt.legend(loc=\"center right\", fontsize=14)\n",
    "plt.title(\"Derivatives\", fontsize=14)\n",
    "plt.axis([-5, 5, -0.2, 1.2])\n",
    "\n",
    "#save_fig(\"activation_functions_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def heaviside(z):\n",
    "    return (z >= 0).astype(z.dtype)\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1/(1+np.exp(-z))\n",
    "\n",
    "def mlp_xor(x1, x2, activation=heaviside):\n",
    "    return activation(-activation(x1 + x2 - 1.5) + activation(x1 + x2 - 0.5) - 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/numpy/ma/core.py:6385: MaskedArrayFutureWarning: In the future the default for ma.minimum.reduce will be axis=0, not the current None, to match np.minimum.reduce. Explicitly pass 0 or None to silence this warning.\n",
      "  return self.reduce(a)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/numpy/ma/core.py:6385: MaskedArrayFutureWarning: In the future the default for ma.maximum.reduce will be axis=0, not the current None, to match np.maximum.reduce. Explicitly pass 0 or None to silence this warning.\n",
      "  return self.reduce(a)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1YAAAF3CAYAAACmM9rRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAPYQAAD2EBqD+naQAAIABJREFUeJzsvXu8VVW5//8eugXECyWSt0TMyqyOFhw93o6lFaWe9uli\nCR6tsFPa0TQzsDBgJ4o/SLTyklYoZbG1vJBZFJaWX/SgCci2BDFzy0FRwQuoXLbg+P0x5mKvNfda\na6/LmHNc1vN+vfZr7z3WmHM+nzXXnGN95hjjGUprjSAIgiAIgiAIgtA427kOQBAEQRAEQRAEIXTE\nWAmCIAiCIAiCIDSJGCtBEARBEARBEIQmEWMlCIIgCIIgCILQJGKsBEEQBEEQBEEQmkSMlSAIgiAI\ngiAIQpOIsRIEQRAEQRAEQWgSMVaCIAiCIAiCIAhNIsZKEARBEARBEAShScRYRY5S6gtKqTeUUp9z\nHUsBpVS3UuqfruMoRik1Vim1SCm1Pnm/LncdU70kcd/tOo7+UErNTmId7jqWRmjm86uU+kCifXId\n2/xZKfVGI8cThFCRtqs2pO3yDx8/u/VSbzutlNovqX991rH5jhirnFFKXZ98+NYopXawsL/+Psw6\n+cmNGi7I3GOqhlLqcODnwC7ANUAH8HuXMZWjhi/YXr2vVQglzko0G3+924f+fgkRIG2Xm5iqIW2X\nt8SgJwYNTmhzHUAroZTaCfgM8AawG/AJ4FcZH/Y24H+B1Rkfp5j+Lsjj8gqkRk5Mfp+mtX7AaSTV\n6e99PQjYkFMsrUwzn98HMOdpraVYBCFzpO3ahrRdjdFqbZeLz65tvglcCjztOpDQkB6rfBkLDAau\nwNxkvmhhn6rai1rrV7TWK7TWr1g4Vq30F9OTWusn8wqmBvZJfod8EyQ5z6tcxxE7zXx+tdabkvP0\nou24BCFDpO1C2q6siK3tcvTZtYrW+rlEw1bXsQSH1lp+cvrBPMHYDAwD7gK2APtWqT8MmAksBzYC\nLyT7+Hry+ucxTxC3Jr/fKPr/mFSdzyX/7wi8Aqyoctwu4DVg5+T/vYDvJMd+DtgEPAlcDQxLbftk\nhZjuLqrTDfyzzHEHJ8dZVqT3TuDIMnU7kv0eA5wCLME88XoG+D4wqIbz8YFUjMXv33Bgv+T/6yts\nX6IrKftzsn1bEuOTyfv1GPCVKrF8AbgXeCl571cAPwTeWnSs9HtaElu5eJLyocD3gH8msTwH3Ay8\np0zd2cl+9gPOSc7FpuScTQaUhevghkRLXccA/hP4E/Bi8vl4BDgf2C5Vb1fgguRcPI255p4Gfgq8\nLVV3UqL3vyoc89PJ61OrfX6BgUksDwMvA68m5/5m4F/KfOYmlznW0cBfkm3XAjcBbwXuAbZWiO90\nYAGwLvnc/BUYZ+ueJT/yo7W0XUV1+lz7Sbm0Xa3Rdu0KXAT8PfksrgMeT469b1G9ks9uah+fAh5K\nzvmzwHXAm8p9too0jQC+kZyLDcnxT07q7ABckpyvjcBS4GMV4h8OzAJWYa7n/wN+QplruejYw1Pl\n22Ha18eT4z2O6d3av9pnrpV+ZChgTiilDgL+DbhTa71GKfUz4EPAOMyFmq5/IOYL1R6YL063AzsB\n7wUmApdjvsR9D/ha8vfcol10F/29rQtea71RKXUL8Dml1OFa64Wp4x6cHKNTa/1qUnwMcB7mS+1C\n4HXg/cBXgNFKqZG698nMFYmmg5PYXq4WT9FxByZ6DwUWJfvZAzgZ+KhSaozW+tbUPjTwVeCjwK+T\n+D6WlO0GnJY+TopuTAPyySTe7yfx6uT3m/vZvhwFbZ2JlnmYRuWzwNVKqR6t9axCZaWUAn6J+QK/\nCpgDrMfcSD+bbL8qiXMc5sbYQe+T1YerBaOU2h1zzvbHNJydyd8nAScqpUZrre9Pxa+ByzDn/U7M\nmP1PJMfdAWNGio/RncQ1Qmu9slo8Keo5xjTMzXsVcCumQTsG+C5wGOZzUuCgZD/3YIZkvAa8C/PU\n/YTk8/p/Sd0bk7qnAb8oE+OpmPfjZ0Vl5Ya0/AwzVGopcD2m0doXOBbzOXik4rtg9H0I+B3ms3IT\n5gn0h4D7MF9Yym3zi0TTiiT2HuAjwCyl1EFa6wnVjikItSBtl7RdSNtVYD7mvbkv0Vcwch/HtAH/\nV1S33GfldIyRWYcxLuuBEzAPK9ow9/BiCpquwLRzv8GckzHAL5RSL2E+MwclegdhzPrcpA3Y1ruq\nlHpHEvdQ4A7gUcz1cjrwH0qpo7XW/yhz7DQ/xpzPfwJXJcc8DziyTN3WxLWza5UfzNO7rcBnkv93\nwjzxeLJC/b8m9U8v89reRX/392Tq88l+PldUdlyyzVVl6l+W1P9YUdnuwOAydU9N9vOtVHmhR2J4\nhZiepO+TmcnJvn6aKj8E89TpBWCnovIpSf0XgbcXlQ/EPCXdAuxZ47kpG28N7225p373JOX3p+J9\nJ+am+Wiq/tlJ/T8AA1OvDQTelNp32Z6LKvFcn2ibmir/WFL/sTLvxRvAP4C3FJUPTd7rl4G2Mudz\nS6XzXeH9rvkYGLPwBvBbUk9zMRO2twKfLCrbpfh9Kyr/QBLndanye5Nzs0eq/M3JZ29htc8v5inm\nVuCBMsdUwK6pGEp6rJI6TySxHZHa/udJ/a2p8i8l5T8Bti8qb8N8UdsKvL+W8yE/8lPtB2m7il+X\ntqu3vKXaLowJeQO4pcxrOxR/zip8dodgjNR6ikZOYHqA/pjsO/3ZKmhaBuxWVH5o0WfoLxS1i/TO\nhfxeal93JzF9MVV+ZlL/rv4+W/S2X4tSx9wLeD6p3/I9VjLHKgeUUm2YG/l6zJMCtNavYZ7kDVdK\nfThV/1BgFPAXrXWfjEla62eaDOkezNCozyqlti86rsI8CVmDeTJTON5arXW5iaW/SDR9uMxr9fI5\nzM37W8WFWuulmCFcb8I8eUrzPV30lEVrvRnzZEth3kMXaOCbyTkuxLUC87TowGQieIH/wdzYv5LE\nTtE2m7XWL9MgSeauMZiG/ZLUvn+PeUr2dqXUUWXiv0hr/XxR/RcwX9h3AQ5M1T8OeDf1TXKt5xhn\nJ/XP0FpvSu3nm8nvsUX7eaXc+6a1/gtmCEX683ojxpCMTZWPAQZgzE1/WhSmlyp9TK21Xt/P9kdj\nnsT+Rmv9v6nXJmIaqzRnY4YMnqWLxsBrrbcAFybxpPUIQl1I21UT0na1VtuVboPQWr9e4XNWzH8C\nOwM/0Vr/s2jbN4BvV9lOAxfronm5Wuu/YnqMhgATU+3irZie2UMKBUqpfYEPYszxLEq5DmPoj1NK\n7UN1Pk/ve7ztmFrr1Zhe06pzFFsFMVb58AnMmPNfpm5AP8N8EE9P1T8s+X1XFsFo84jhF5gnOScU\nvfRhYG/MUIo3irdRSn1KKfUHpdTzSqnXk9SpWzFP6/duJh6l1C7A24B/VGh478G8T+9LSwEWl6lf\nmAT7pmbiapJ+40oaqXdhnvz+s0z9ZnkXppv+wTKGBMz7Cn3fV6jjfdVmQncjk1xrPca/YYbzfVEp\nNaX4B/g6Zpz3u4p3opT6oFJqrlLqGaVUT5JC+Q3gX+j7ef0lxhSlh9+cimmgbqomQpuhRL8DjkrW\nk/mWUuqI5EtpLRQawAVl9r2S0uElKKV2xDw9fRn4Zpn3pGCo3oUgNIe0XVWQtqul2q5lmDl8Y5VS\nf1FKnaeUen9i6mvhEMx5v6/Maw9gTGollpYpW13uteTz/zyln+3C+/SX9E6Sa+reVL1KHJz87tNW\nAf+vn21bBpljlQ9fxFxQN6bK78Y8KfmEUupNRU94hiT1s0xzeSMwAfPl8TdJ2WnJcUue0CulzsfM\nZXke0+2/CvNlFszY2oFNxrJr8vu5Cq+vTtUrplxvQOEGtX2Z13JB947xLyYd15Dkd1bnuZb3VeHu\nfa31GLsl/0+usq/BhT+UUp/BmKFXMJ/XbsyEX03vWP9taK3XKaXuBD6VjEtfppTaHzgCM6+kltTo\nJ2F6l04BLsa8r+uVUjdgnihurLJt4Xp/vsLrz2GG9hR4c7L/faj8nmiK3hNBaBBpu6ojbVc2eNd2\naa23KqWOxczX+jRm6KkC1iilrgIuSZv6FIVY+9zntdZaKVWtnamoqcr5Kl5rrpnPaTFDgDeSXsA0\nlfbdcoixypika/Ujyb/3Vni4oTGNxFXJ/y/T+8UpE7TWf1dKPYyZtLgL5kL8BGbc8qJCvWS4xbcx\nGYsOSV9QSqkLLIRTuGnsUeH1PVP18qJwk+xznSil+rsB1cK65HdW57mW91WT//taL+sxN/O31Fi/\nA/PlaWT6aapSqtLwuBsxjeWpmKF0n6P8F8qyJE9VJwOTlVL7YZJWnAmci3ny+pUqm6/DXO+V9KXP\nX+F8LdJaH5auLAg2kLarJqTtygYv2y6t9UuYe/q5SZKW4zDJI76DGQ46vcrmhVj73OeTXq/d6e1Z\ns42tz+k6YDul1NAy5qrSvlsOGQqYPadj3ucFmInm6Z/ZmIaoeF2QB5Pfo2vYf6ELu5EnMTdivvSd\nhMkutDN9v0jujnlK8b9lGqZDMSlwm4opGUr1T8yY6b3KVDkWcxOtmkUoAwrZ2Mo1HiOb3Xkyjv1R\nYH+l1AE1bLIVtt2Ea2E5Zjz4oUqpQWVePzb5nff7Wi8PAENrfI/ADM1ZVsZU7ZW8Vo7fYcbzn5K8\nv/+F6fG6o95gtdZPaa1nY8a0vwq097NJYSjHv6dfUEoNx2QXLN7/q5hhKQdZ+pIkCOWQtqsfpO1q\n3bZLa/2Y1vqH9H7Wa7nPKyA9LwzMcPcsOzoK79MxFV4/JlWvEhXbqir7bjnEWGXPF+hdz+DLZX5O\nx6yxcbBSaiSA1vohTAN1jFLqv9M7VEoVj519CXPj3jddrwbmJLGdlvy8Qd+U08+TPP1P5nYUYngz\ncGWF/RYmWdYT008xiQIuLS5UJoXu5zFPQueW2S4zki+wjwFHK6W2fSFPnpJOo/pK8rVyNeaGek26\nAVFKDUze5wJ1va9a69cxk6GHkZpYrZT6GKZBeFxrXW7Md80opd6mlDqweDK5ZX6AaZCuV0rtVub4\neyiliucTPYX5ojOsqM5AzNoqO6S3h21JH27GDBOcALwdk/2pT0KKMsffXSn1njIv7YYZalRujkAx\nCzDZqf5DKZVOWXsp5b/k/QCTne0nSqk+Q/6UUiOSnjNBaJQvIG1XLUjb1QJtl1Jqvwr31EJvT7Xh\n3mASaLyKmStcfE62B6bWGnMjaLO8yD3Ae5RJ+b4NpdQZmHTtf9Ja9ze0szC3cnJxu5P0bp+Dnc9V\n8MhQwAxRZm2a/YF7tNZPVal6A2Y+xxfpnXh5KuZCuE4pdRqmARsEvAczwXAYmCdHSqm/Yhqyn2EW\na3sD+JnuXaun/BgOrZ9TSv0Rc5N6A1igU2s5JGN/r8EkCViqlPoNZhzu8Zi5K+Um7N6NWczux0qp\nWzGJB57SWlfLrjYDOBE4TSn1bsy6Hntg1sPYHvhScaaiGrCVnWYm8CNgoVLqV5iHEcdjUgo3fQyt\n9Q+VUsdgdD6ulLoD0x2/H+a8nE5vr8ndmCe0tyml5mG+sC/VWt9Z5RAXYFKkfluZDEoP0LsWyKuY\nOUfNcjfJWiBAPetY1YTW+g9KqamYYT3/UEr9HmOehmIM0L9jhu8tTza5EmM8HlZm3Zs2eoc0LaV3\nAm6aGzGZri6izHyNKuwDLFFKLcVMbn46ie0/k2N/tx99Win1ZUw6+T8ppW7GXFfHYRrtLkzSjeJt\nrlNK/Rvmi9tRyXX8DOaaeRcmicApmPdJEOpC2i5pu/qjBduu92HifxDTW/cs5t7/CUyP3BWp+iXv\ncTKX9+uYLHyLlFI3YYbWnYB5P56hdwhnFnwFk2DiR0qpj9O7jtXHMfOj/qe/HWit/6LMvOEvAI8o\npW7HXNufxVznH88m9MDQHuR8j/UH8wRtK3BaP/V2wdzAX6BoPQhMA3Q5vStcr8GsMXFOavu3Yybx\nvoAZb55evb5kPYXUtqckr28htb5BUZ3tMWmtl2OSADyJaUwGJ38/UWab8+ntzt9K6er1lbbZETM/\npnj1+t+QWtsnqTulWGfqtaqay9S/gSprWWDmyhS0PImZS7N9cow/pereA2yp9ziYRuI+TMP0SnK8\nq4B9Uufh0iSGzaTWjCgXT1K+G+amX7x6/U3Au+uMsex7TmPrWNV1jOS14zBPfp9NdDyN6e35VvH7\nlNT9EsaQvJbUuw4zNKji+Um2W54c/6kqdUo+v5jhRpOSfRcmx/8fZsHGj6S2/UCy/0ll9ntUso9X\nMdd6J/DWfj5TJ2Em5a9N3pOVmC9251K07on8yE89P0jbJW1XjcehRdoujIm6JNG6OjnPT2Kyyh5a\n63kEPgU8lHweVwPXYrIVrgcW16Gp2vmq9DndFzOMd1VyHlZhFvzdt9b3E2MYJ9B7bT+e/P+2RPOs\nWj67Mf+o5I0SBEEQBEEQBCFHlFJvB1YAN2utZf3BwJE5VoIgCIIgCIKQIUqpNymlBqTKBmF65TRm\n4W0hcGSOlSAIgiAIgiBkyweAWUqp+Zhh27tjhrjvhxkK+UuXwQl2kKGAgiAIgiAIgpAhyZC/i4Aj\nSZK4AP/AzBubqbXucRWbYA8xVoIgCIIgCIIgCE0S9VBApdRQ4KOY1Kr9rSUjCIIg2GMQJo3xH3Rq\ngdZWR9omQRAEZ2TaNkVtrDANV3rRQEEQBCE//guzoKvQi7RNgiAIbsmkbYrdWHWDWTxhf7dxNM13\ngfGug7BAnjr2erCND736J7ZM3xn+8HgGR5Cz4hex6IA4tDyJWWLM3IeFErrBLCq0n9s4muYHwDmu\ngyjifR9tbLvzFsMVI+3Gkitf6P3zvO/CFYHcPv7yzsMrvjbrvMf44hUH5hhNKbfwaSv7WXbeDRx0\nRfPrGd+/+DgL0TTBVefB2ck6yNe5DWUbDz3SwEbdmGXnsmmbYjdWm8CYqoMcB9IsOxO+BshZx2Fb\neP38DzD59xOZesol0Nll+QByVvwiFh0QlxYZ6laGTWBMlbuvjXbYGb80bPwDHNXASkBDBsDI3ezH\nkxt3JL8vgCG7wMhAbh8jWcgdh4wu+9rgIW0cMHLXnCPq5QLu4lrOaHo/OwwZzJCRb2t6P8eP7AZg\n3r2fanpfDbHTEHhn8vRhJok3ccyxI+GeBxrdOpO2SdaxCoS1rgOwRN46umbCRd+YxqQ5F8LYgy3v\nXc6KX8SiA+LSIsSMj5Pn7us0P/Xw7MZsYsmd6fBsYLeP9qXzy5a/9OzmnCPpy5lcx5lNds9sfvYl\nS9EYjj/mNqv7q5kXny39v8NJFH059t9cR1CCGKtAeN51AJZwoSM7cyVnxS9i0QFxaRFixufv8PWY\nq6djMVbA0/90HUH9lDNXLzztT2d3M+Zq09MvWozE4MRcrXm6b1lH7lGUxyNzJcYqEN7tOgBLuNJR\nbK4GvDDC0l7lrPhFLDogLi1CzPg0DLActZqrUSEPA0wxajdguuso6qd96fwSg/X2UUMcRtOXRs3V\nkFEHWI7EkLu5OnBU+fIO/DBYnpgrMVaBcLzrACzhUkfXTDhJTWPNkGGWzJWcFb+IRQfEpUWImQ+7\nDqAGajFXY4dnH0debNMSoLmC3t6rY8bu6TiSvjRirvYae3QGkRhyNVcf6mfyYkcuUVTHA3MV9QLB\nSqmRwKKbiGgauGCFEVsGMGzdGnqGdrsORRAiZRkwBmCU1nqx42C8otA2zcL/Hp+YaCSpRRRc4DqA\nxqiU1MIHbCS1sImzhBbl6HAdQELFpBbLSdJoZtI2SY+V0JJ0t/VY7LkSBEEQfKfehBbREHjPlY80\nm9DCNs4SWpSjw3UACY56r8RYBcIk1wFYwicdBXM1Sd/cYFILn9Q0g+jwj5i0CDEzzXUAdVLJXI1b\nmG8cWVJWy3SCM1jjJsdhrrrGXZVxJIbjj7ktW4N1aR1rcXVkFkV9ODBXYqwC4UjXAVjCNx3dbT1N\nZAz0TU2jiA7/iEmLEDOHug6gAcqlYx/t33SehqmqJSBzNfoI89t3c9Wfwdp99CE5RWPIzFwdWufQ\nzI5MoqifnM2VzLESBODg82HyZVktJCwIrYjMsaqEzLHyB5l3FQ4+z7kCmXdVkQ7XASRsm3Mlc6wE\nIXOySccuCIIg+IzMuwqHdDp235B5VxXocB1AQk49V2KsBCHBfjp2QRAEwXfEXIWFmKva8cpcdTiO\nAXIxV2KsAiGWcTQh6Kg9Y2AIampBdPhHTFqEmFnqOgBLXBORuVqwpo7KHpurBUsqvxaSuXpxwTJH\nkRismauuBc3vo6P5XTTNv/5LprsXYxUIs10HYInZrgOokdrM1eycosma2a4DsMRs1wFYZLbrAASh\nJua4DsASc4in52pGvd/jPTVXM2ZXfz0Uc/XkjLkOIzFYMVedM5rfB/hhrjJEklcEwkZgR9dBWCA0\nHSO2DOCy7b9RIalFaGoqITr8IwYtkryiEjElr9gEDHIdhAWKdYSe0GLDFhjc1uDGHiW12LARBtdw\nG/Q5qcW1nMHWDZvZfvBA16Fso+GkFps2wKDB9gLpsLerunhlMTw0CiR5RWsT+lesAqHpqJ6OPTQ1\nlRAd/hGTFiFmYjBVUKoj9J6rhk0VeNV7VYupAv97rs4aPNt1GCU03Htl01RBtD1XYqwEoR+KMwY2\ntpCwIAiCEBLl1rpqGTwyV7Xis7kCSWpRkQ7XAdhHjJUg1ICYK0EQhNZDzFU4iLmqDzFX2SDGKhAu\ndx2AJULWUTBX624cmCS1CFlNMaLDP2LSIsTM1a4DsEQ1HaGZq/FVsunVhWNzNb6B26CPa13dMP6x\nbX8Hba5+OD67QDqIxmCJsQqEPV0HYInQdXTN7M0YuP2l73EdjiVCPysFYtEBcWkRYmYP1wFYoj8d\nIZmr4TtZ3JlDczV8r8a39clcDRteOlksWHP1luHZBgJRmCvJCigIDTJiywCGrVtDz9Bu16EIgodI\nVsBKxJQVsNUIPWNgw3iULbAefM8Y6BMNZwvMgo4M9y1ZAQXBT0rWupJ5V4IgCNETUs+VVQKccwV+\n9VylCbbnKg86XAfQOGKsBKEJutt62DxtiCS1EARBaBFa2lwFaLDEXNXO8cfc5o/B6nAdQGOIsQqE\nJ10HYIlYdECvlvAzBsZyVmLRAXFpEWLmKdcBWKJeHT6nY1++PuMD5GSullu8Dbo0V6uWv1b19TO5\nzkuD1YenlucfSEf+h2wWMVaBcIXrACwRiw4o1RK2uYrlrMSiA+LSIsTMNa4DsESjOnw0VxMezuEg\nOZirCd+zuz9X5mr2hBU11fPeXF07wU0gHW4O2yiSvCIQVgNNJMjxhlh0QHktB58Pky+byPQXLwgo\nqUUsZyUWHRCHFkleUYmYklc8Sxw5LJvV4VNSi5WvWc4MWI0Mk1qsXN1cZsBq5JnUYs3KjX0yA1bD\n26QWz62EPXLIDFiNDgv7kOQVAoT/FatALDqgvJaumXCSmtab1CIIYjkrseiAuLQIMRODqYLmdfjU\nc5WbqYJMe66yMlWQb+9VPaYKPO65cm2qIIjeKzFWgpABJRkDBUEQhOjxyVzlSoAJLUCSWtSDNwkt\nwHtzJcZKEDJCzJUgCEJrIeYqLMRc1Y6Yq9pocx2A0D+vA+Pa4IYtsIPrYJrkeuB010FYohYt3W09\nbD5/CJP1RKaecgl0duURWp3EclY81LHTGTBodf3bbVwHOw6pf7tNe8FrfjXGQry8DpzVBldH0Db9\nHDjV0r7u63Q752r6o3DBu10cOPltad7V9BvggnF29lWN9qXzM51zdev0J/n0Bfs3tO2ZXGd9ztWD\nn/wOG59fW/d2r696hcFv/SoAGzbsXPuGQ/aDizIwsB14abDEWAXArwfAml3h1+vhpB7X0TTHJtcB\nWKRWLV0z4SKmwRyYio/mKpaz4qGOQavhqw0kpL4HOPbl+re7Eqie2VcQrDFvALy4K8xbD+2Bt02b\nLe+v0HPlwmBt2Jr/MUuYjhVztWFj8/uolSzN1eYmT0ih58qWwdr4/Fo2jH6m/g3vgdePfaX+7ebW\nv0nNdOCduZKhgJ7zOvC73eCGG83v110H1CT/4zoAi9Sjxe907LGclVh0AMe6DkAQqvM6cFfSNt0V\nQdv0xYz262Jo4Hf+Jf9j9sHC0MDv5HxLz2pY4CnfebuV/TgfGuhru9ThOoBSxFh5zq8HwHGfgUGD\n4NiTzP9CmBSbK5l3JQhCyMwbAB9K2qYPnWT+F8oj867CoX3pfJl3FSIdrgPoRYyVxxR6q0a3m/9H\nt8fRa9XKhJmOXRAEoZdCb9VHi9qmGHqtskTMVViIuQqQDrwwWGKsPKbQW9XWBuvWwQ47hN9r9ZLr\nACzSjBa/MgbGclZi0YHMkxK8ptBbVdw2hd5r1cCMxrrJy1yttT1hrFkaNFdrHd/SbZmr9WvtT0B0\nYq5CaZc63B4+N2OllNpJKfUdpdQ8pdQLSqk3lFKfq2P7IUqpHymlnldKvaqUulsp9f4sY3ZJurdq\nxgzzO/ReqymuA7BIs1r8MVexnJVYdAC/dh1AayDtUv2ke6uK26aQe60uzek4eZir0x/I/hh104C5\nOr3DehR1Y8Nc/eD0v1uIpC+5m6uQ2qUOd4fOs8dqd2AS8C7gYUDXuqFSSgG/A8YAPwDGA8OAPyul\nDrAfqnuKe6sAPv958zv0XquvuA7AIja0FMzVJH2zw6QWsZyVWHQAH3QdQMsg7VKdFPdWQWnbFHKv\nVZ4LNWRtrjrem+3+G2Y6dRmsjjMzi6QumjVXYzuyux3kaq4+mN+hrNDh5rB5GqtngD211vsDEwBV\nx7afAY4APq+1vlhr/UNMfpKtwHesR+qYdG8VwDvf2ft3yL1WB7kOwCK2tHS39TjOGBjLWYlFB7C3\n6wBaBmmX6iDdWwV926ZQe60OzPl4WZqrkbtlt28r1GiuRnp0S2/GXB0wcleLkfTlTK7Lx2CF2C51\n5H/I3IyV1vp1rfXzDW7+aeBZrfXtRftbC/wS+E+lVOhrE5aQ7q1KE3qvldAXv9OxC0KcSLtUH+ne\nqjSh91rlzX2dktQiJHxOaAGS1KIiHfkeLpTkFe8HFpcpfxAYDLyzzGtBUq63qhwh91oJ5RFzJQhB\n0TLtEpQ/z0qcAAAgAElEQVTvrSpHyL1WrhBzFQ5irgKlI79DhWKs9gJWlykvlIXYQVmWSr1Vv/1t\n6f+h9lrd5joAi2ShpWCu1t04MMekFrGclVh0UP7ruuAbLdMuQeXeqnJtU4i9Vnc6Pr5NczXrCXv7\nypwq5mrW7ZVfc0m9a13dNWtVhtH0JTNz1WC7NHjwq3bjaJQOcjFYoRirHYFyCUQ3YcbE75hvONlQ\nrbfq8cf7loXYa7XcdQAWyUpL18y8MwbGclZi0UH5r+uCb7REuwTVe6sqtU2h9Vo95joA7JmrxaGt\nPFHBXC1elm8Y9VKruXpi8SsZR9KXTMxVE+3S8cd49ODzjGx3H4qx2ggMLFM+CJPFaWO+4WRDtblV\nX/ta37IQe60mug7AIllryc9cxXJWYtEBnOg6AKEGWqJdgupzqyq1TaH1Wp3vOoAEG+bq6n9tfh+5\nU8ZcXR3ALb0Wc3Xm1W6ycFg3V022S16ZqwwJxVitxgy7SFMoe6baxmcB56R+TgXuTtW7P3ktzTT6\nDjJaltRNPxi6Brg+VbY6qftkqnwOcHnyd6G36pjRcOGF8MgjpXX/9CeYXubG89dHYM7g0ieDLnUU\n2JjUTfccz8PkNk4zHr/ORwHXOgrmarvxc+CQeQErKRD6GSlQh44HgHTb24OR91Sq/BFgbpnQfpWE\nUsw/kn30wcX5uIbSO+wYzJ03appqlwC+AVyQ+vkycG+q3oPJa2lm0ncI22NJ3fSCt7OAn6fKnk3q\npj+GtwBXJ38Xeqs+0EDb9KtU2+RSR4FNSd2lqfK7MFdOmsnkfz7mpMzVlStg/JLSsg1boP1eWLCm\ntLyzG8Yt7BvbyffB3NSItPmrzT7SnPVQ3+GEi180ddOLD095BKY/Wlq28jVTd/n6OnUUfY4658G4\nyWV0TIC5qVv6/Puh/dwyOqb1HU64eJmpm158eMo1MP2GlI7Vpu7y1K3wyk4YX3QrbF86n80btnJx\n+xIeXVC643s7V/P9cX/rE9uMk5eycG5p3pwl89dycfuSPnWvPWtZn+GETyxez8XtS/osPjxnyj+4\ndXpvwGdyHRtXrmFR+6W8ujz1Aci5bfr7WT/mvY//T2nhisXwrXZ4eW1p+fVTYE7qxvLcSlP3qdTo\nlFuvhB+OLy3btMHUvb7D/C78/PcomHBCGSH2UFrXvGyHvYMqNQr4K/AFrfXPaqj/S+BorfXeqfIf\nAWOB3bTWfUYdKKVGAotuwv9EzLcMgE1nwAmfqn/b394KO/4ITrK/uLfgCQefD5Mvm8jUUy6Bzi7X\n4Qi1MrQdvppuoTLkyv3ghTvyO15VlmEMFqO01t7PGsurXUrqjAQWzSL/NN/1cscAeOMMOLHBtmm7\nH0G7tE0NcdRY1xE4pJxz9Zw7DhntOoSKXFs0/u0vR32VDaP7fe5jjcHz9+YD913Zp3zevQ3cVGyw\nYjF8aRRk1DZ512OllNpTKXWgUmr7ouJbgD2UUp8qqrc7cBJwR6XGKxRqzQRYiRDnWgn1IRkDBcEd\nrdguQe2ZACsR4lwrn5B07GHhc8bA3Na6qoNYhwbmaqyUUmcppS4EvpgUtSulLkx+dknK/j/Mo859\nija9BdNpeYNSapJS6ivAPcD2OFtb2R79rVsFZghGJUKaa1VuAFao5K0lO3MVy1mJRQcVhvgJWSDt\nUmX6W7cK+m+bQplr5XMHSb3mqtzwvhBpD3CuaTlzVW54nyuaMlcZtEsxmqu8e6y+AVyEycmhgU8m\n/18EvDmpo4E3ijfSWr8BHA/cDHwVmAE8D3xQa10mJ1E41Npb9YlPVH89lF6rMa4DsIgLLcXmyl5S\ni1jOSiw6gMNcB9BSSLtUhlp7q2ppm0Lotfq06wD6oR5zdfY7sosjT85+B8H2XBUbrBPP3tdhNH15\nU58ZfzWSUbsUm7nK1VhprffXWm9f4WdlUmec1rqt8H/Rtuu01l/WWr9Fa72L1vpDWmt/HgM0SC29\nVQCHHlr99VB6rY50HYBFXGnpmgknqWkWMwbGclZi0QG83XUArYO0S+WppbcKamubQui1CuFZRq3m\nanS5lCoBsk1HgOYKenuv3j96d8eRWCLDdikmc+XdHKtWotm5VWlC6bUS7JDvWleCILQKzc6tShNK\nr1UIyJyrsPB53pVvxGKuxFg5pNbeqloJpddKsEeJuZKkFoIgWKDW3qpaCaXXKhTEXIWFmKvaicFc\nibFyRL29VQsW1FbP916r9IpCIeOLlu62HjZPG9JEUgtflDRLLDrouy6IIOREvb1V9bRNPvdahZbv\noZq5Sq9XFSpldUwnOIM19+5IzFVO7dLxx9wWtMESY+WIenur/vSn2ur53muVXuI2ZHzS0lzGQJ+U\nNEMsOoC+60kKQi7U21tVT9vkc6/VH10H0ACV0rF35rh0XpZU1RGQuer8vfkdvLnKuV0K1VyJsXJA\nI3Orpkypva7PvVbfdR2ARXzT0ri58k1Jo8SiA/iM6wCEVqSRuVX1tk2+9lpd5DqAJkibq5uPchOH\nbfrVEYi5unlG799BmysH7VKI5kqMlQNsz61K43uvlZAd2aRjFwShFbA9tyqN771WISPzrsIhnY5d\nqE5o5kqMVc7YzgRYCZ97rYRssZ+OXRCE2LGdCbASPvdahY6Yq7AQc1U7IZkrMVY5k3VvVQHptRIk\nHbsgCLWSdW9VAem1yhYxV2Eh5qp2QjFXGd9ChTTLB8Gq2+B/b69vuxUvwjt3q2+brRreOgjoqW+7\nLJkETHUdhCVC0NLd1sOaLcMY9sIaeoZ2V6gVgpJa8FDHpr3gyga2e3Ut7NzAopKbIlkZVMidxwfB\nM7fB/XW2TY+/CO9ooG3a27O2aRow0XUQljixE3471nUUzTNuIdxweB0bTAcuyCqaxhk3GW6oMomv\nfel87jhkdG7xDHvLIKjDz73MmwDY/PhLDHzHm+s+3o5vsbdA8vHH3Ma8ez9lbX9ZIMYqZ769Hlhf\n/3bzgOM32I4mf450HYBFQtFSMFeX6W8w9ZRLoLMrVSMUJf3hoY7XroPXGtlwHmw+3nY0glCR8xts\nm+4CPhJB23So6wAsciim5+qowM3V6D0b2KjQc+WRwRp9RP918jRXF93+r3Vvcy1n8Ezn/2Pvsf+e\nQUT1Uei58tVgKa216xgyQyk1Elh0E3CQ62AEwTEHnw+TL5tYwVwJgm2WAWMARmmtFzsOxisKbdMs\n4EDXwQhRE7q5agqPzFWt5Nlz1QjXcobrEEpoyFytWAxfGgUZtU0yx0oQWoTm1roSBEEQQqPSWlct\nQYDzrnyfc3Um17kOoQQf512JsRKEFkLMlSAIQush5iocxFzVh2/mSoxVIMQyjiYWHRCuloK5Wnfj\nwCRjYKhK0sSiA+LSIsTMUtcBWCIWHVBZS2jmasEaSztybK4WLKl/Gx/Xunp0wUvb/hZzVRkxVoEw\n23UAlpjtOgCLzHYdQBN0zexNx64+9kvX4VhitusALDLbdQCCUBNzXAdgiVh0QHUtIZmrGcss7syh\nuZoxu/FtfTJXt83oLvlfzFV5JHlFIGwEdnQdhAVi0QHxaHnL+h3Y7/W1VdKxh0IsZwTi0CLJKyoR\nU/KKTcAg10FYIBYdUJuWEJJabNgCg23nrnaQ0GLDRhjc5O3ch6QWmzdsZeDg7fuUB5fQQpJXCBD+\nV6wCseiAeLQ8v+vrvQsJBz3vKpYzAnFpEWImFjMSiw6oTUsIPVfWTRU46blq1lSBHz1X5UwVSM9V\nGjFWgiDQ3dbD5mlDJKmFIAhCixCCucqE6Tifd9UIPpirSvhorlwZLDFWgiAAkjFQEASh1ZB07GHh\nu7ny0WDljRirQLjcdQCWiEUHxKOlWEfY5iqWMwJxaRFi5mrXAVgiFh3QmBYfzdX4BrLp1U0O5mq8\n5du5K3N1w/jHaqrX6uZKjFUg7Ok6AEvEogPi0ZLWUWyuTDr2UIjljEBcWoSY2cN1AJaIRQc0rsU3\nczV8p5wOlLG5Gr6X/X26SMc+bHjtk8Va2VxJVkBBECoyYssAhq1bE0HGQCF/JCtgJWLKCijERwgZ\nAzPBQcZAG/iQMbASXmYMlKyAgiC4orDWVVg9V4IgCEKj+NZzlRsBzrkC/+dd+UQePVdirARBqIqY\nK0EQhNZCzFVYiLmqnSNH3p3p/sVYBcKTrgOwRCw6IB4ttejYlo5d3+xxUotYzgjEpUWImadcB2CJ\nWHSAPS2uzdXy9Y4ObDkd+/KcbudZm6tVy19reFvfzFWWiLEKhCtcB2CJWHRAPFpq1eF/xsBYzgjE\npUWImWtcB2CJWHSAXS0u07FPeNjNcbdhyVxN+J6d/dRCluZq9oQVTW3vYzr2LBBjFQjfch2AJWLR\nAfFoqUeH3+YqljMCcWkRKvG+j7qOoHnOcx2AJWLRAdlocWGurhqV/zH7YMFcXfXN5vdRD1mZqzOu\nepeV/cRursRYBUIG2TqdEIsOiEdLvTr8TcceyxmBuLQI1Qg9A1ssCwPEogOy05K3ucot3Xp/NGmu\nski33h9ZpGOvJ916f8RsrsRYCYJQN10z4SQ1TZJaCIIFQjdXQuvget6VMySphXViNVdirARBaBjJ\nGCgIdhBzJYSCmKuwEHOVL2KsAuF61wFYIhYdEI+WZnX4Y65iOSMQlxahVkI0Vz93HYAlYtEB+WjJ\nw1xNfzT7Y9RNA+Zq+g32w6gXG+bq1unZpDeMzVzlZqyUUgOUUtOVUquUUhuUUguVUh+ucdsPK6Xu\nVkqtUUq9pJR6QCl1atYx+8Qm1wFYIhYdEI8WGzoK5sptOvZYzgjEpcVvfGubQjNXm10HYIlYdEB+\nWrI2Vxu2Zrv/hqkzHfuGjZlFUhfNmqvNGZ6QmMyV0lrncyClbgI+ickj/A/gC8BhwAe11vdX2a4d\nuB24H+gENPBZ4APAeVrr71fZdiSw6CbgIDsyBEGowsHnw+TLJjL1lEugs8t1OIJTlgFjAEZprRc7\nDqYiLtumRR+FkbuVr9Oyw62E4AjtYYBVLnAdQP3cccho1yFU5VrOyHT/6xb/k/tHjYeM2qZcjJVS\n6jBgIXC+1vqKpGwg8DfgOa310VW2/QPwbmB/rfWWpGx7YDnwqtb6/VW2FWMlCDkj5kow+G+sXLdN\n1YwViLkSwqJlDZaYK+tkaa6yNlZ5DQU8CdgC/LhQoLXeDMwCjlBK7VNl212BlwoNV7LtVmAt4EkH\nqyAIBfxe60oQSvC6bTpqbAt/WRWCo2UfBASY1MLnhBYQ9tDAvIzV+4AVWutXU+UPFr1eiT8D71FK\nXaSUOkAp9Tal1CRgFDDDfqh+8pLrACwRiw6IR0sWOgrmat2NA3NMahHLGYG4tHhNEG2Tz+bqZdcB\nWCIWHeBWi01ztTakiW9VzNVaT2/n9a51tX5tT4bR9CVUc5WXsdoLWF2mfDWggL2rbHsR8CvgQuBx\nzBj4CcCntdZzLcfpLVNcB2CJWHRAPFqy0tE1M++MgbGcEYhLi9cE0zb5aq4udR2AJWLRAe612DJX\npz9gZz+5UcFcnd6RaxR1U6u5+sHpf884kr6EaK7yMlY7Uj5Rzaai1yvRA6zANGBjgP8CHgJ+kYyP\nbwm+4joAS8SiA+LRkrWO/MxVLGcE4tLiNUG1TT6aq9NdB2CJWHSAH1psmKuO9za/j9wpY646zsw/\njHqpxVyN7Tggh0j6Epq5ystYbQQGlikfVPR6Ja4G/kNrPUZr/UutdSfwEcwTxYpZl4o5Czgn9XMq\ncHeq3v3Ja2mmAbelypYlddM9vNfQdwWa1Und9AoAc4DLU2Ubk7rp2XTdwKQysY1HdED+OuYl9dOI\nDkNaR8FcbTd+DhwyL2AlBbI8I5Pom27Hdx3XUHqHHYO583qP07bphD9D+72lP0fMh7mrSuvNX21e\ng1JzNRO4M7XPxzBz6dPDwWbRd32jZ5O6T6XKb0nEFbMpqbs0Vb4S84lLMxm4N1X2IOXn+YsOgw0d\ndwG3lonNhY45KXN15QoYv6S0bMMW89lesKa0vLPb1E9z8n3Vr49iznoIZj1RWrb4RVM3PcxwyiN9\n181a+Zqpu3x9nTqKzFXnPLiyjMk8eQLMTd3S598P7eeW0TENZt2e0rHM1E0PM5xyTd91s1auNnWX\np27pV3bC+KJbevvS+WzesJWL25fw6ILSHd/buZo7r1zZJ7YZJy9l4dznS8qWzF/Lxe1L+tS99qxl\n3DWr9OQ9sXg9F7cv6TPMcM6Uf5Ssm3Um17Fx5RoWtV/Kq8tL99F95e9YPv6nJWVbN2xmUfulrOi4\niUXtl277uW/UeB464eI+sdkkr6yA84G9tdbvTZUfB/wR+LjW+rdlttsBeA2YrrWelHrte5iWe7DW\n+vUKx5WsgILgEZIxsJUIIiug07apv6yA1WjZRAFCcPjY05obkjHQKjayBcaSFfBh4J1KqZ1T5Ydj\n1v54uMJ2Q4E2YPsyr+2AiT+3RY4FQWgOyRgoeEawbVNLf1kVguK+zhZ+ECAZA61yJtd5PzQwL1Ny\nC6YR+nKhQCk1ALMQ40Kt9dNJ2b5KqQOLtnse0/P8SaVUW9G2OwMfB5YlqXGjJz2wJ1Ri0QHxaMlb\nR3bmKpYzAnFp8Zqg2yYf0rGnh4yFSiw6wF8t9Zqr9DC+UJn15f7r+EY5c5UexucSn81VLsZKa/0g\nZoLvpUqp6UqpLwH3APthsigVuBEzfqSw3RvAZcA7gQeUUucqpc7HDA3eB8h2oKRHLHcdgCVi0QHx\naHGho9hc2UtqEcsZgbi0+EssbZNLc/WYu0NbJRYd4LeWeszVYk/TlNfL4pcItueq2GA9sfgVh9H0\nxVdzlcscK9j2FHAqJm/Em4Eu4Nta6z8W1bkH+HetdVtq2zHAuZhGbGCy7Yz+UtrKHCtB8J8RWwYw\nbN0aeoZ2uw5FsIr/c6zAbdvUzByrcrTscCshOFz3tDojwDlXENe8q6znWOVmrFwgxkoQwkDMVYyE\nYaxckJWxAjFXQjiIuQqLWMxVLMkrBEEQKpLvQsKCEC8t+2VVCI6WfQgQ4LBA8D+phS+IsRIEwQsK\n5mqSvlkyBgpCE4i5EkKhpc1VgAZLzFX/iLEKhHLLgIZILDogHi0+6ehu62kiY6BPSpolJi2CC/Iy\nV4GOaupDLDogPC2V0rGXW/Q3RKrqCMhcFRYv9t1cuTZYYqwCYYzrACwRiw6IR4tvOhpPx+6bkmaI\nSYvgijzSsX86293nRiw6IFwtaXN19jvcxGGbfnUEYq7OPrn3b5/NFbjtvRJjFQhHug7AErHogHi0\n+KijsXTsPipplJi0CK7J0lwdlt2ucyUWHRC2lmJzNXovd3HYpCYdAZir0almKZ2O3TdcmSsxVoIg\neEnXTDhJTZOkFoJgAZl3JYRCS8+7ChAxV6WIsRIEwWskY6Ag2EHMlRAKYq7CQsxVL2KsAuFu1wFY\nIhYdEI+WEHTUZq5CUFIrMWkRfMK2uYokv0A0OiAeLZdGYq7mrqpzA0/N1dx+miUxVwYxVoEwz3UA\nlohFB8SjJRQd/adjD0VJLcSkRfANm+bqj/Z25ZRYdEA8Wv5IHD1XnU81sJGH6dg7f99/HTFXoLTW\nuRzIBYXV7W8CDnIdjCAIVjj4fJh82USmnnIJdHa5DkeoyDKS7IaZrG4fMoW2adFHYeRu7uKI4Uur\n0Bq09DDW0PLnA3ccMtp1CBV5YvF6vj5qIWTUNkmPlSAIQdF4OnZBEIpp6S+rQlBUWuuqJfCs56oW\nfO65yhoxVoIgBIeYK0GwQx5rXQmCLcRchUOrmisxVoIgBEnBXK27caBkDBSEJhFzJYSCmKtw8H2t\nqywQYxUIk1wHYIlYdEA8WkLW0TWzN6nFdmNnuA7HIiGfFSFUGjFX0+yH4YRYdEA8WqrpCMlcjVto\ncWcOzdW4yY1v20rmSoxVIBzZf5UgiEUHxKMlBh3dbT38+MSbIuq5iuGsCCFSr7k6NJswcicWHRCP\nlv50hGKuRu9peYeOzNXoI5rbvlXMlRirQDjedQCWiEUHxKMlFh3/eurW3rWugp93FctZEUKkHnP1\nkezCyJVYdEA8WmrREYK5Gjsig506MFdjLTRLrWCuxFgJghAN3W09bJ42RJJaCEKTyJwrIRRCMFeZ\n4OFaV7UQu7lqCWO114NtrkMQBCEnJGOgINhBzJUQCpKOPSxiNlctYaw+9OqfGLFlAAef7zqSxoll\ndc1YdEA8WmLUEb65iuWsCKHTXzr2pfmFkimx6IB4tDSiw0dztWBNDgfJwVwtWGJ3f7Gaq5YwVluO\nW82Q0zYz+bKJwZqr2a4DsMRs1wFYZLbrACwx23UAlpid+r/YXIWX1GK26wAEoYRK5mpOvmFkRiw6\nIB4tjerwzVzNWJbTgTI2VzNm299njOnYldbadQyZoZQaCSyCm4CDYOzBTJpzIRd9YxpdM11HVx8b\ngR1dB2GBWHRAPFpaQceILQMYtm4NPUO7c4yoGWI4K8uAMQCjtNbSBVdEoW1a9FEYuZvraOoj/aV1\nEzDISSR2iUUHxKOlWR2+DGXdsAUG5zkj5YJsdrthIwzOsFm645DR2e28iCcWr+froxZCRm1TS/RY\nbaOzi6mnXBJkz1XoX7EKxKID4tHSCjoKa12F03MVy1kRYiP9ZTWGL/AQjw6IR0uzOnzpucrVVEFm\nPVdZmiqIZ2hgaxkrKDFXI7YMcB2NIAg5EZ65EgQ/8aUnQBD6wxdzlTsBJrSAOMxV6xkrMOZKncyw\ndWvEXAlCC7EtHbu+OdCkFoLgB2KuhFBoaXMVoMEK3Vy1prFK6BnaHYy5utx1AJaIRQfEo6XVdISR\nMTCWsyLEzFFj4WrXQVgiFh0QjxabOlymYx9vOZte3VgyV+NzbJZCNlctbawgHHO1p+sALBGLDohH\nSyvq8N9cxXJWhNg5YlQcvVd7uA7AIrFoyUKHC3M1fKf8j9kHC+Zq+F7N76MeQjVXrZUVsAoDXhjB\nBbtNDzJjoCAIjXHw+TD5solMf/GCgDIGhoJkBaxEyFkBq9GyQ66E4IjhYUBDZJQxMGtsZgyUrIA5\n0TO0O9iMgYIgNEbXTDhJTZOkFoJggZb9sioER8s+BAhwzhWE1XslxqqYgNOxC4LQOJIxUBDsIOZK\nCAUxV2ERirkSY5XG03TsT7oOwBKx6IB4tIgOg1/mKpazIsTO8vV9y0I0V0+5DsAisWjJQ0ce5qrc\nNeKcBszVcg+apRDMVW7GSik1QCk1XSm1Sim1QSm1UCn14Tq2P1kpdb9S6lWl1EtKqfuUUh/MJFgP\n07Ff4ToAS8SiA+LRIjp6KZgr9+nYYzkr/hNU2+QhEx4uXx6aubrGdQAWiUVLXjqyNleVrhHn1JmO\nfcL3MoukLnw3V3n2WP0M+Brwc+AcYAvwO6XUkf1tqJTqAOYAK4HzgAuBpcA+WQULfmUM/JbrACwR\niw6IR4voKKW7rceDjIGxnJUgCK5t8omrRlV+LSRzdZ7rACwSi5Y8dWRprqpdI15Qo7m66pvZhlEP\nPpurXLICKqUOAxYC52utr0jKBgJ/A57TWh9dZdvDgfuA87TWP6jzuDVnBazGgBdGsGbIMLrbehre\nhyAIYVHIGDj1lEugs8t1OAHif1ZA121TbFkBK9Gyc1mEIAnpgYBVAswY2Ei2wFiyAp6EeQr440KB\n1nozMAs4QilV7ene14DVhYZLKZX7igCFnqtbtCS1EIRWwf+1rgQLBN02hcJRY1v4y6oQHC37ICDA\npBY+9lzlZazeB6zQWr+aKn+w6PVKHAf8VSl1rlJqDfCKUuoZpdRZWQRaCUnHLgitR8FcrbtxoCdJ\nLQTLBN82hYSYKyEUxFyFQ/vS+V4ZrLyM1V7A6jLlqwEF7F1uI6XUm4DdgaOBi4BpwGeBJcCVSqkv\nZRJtJRymY78+38NlRiw6IB4toqM6XTNdZAyM5ax4Txxtk0OmP1pffV/N1c9dB2CRWLS41mHLXNV7\njTingrmafkO+YdSLL+YqL2O1I7C5TPmmotfLsXPyezfgi1rrK7TWtwD/ATwKfNtqlLXgyFxt6r9K\nEMSiA+LRIjpqI19zFctZ8R63bdMXao7TWzZsrX8bH81VuQ9BqMSixQcdNsxVI9eIc8qYqw0b8w+j\nXnwwV3kZq43AwDLlg4per7QdwOvArYVCbTJu3Ay8VSn11v4PfxYm2VPxz6nA3al69yevpZkG3Nb7\nb2cXUz/2abb7+/Hs8uwOJTWvoe+z5tXJXtNLAMwBLk+VbUzqpmfT7Q9MKhPZ+MZVAGZ6+TnAS6ly\n0WGopGMe5R9ziw5DrDoK5mq78XPgkHkZKZkE/E/GSgrYOiPXUHp/HYO573qP07bphLOh/Rlov7f3\n54j5MHdVab35q81rac56CGY9UVq2+EVTd23qW+mUR/o+OV/5mqmbXmfnyhUwfklp2YYtpu6CNaXl\n79oFxi3sG9vJ91XXUWyuZgJ3prZ/DDOX/uVU+Sz69mQ8m9RNr3t0C3B1qmxTUndpqnw45spJMxlI\nv/UPUn6evw867gKeKxOb6DA0omNOylzVc310dpvrLE1/10cxzq7zInPVOQ9WPltGxwSYm2qa5t8P\n7eeW0TENZt2e0rHM1F2bapqmXNO3h2zlalM3vZ7WlZ0wvqhpal86n80btnJx+xLmdPyDi9uXbPs5\nb9T/ctEJ2eZSyisr4Hxgb631e1PlxwF/BD6utf5tme0U8BrwktZ6n9RrZ2Ba8/dprR+pcFwrWQGr\nIRkDBaH1kIyBtRBEVkCnbdOiThhZaJoCnNtgg5adyyIEh489rbkRUcbAWLICPgy8Uym1c6r8cEAn\nr/chefr3MDBMKdWWernQmKWeD+SLT2tdCYKQD5IxMBr8aZsC/OJig5b+sioExX2dLfwgIMAHP66G\nBeZlrG4B2oAvFwqUUgMwI8wXaq2fTsr2VUodmNr2ZmB74PNF2w4C/gv4u9a6TOdkvhSbq6zmXaUH\n8IRKLDogHi2iozGyNVexnBXv8attCtBcpYciNYIP6djTQ8NCJhYtvuqo11zZuEZ8YO1FriOoHxfm\nKoevz8IAACAASURBVBdjpbV+EPgVcKlSanqSMekeYD9gQlHVGzHjR4q5DjMZ+Gql1Ayl1NmYIbb7\nAt/IPPga6RnazZDTNmeW1GKK/V06IRYdEI8W0dE4xebKblKLWM6K33jZNl1AUAbr9Afs7culubrU\n3aGtE4sWn3XUY65sXiMuOf0Bgu25ytNg5dVjBXAa8D1M1ojvY570nai1vq+ojgbeKN5Ia70JOBYz\nc3ocMAOzoOMJWmv36T+KyTBj4Ffs7s4ZseiAeLSIjubomgknqWmWMwbGclaCwM+2KRBz1fHe/uvU\ngytzdbqbw2ZCLFp811GrubJ9jbhim44AzRXk13uVS/IKV+SRvKIsYw9m0pwLuegb0+iamd9hBUFw\ny4gtAxi2bg09Q7tdh+IB/ievcEXZ5BWVCPRLTLO07FwWIThcD2N1RiAPf9JcsfXwKJJXtBZFPVeS\n1EIQWof8FxIWoifQLy/N0rJfVoXgaNmHAIE+9PnAijLrQ1hEjFVWdHYxVZ0sGQMFocUomKtJ+mbJ\nGCjYQcyVIHhNS5urQA1WVoixyhhb6djTy32GSiw6IB4tosM+3W09TWYM9EmN4AWemqv0wqW2yctc\npReSDZlYtISmo1I69qyvkbyoqkPM1TbEWOWADXO13GI8LolFB8SjRXRkQ3Pp2H1TI3iBh+ZqcQ4r\nA+SRjv2xbHefK7FoCVVH2lzlcY3kQb86xFwBkrwiVwa8MIILdpsuSS0EoYU4+HyYfNlEpr94QYsl\ntZDkFZWoK3lFOVr4C0zLDrkSgqNlh7J6+AComMXLYJQ5N5K8InR6hnZnlo5dEAQ/ySYdu9DSBLbW\nlU1a9suqEBwt+xCghR/8gBir/MlwrStBEPxFMgYK1hFzJQheI+aq9RBj5QJJxy4ILYmYK8E6Yq4E\nwWvEXLUWYqxcUWc69nNyCCkPYtEB8WgRHflSWzr2UNQIXuDQXLXf6+7YNs1VTP40Fi0x6YjBXDV0\nrbdgOnYxVo6pNWPgmJziyZpYdEA8WkRH/vSfjj0kNYIXOPoWevY73By3gC1z9Wk7u/GCWLTEpiN0\nc9XUtd5C5kqMlQfUYq6OzDGeLIlFB8SjRXS4oXo69tDUCF7gwFyN3iv/Y6axYa4Oa34X3hCLlhh1\nVFrrKgSavtZbxFyJsfKEgrm6RUtSC0FoFZpb60oQyhDL+Kk6yWOtK0GwRajmqmlawFyJsfIISccu\nCK1HwVytu3GgJLUQ7CDp2AXBe8RcxYkYK9+okI79bncRWSUWHRCPFtHhnq6Z6YyBIasRvCEHczV3\nVfbHqJdGzJXDHBzWiUVLK+gIyVxZvdYjNldirHykjLma5zYia8SiA+LRIjr8oWCutvtELF8pBOdk\nbK46n8p2/41Sr7n6YzZhOCEWLa2iIxRzZf1aj9RcKa216xgyQyk1ElgENwEHuQ6nfsYezICr1rNm\nyDC623pcRyMIQk6M2DKAYevW0HP2rtDZ5TqcBllGkt1wlNZ6seNgvKLQNi3qhJF5NU2Rfonpj1C+\ntApCyw5jzXnY8uJlMMq815m0TdJj5TOdXTWnYxcEIR6623rYPG2IJLUQ7CFzrgTBa1r2IUBka12J\nsQoAMVeC0HpIxkDBOmKuBMFrQk7H3jSRmCsxVoFQbK4kY6AgtAZirgTrtLC5EoMlhIKYq3ARYxUM\nk+gZ2s2Q0zYHnY59kusALBKLFtHhH8Vais2VpGMXrGAxHfu4hXb2kxeVzNW0fMPIlFi0tLoO38xV\nbtd64OZKjFUwHGl+VUjHHgpHug7AIrFoER3+kdbSNRNOUtOK0rELggUsmKvReza/j7wpZ64OzT+M\nzIhFi+jwy1zleq0HbK7EWAXD8b1/Bmyuju+/SjDEokV0+EclLaVrXQmCBZo0V2NHWIkid9Lm6iNu\nwsiEWLSIDoMv5ir3az1QcyXGKlSKzJUktRCE1kHMlWCdFp53JQgh4Iu5yp0AzZUYq5Dp7GKqOlky\nBgpCi7EtHbu+WZJaCHYQcyUIXtPS5ioggyXGKhgqr2EWUjr2mFYJjUWL6PCPWrRIxkDBOg2YqwVr\n7IeRN0eNhaWug7BILFpER19cpmN3fq0HYq7EWAXD7KqvhmKuZrsOwCKzXQdgidmuA7DEbNcBWGR2\njfXEXAnWqdNczViWTRh58/t94um9muM6AEuIjsq4MFdeXOsBmCsxVsHQ/6epYK5u0f4mtQjgmqiZ\nWLSIDv+oR4ukYxesU4e5uimSdJwFHTGYq++4DsASoqM6eZsrb651zxt7MVbBsGNNtXqGdnudMbA2\nFWEQixbR4R/1apF07IJ1alzranBb5pHkQrGO0M3VINcBWEJ09E+e5sqra91jcyXGKkYCTscuCELj\nSMZAwTqS1EIQvKalk1p4iBirWJF07ILQkoi5Eqwj5koQvEbMlT/kZqyUUgOUUtOVUquUUhuUUguV\nUh9uYD93KaXeUEr9IIs4/eXy+jfxMB17Ayq8JRYtosM/mtVSMFeSjr1/pG2qkQrmavySfMPIiko6\nQjRXV7sOwBKioz6yNlfeXuuepWPPs8fqZ8DXgJ8D5wBbgN8ppWqeDqeU+hRwOKAzidBr9mx4S58y\nBjauwj9i0SI6/MOGlu62HskYWBvSNtVKGXM1fKf8w8iCajpCM1d7uA7AEqKjfrI0V95f656YK6V1\n9u2AUuowYCFwvtb6iqRsIPA34Dmt9dE17GMgsAyYBUwFrtJan9PPNiOBRXATcFBzIiJgwAsjWDNk\nGN1tPa5DEQQhJw4+HyZfNpGpp1wCnV05HnkZMAZglNbay2XGXLdNly86nPO2X9ikCgd48gUmb1p2\nuJUQJKE9ELBGP0OXFy+DUea9yaRtyqvH6iTMU8AfFwq01psxDdERSql9atjHBYACLsskwhYghHTs\ngiDYRda6qorztumOQ0Y3splbWnjOVct+WRWCo2UfBDh+8JOXsXofsEJr/Wqq/MGi1yuilBqOuZVP\nSBo9oUF8T8cuCIJ9CuZq3Y0DJalFKV60TcGaqxY2WIIQAmKu8icvY7UXsLpM+WrMk769+9l+JrBY\na/0r24GFw5P2duUwHbtFFc6JRYvo8I8stHTNlIyBZfCmbQrSXAHLP+s6AjssX19ffZ/N1VOuA7CE\n6LCDLXNV7zXiHEfmKi9jtSNQ7mnepqLXy6KUOhb4JHBuBnEFxBV2d+fIXFlW4ZRYtIgO/8hSi5ir\nErxqm0I0VxO+RxQ9VxMern8bX83VNa4DsITosIcNc9XINeIcB+YqL2O1ERhYpnxQ0et9UEptB3wf\n+Jmvk5/z41v2d5mYq4ET1+WWMTADFc6IRYvo8I+stZSYq9aed+Vd2xSaubrqm8kfgZurq0Y1tp2P\n5uo81wFYQnTYpVlz1eg14pyczVVexmo1ZshFmkLZMxW2+wLwTuBHSqn9kp8RyWu7JP9XfKLYy1mY\nLLrFP6cCd6fq3Z+8lmYacFuqbFlS96VU+TXA9amy1Und9ACfOfRdsWZjUjfdVj8MTCoT23ia0tF5\nMz1D29n9n8tLzFVgKnI/G/Mo/xRKdBhERy/16phE35tlFjq623r45olDOO6Q41LmqhEl11B6fx2D\nue96j9O26aITFnNx+5KSn/FHLGTik+8rMVjz74f2Mv1iZ02DWbeXli1eZuquTX1op1wD028oLVu5\n2tRdnjrVV3bC+NSp3rDR1F2QWsvmvodh3OTknyJzdfJ9MHdVad35q6H93jI6HoJZT6R0vGjqrk31\nJ055BKY/mtLxmqmbHqp05Yq+a+9s2GLqLliT0rEGxpVJ0FiLjoK5mgncmdr+Mczb8nKqfBYmv38x\nzyZ100PHbqHvWkibkrpLU+V30ffeBDAZSL/1D1LeD4sOQ4w6is1VPddHZ7e59tL4fp13PGJ+t59o\nfkaNhRPO7hubTfJKtz4Ds07IbsWThJVSEzHpaYdrrZ8us90UzOdPpV7SSZkGPqm1vqPCcSXdeh1I\nOnZBaD2yS8ceRLp1p23T5YsO54CRu1aNsX3p/NoF+YKkYxcE7/GxtzUPFrfHkW79FqAN+HKhQCk1\nAPPUb2Gh4VJK7auUOrBou07MGPZPpH4U8Nvk7wdyiL8lKF5IWDIGCkJr0OLp2L1vm0IbGggEPyyw\nUSQduxASLfsgYHa2u8/FWGmtHwR+BVyqlJqulPoScA+wHzChqOqNmMeche1WaK3vSP8kLz+ptf6N\n1vq5PDS4p1xnsn16hnYz5LTNmSW1yEdFPsSiRXT4R95ais1VKyW1CKVt8tlcpYcXbiOwdOzpYUfN\n4NpcpYeChYroyJ56zJXNayRm8uqxAjgN+B5mctP3ge2BE7XW9xXV0cAbNexLJz8txKb+q9giw4yB\nOarInFi0iA7/cKGlayacpKa1YsbAINomX83VhrLpPYoIxFxt2Gp3fy7NVSyLfYqOfKjVXNm+RmIl\nlzlWrpA5Vk0y9mAmzbmQi74xja6ZroMRBCEvRmwZwLB1a+gZ2t3EXvyfY+WKeuZYpQlyzhXIvCtB\n8BzXPa15sfhFGPUHIPA5VkKIFPVc5ZWOXRAE90g6dn/xteeqXwLpubJNq3xZFcJHHgLYQYyVUJ3O\nLqaqk7cltRAEoTXobuth87QhrZrUwmvuOGR0mAZLzJUgeI2Yq+YRYxUM6ZV08qU4Y2AzuFVhl1i0\niA7/8EVLi2cM9B4fzFV6vax+8dRcpdfRsU2e5iq9tlGoiA433NdZ3mBlfY3EghirYJjiOgAr5sq9\nCnvEokV0+IdPWsRc+Y1rc3V6RwMbeWiuTs9h4Za80rFfmv0hckF0uCVtrvK4RmJAjFUwfMV1AECv\nubpFN5Yx0A8VdohFi+jwD9+0tGo69lBwaa46zmxwQ8/MVcd78ztW1ubq9Gx3nxuiwz3F5irPayRk\nxFgFgz9ZDXuGdjecjt0fFc0TixbR4R8+amnhdOxB4MpcjWzmw+rRWlcjd8v3eFmaqwP7rxIEosMP\nCuYq72skVMRYCY2R4VpXgiD4S0nGQMErXA8LbBhPzFXeSFILIRQkqUXtiLESGkfSsQtCSyLmyl/E\nXIWFmCshFMRc1YYYq2C4zXUA5akzHbunKhoiFi2iwz9C0FIwV5P0zZLUwjPyNFezbre4M4fmatYT\n7o5t21zdaXd3zhAdfnEnYq5qQYxVMCx3HUBVas0Y6LeK+ohFi+jwj1C0dLf1SMZAT8lrravFyyzv\n0JG5Wux4jQOb5uoxe7tyiujwi4IOMVfVUVpr1zFkhlJqJLAIbsLP6eDxMeCFEawZMozuth7XoQiC\nkBMHnw+TL5vI1FMugc6upHQZMAZglNZ6sbvo/KPQNl2+6HAOGLlr5sdrXzo/82NYZ7rrANwgX1qF\nkAhxKOviF2HUH4CM2ibpsRKs0mw6dkEQwkPWuvKbIOddtfCcqxC/rAqtiTwI6IsYK8E6zaRjFwQh\nTArmat2NAyWphYcEa65a2GAJQgiIuSpFjJWQDZKOXRBajq6ZvUkt2u7ey3U4QoogzRWIuRIEzxFz\n1YsYq2A4x3UA9VPGXAWooiKxaBEd/hG6lu62Hv6084dchyGUwba5aj/X6u4qk7G5ar832/03SiPm\nKhYfKjr8oj8dYq4MYqyCYYzrABojMVcDJ65jxJYBoaooSyxaRId/xKBl9WFbXIcgVMCmuTr7ZGu7\n6p8Mv6Ge/Y7s9t0s9ZqrT2cTRu6IDr+oRYeYKzFWAXGk6wAap7NrW1KLUyJaSDjgM1KC6PCPmLQI\nfmIrHfvovD+sGZmr0Z6PXK3HXB2WXRi5Ijr8olYdrW6uxFgJuVHrWleCIAhCPgQ57yqWsVV1InOu\nhFC4r7N1DZYYKyFXis2VJLUQBEFwj5ircJB07EJItKK5EmMVDHe7DsASd9MztJshp20OPmNgPGck\nDmLRAXFpEcKgUXM11+WH1WI69rmr7OwnL6qZK0/zcNSN6PCLRnW0mrkSYxUM81wHYIlERwTp2CM7\nI8ETiw6IS4sQDo2Yq87fZxBIvVgwV51PNb+PvKlkrv6YbxiZITr8ohkdrWSulNbadQyZoZQaCSyC\nm4CDXIcjlGPswUyacyEXfWMaXTNdByMIgi2WsS274Sit9WKnwXhGoW26fNHhHDByV9fh9KF96XzX\nITTGdNcBuKGVvrQKYePDMNbFL8KoPwAZtU3SYyW4pajnSpJaCIIguCfIOVfQ0vOuBCEEWuEhgBgr\nwT2dXUxVJ0vGQEEQWopbPF7hxlY69twRcyUIXhO7uRJjJXiDpGMXBKHVuJYzXIdQFTFX4SDmSgiF\nmNOxi7EKhkmuA7BEdR0hmavWOCPhEIsOiEuL0D8hm6txk3MMpB7qNFfjFmYTRt4cNRZ+sr/rKOww\nzXUAlhAdlYnRXImxCoa8l7fPiv51FMzVLdrvjIGtc0bCIBYdEJcWoTau5QyvDVYlczX6iJwDqYc6\nzNXoPbMLI29G7xlH79WhrgOwhOioTmzmSoxVMBzvOgBL1KajZ2i39+nYW+uM+E8sOiAuLUJ9hGau\nxvr+Ya1xrauxI7IOJD8KWkI3Vx9xHYAlREf/xGSuxFgJ/hLBWleCIAj1Epq5CgKZdyUIXhOLuRJj\nJfiNpGMXBKEFEXOVAWKuBMFrYjBXuRkrpdQApdR0pdQqpdQGpdRCpdSHa9juU0qpTqXUE0qp15RS\ny5VSlymlhuQRtz/Esr5mAzo8TcfewmfES2LRAXFp8R2f26YQzNWCJY4DqZcK5mrBmnzDyJJyWkI0\nV0tdB2AJ0VEfoZurPHusfgZ8Dfg5cA6wBfidUqq/edrXAQcBNwJfBeYBZwP3K6UGZheub8x2HYAl\nZje8pW8ZA2e7DsASs10HYInZrgOwyGzXAbQWXrdNvpurr982zHUY9VPGXM1Yln8YWVFJS2jmao7r\nACwhOuonZHOltNbZH0Spw4CFwPla6yuSsoHA34DntNZHV9n2GK31vamy04CfAv+ttb6+yrYjgUVw\nE6b9C5mNwI6ug7BA8zoGvDCCNUOG0d3WYyekBpEz4hex6IA4tCwDxpg/R2mtveyEc902HbnouwwZ\n+baaYj2T62qqlzebN2xl4ODtaV8633Uo9TO9988NW2Bwm7tQbNKfllC+tG4CBrkOwgKiozlsPxBY\n/CKM+gOQUduUV4/VSZingD8uFGitNwOzgCOUUvtU2jDdcCXcnvwO3S3VQehfswo0r8OXdOxyRvwi\nFh0QlxbPCaZt8jUd+8DB2wOBzrsq6rmKxVRB/1qOGhtG71UMZgRER7OE8iCgQF7G6n3ACq31q6ny\nB4ter4e9kt9rm4pKCJYQ0rELguA9wbVNPpqrAsGaK0lqIQheE5K5ystY7QWsLlO+GlDA3nXu7wLM\nU8ZbmoxLCBlJxy4IQnME2TaJucoAMVeC4DWhmKu8jNWOwOYy5ZuKXq8JpdQpwOnAZVrrJyzEFgiX\nuw7AEpZ1ODRXckb8IhYdEJcWzwm2bfLFXN0w/rE+ZSGaq/GXE425Gl9npkZfzdXVrgOwhOiwRwjm\nKi9jtREolyVpUNHr/aKU+nfgJ5jsS9+2E1oo7Ok6AEtkoCMxVwMnrss1Y6CcEb+IRQfEpcVzgm6b\nfDBXw4aX956hmavhhUGcEZir4TvVv42P5moP1wFYQnTYxXdzlZexWk3v2PNiCmXP9LcDpdQhwK+B\nLuAzWus3aj/8WZgsusU/pwJ3p+rdn7yWZhpwW6psWVL3pVT5NUA6GdTqpO6TqfI59H02vTGpm05U\n8mZgUpnYxiM6gM6b6Rnazu7/XF5irrJSMQ/zzllWkfvZEB29+KJjEnBKqtx3HddQencdg7nrBoDT\ntumhEy5mUfulJT/3H/FNnpv7QEm9NfMfZlH7pX22//tZP+bCWQeUlD2xeD0Xty9h/drSrKlzpvyD\nW6eXntU1KzdycfsSVi1/raT8zitX9umJ2rxhKxe3L+HRBaWfol1334Hvj/tbn9hmnLyUiU++r8Rg\nzb8f2s/tU5WzpsGs20vLFi8zddemPrRTroHpN5SWrVxt6i5PfWiv7Ex6oorYsNHUTa+/tfubYNzk\n5J8ic3XyfTB3VWnd+auhvUzqkrMeglmpvsrFL5q6a1P9olMegemPpnS8ZuouX5/SsaJvL9SGLaZu\nes2qzm5zzDS16CiYq5nAnantH8O8LS+nymdh1iko5tmk7lOp8lvo2+uxKambXiPpLmBFXxlMBtJv\n/YOU98OiwxCjjmJzVe366HjE/C78jPo9nPDnMsFZJK906zMw64TsVjxJWCk1EZgKDNdaP11l+wOA\nBZjvBUdrrcvcNspuF1G6daFWfEnHLgitTCDp1p22TfWkW+8PX9OxFwg9HXsr4XuPgCAUU29vayzp\n1m8B2oAvFwqUUgOALwALCw2XUmpfpdSBxRsqpfYA5mMmBH+s1oZLaF2KFxKWpBaCIFQhmrbJ13Ts\nBUIbGghEMSywEUJJxy4I4N+DgFyMldb6QeBXwKVKqelKqS8B9wD7AROKqt74/7d39/FylPXdxz8/\nhRAEjRKDhioguYV6V0UiRZQWlYf4Qm9PNaAhKhZjFbhBsBUShVIODzcYKlXAUgGDaC1B5CFQNQUK\naiQIUcKTkgAGQm5KKAnynEfC1T9mTtgzZ3fP7uw1c10z+32/XvtKMjsz+/ud2bNXfnvN/IaRZ/Rc\nD+xMMiv4l2b26YbHAcVHH4vsiTlVVU4eG8YvZ9xh6wttaqEjEpe65AH1yiVmdRybyi6usqcRthNz\ncZU9jXCzCrZjz55KmFfo4ip76lpVKY/ixVRclTVjBXAY8C2Si5vOBV4JfMQ5t7BhHQdkz09/R/rn\nTOAHmceJRQYcl2+GDsCTEvMouGOgjkhc6pIH1CuXCqjd2FRmcXXpzGZXXrQWa3E181ujrFCh4mrm\nXf72FbK4uiDcS3ulPMoRS3FVyjVWodTrGqtW11hXTYA8pr+Tky87idOOP5N7zvG3Wx2RuNQlD6hH\nLlW4xiqUIq6xaqaM665WrVjbsjNgO7Fdc7ViZUNnwHYqcN3VihfydQZsJ8R/Wh+nHh1SlUe5Rvsy\noC7XWEnPqv7frCEB8miYufLZjl1HJC51yQPqlYuEU8bMVZ6iCuKbueqoqIJKzFz5LqogzMxVFf4T\n3wnlUa7QM1cqrKQ/zL2H023a5qYWIiL9IPaGFrEVWB2pQHFVhNDXXIl0KmRxpcJK+kpjx0ARkX4Q\nc3EF8c1edUTFlUjUFs4NU2CpsKqM7G08qyp8Hr6Kq/CZ+KE84lOnXCQORRVX2ZsO5xW6uMredLgj\nkRZX2RsP+1ZWO/bsDWKrSnmEVXZxpcKqMtaFDsCTOPIYasd+pcvfMTCOTHqnPOJTp1wkHkXc62r9\nmk3e9hWyuFqzNueGERZXHg9JW0UXV+uL3X1plEd4ZRZX6goo/a2gjoEi/U5dAVsrqytgO2V0DMwr\nto6BHatAx8AihG4WINKpfaarK6BIsQq+15WISIxivu4q9GmBuUU4e1UGXXclVVHGlwAqrEQKascu\nIhIzFVcFUHElErW7ri92/yqsKuOp0AF4EmkeOdqxR5pJ15RHfOqUi8St1+Lq2dUbPEUyUpnF1Wqf\nv3SBi6vVgS6G8V1cPe13d8Eoj/6iwqoyTgkdgCdx59FNx8C4M+mc8ohPnXKR+PVSXJ034/ceIxmp\nrHtdzRj0vMOAxdWM28O9ts/i6ix/uwpKefQXFVaVcVToADyJP49Oi6v4M+mM8ohPnXKRashbXE0f\nnOQ5kuaKLq4Gjyxgp4GKq8G3h3ndIb6Kqxl+dhOc8ugvKqwqoy5dDauRx1Bx1a4dezUyGZ3yiE+d\ncpHWbl28X+gQhsnTjn3S5NcUFM1IRRZXk4v6pQtQXE3ervzXzPJxr6vd/IQSnPLoLyqsRFrYMH65\nOgaKSKHmL5jK/AVTQ4cxjJpaeDaL4NddhaKmFtJvVFiJtKN27CJSAhVXnatkcQUqrkT6gAqryrg6\ndACeVDCPFsVVBTNpSnnEp065SOeqWFzdOOfREiIZyXdxNecar7trrYTias6y4l+jW3mKq5/4DyMI\n5dFfVFhVxtLQAXhS0TzS4mqrE5/Z3NSiopmMoDziU6dcpDtVK66WLX6upEhG8llcLV7ibVejK7i4\nWhzp/Rq6La7uLyaM0imP/mLOudAxFMbMJgN3wOXocnDxZcyTO7Nq3ASWb1Hc/VtEqm4JcGjy13c7\n5xYHDSYym8emi++AXSc3XeegfeOatzySC0OH0NbA3TeEDqF7s0MHEMbCuaEjkH52P/D55K+FjE2a\nsRLpUjf3uhIRyaNqM1ehVfK6K11zJVI7KqxEcmgsrtTUQkSKEGNxFXOBpeKqOny0YxeJkQorkZw2\njF/OuMPWq2OgiBRG7di7U9niqo8LLJE6UWFVGceGDsCTuuQBcGwt2rHX5YjUJQ+oVy7iR6zF1RkD\ndwaOZKQ8xdXAcQUE0i1PxdXAAj/7KUur4qoutaby6C8qrCrj0NABeFKXPGBzLhUvrupyROqSB9Qr\nF/EnxuLqI8e8OXQYTXVbXB0zraBAuuXhf6/HvLX3fZStWXF1cPlhFEJ59BcVVpXxvtABeFKXPGBY\nLg3FVdWaWtTliNQlD6hXLuJXbMXV7VNOCh1CS90UV1Ni+qXrsbiaMtFPGGXLFld7hQnDO+XRX1RY\nifgy9x5Ot2nqGCgihYqtuIr9mqvKXnfVh3TNlVTdFqED6DvbHAFjV5b3eusmwgtx33+kbjaMX86E\nJ1ex6kXd60q6txGYvTXMWgtbhg5GojV/wVSv97pa9PFTWfvE6tzb/xJ4LU93vP6E7cdy2jV75n69\nbl23+5Tq3etqFn15r6t9puteV7HZCJy7NRyncWlUKqzKNnYlfOmR7rdbQr57HJ8PvJBju8LcDOwX\nOghPWudSpeKqLkekLnlcOwZ+Ox6ufQIOifutI4H5LK7WPrGaNVMe637DhrFpTTfbBahx2hVX826G\nj8X4AZKjuJr3KHzsTYVEU5p9pid5TPhV6Eh6twDYN3QQPZo/Bu4eD/OfgAGNS23pVMCq+F3oND3J\n8QAAHj5JREFUAHyZHzoAj9rnMnSvqytd3E0t6nJE6pDHRuBn28Gbd0n+3Bg6IIle8NMCKzY2tTot\ncO5/lBxIN7o8LXBuju9uYzT3kXqcGvifoQPo0UbgxnRculHj0qhUWFXFJ0IH4Ms/hg7Ao9Fz2TB+\nefQdA+tyROqQx7VjYL9PwKmnwgcPSf4tMpqg97qq4NjUrLj60dkBAulGF/e6+tE+hUZSmqE8ql5c\nnRY6gB7NHwP7p+PS/ock/5bWVFiJFK3i7dilHEOzVVMGkn9PGdCslXQn+OxVhVSyoQWoqYWUami2\n6kMN45JmrdpTYSVShgq3Y5dyDM1WbZFe+brllpq1ku6puOqciqtqUXFVvqHZqsZxSbNW7amwEimL\n2rFLC9nZqiGatZI8VFx1TsVVtai4Kk92tmqIZq3aK62wMrMxZjbbzB41szVmdpuZHdDhtjuY2RVm\n9pSZPWNm88zsLUXHHJV5oQPw5eTQAXiUL5ehphaxFFd1OSJVziM7WzU77QKmWavi1XVsKq24qsHY\ndN3uU9j/WzuEDqN7LYqrz91WbhhFaZVH1YqrM0MHkFN2tqpxXNKsVWtlzlj9APgy8EPgWOBF4Gdm\n1vZ+52a2DfAL4C+BM4B/APYAfmFmrysy4KhMCh2ALzHd3r5X+XOJqbiqyxGpah7NZqv2bLi9j2at\nClfbsamU4qomY9MeU8ZXc/aqSXE15Y3lh1GEdnlUqbj689AB5NBstio7LmnWqrlSCisz2wv4JPBV\n59xXnXPfBfYHHgFG68VzNMlH90ecc+c4584FpgA7AP3TCuAdoQPw5aDQAXjUWy6xtGOvyxGpah7Z\n2SqA/fd/+e+atSpOP4xNhRdXNRmb9p0+EajoqYGZ4mr6zkGi8G60PPaZXo0C68DQAeSQna2CkeOS\nZq2aK2vG6hCSbwEvHlrgnFsPzAHea2Z/0mbbg4HfOOcWN2x7P3ATyYAoUllVaMcuxWl1bVWWZq0K\n0xdjU9B27C08zWtDh9BSZYsrXXclHrS6tipLs1bNlVVYvQt4wDn3fGb5oobnRzAzA94J/LbJ04uA\nSenpGCLVpXbsfavZbFUzmrUqTF+NTbEVV9/hiNAhtFTJ4gpUXEnPms1WNaNZq+bKKqwmAiubLF8J\nGMmpE81sB2zVZlvabFsvNbmTOiwefZXK8JhLwOKqLkekanm0m626996RyzRrVYi+G5u8F1c9jk2x\nFFf33fLUiGVVLa5uqWbYI9yyqrv1Yy2u7g4dQBfazVa1Gpc0azVcWYXV1sD6JsvXNTzfajtyblsv\nC0MH4MuloQPw6FK/u0uLq61OfKbUphaXlvZKxbo0dABdajdbdfnlI5dp1qoQfTk2eS2uPIxNMRRX\nV5+9vOnyKhZXZ19KLWauzl7S/TYxFleXhQ6gC+1mq1qNS5q1Gq6swmotybd7WWMbnm+1HTm3bXA0\nSbOnxsdngJsz692aPpd1JnB1ZtmSdN3st1wXAJdklq1M1314+OLbgRsyq24g+S3Mfgv4Npq3tf1x\nGkqjP9DiN7mgPLgM+KfMsrXputl5hP1p3hj7BIIfj67ymA9s2yS2HvOY+yM2jB/g9Q8tHVZcVSyL\nuhyNwvJ4DjjPYIddhi+/6aakpe3JmV+RU0+FW24ZPmsVQx5Dx+MChn+6HkryqVsBYcemmR+Grw0M\nfxz1XvhV5sP+Nzckz2V982j46Zzhyx5YnKz79Orhyy85BS6bvfmf8xdMZe2KVdwxcBbPL310+Lol\nj02/P/piTpozvL3gssXPcsbAnTy7esOw5Zed8geumj383blqxVrOGLiTR5e+MGz5T85fwfdOuH/Y\nsvVrNnHGwJ0jZqjeO3V7zv3c70bEdva0uznx4XcNK7BuuBUGjhuZx9Fnwpxrhi9bvCRZd3Xml++U\nC2D294YvW7EyWXdp5pfv/LlwQuaXb83aZN1b7hy+fO58GDf0YdhQXE1bCPMyh/mGlTCwoEkev4U5\nyzJ5/DFZd3Xmq4RT7oXZ92XyeCFZd+mzmTwegBMy8a55MVk3Ozs1dzmM23JkbJ3kMVRcnQP8JLP9\n/SQ/lqczy+eQtAVt9Hi6bvYtfyXwz5ll69J1s7NTN9J8bPoHIPujX0TzerisPDYC178ObvnNyNmp\nm26CbZqc3HzqqbDN+OGzVqHzgJePxxxevvxwFjADOL5JbD6Zc67glwAzuwHYwTn39szy/YD/BD7q\nnPtpk+0MWAPMcc4dk3nuNOAkYFyT8+OH1pkM3AGXk3z6R2D8AHypxPP6zt8JnryuvNcTb8Y8uTOr\nxk1g+RYbRl9ZKuXKMbDuCPhwjomDn14FW18Eh0T+tlhCUmAB725s8BCT4GPTxXfArpP9JJPTQfsm\nZfgv9/kSa6Y8VtrrvuqGHXj/wvNHLD+SC0uLIY+Bu7MVZwXMHn2VOlo4N3QE1XLdGHjpCPhIznHp\nFRfBQOTjEiTF3OeTvxYyNpU1Y3UXsKuZZQv3vQGXPj+CS6q+e4E9mzz9HuChVgOXSNU13utKTS3q\no9NOgK3oWiuv+n5sirGhRQynBrZSxVMD63BaYB5Vacceg047Abaia61eVlZhdSWwBfDFoQVmNgY4\nHLjNOfdf6bI3m9luTbb98/QbvqFtdwP2A64oOG6RoDaMX864w9arY2CNdNoJsBVda+VV2LEpksmZ\n+QumsmZNsxOWwlFx5ZnasUsbnXYCbEXXWr2slMLKObeI5Izrs8xstpl9Afg5sBMws2HVf2XkWdkX\nAA8BPzOz483syyRnf69k5Cn/9VXBsw+aq9MhKymXgjsG1uWIVCGPTmervvOd9s9r1sqPKMamwdzh\nx6HAsanM4ip7LdZoYi6ustdjDVOh4ip7PVYvQhZX2et/YtPpbFUn45JmrcqbsQI4DPgWSdeIc4FX\nktyxvrGnkANeatwoPZ3i/cAvSc5bPxW4E/iAc+7JEuKOw7jQAfjyxtABeFRiLgUWV3U5IlXIo9PZ\nqu23b/+8Zq28Cj82DeaMPAYFj01lFVcTduy+iWOsxdWOE0dZoSLF1Y6e7wQXqrh6Q5iX7Vins1Wd\njEuatSqpeUUoal6BmlfUzfR3cvJlJ3H8pm+oqUXFbASOeCN8/V/zn24xbH8b4WufhQsfhybNs4Kr\nQvOKUDaPTXveAa9uaF4xGCoi4Ljd4GMPlPZyrZpXtBJzU4tKNrQANbUQNgJ/90Y42+O4NOuz8E+R\njktQn+YVIuLD3Hs43aZtbmoh1dHrtVVZmrWqoUGqPXtVoNivuYp19qqtisxc+aZrrl7W67VVWZq1\nUmElUkmNHQMlfr12AmxF11rV1GDoAOIUc3EF8Z4a2JaKq77VayfAVvr9WisVVlWxavRVqiF729Eq\nC5uLr+KqLkck5jy6na1asaKz9TRrVWODoQPoUMljU1HFVfbmwnnFUFxlbzA8qkiLq+wNhn0rqx17\niRd/dKXb2apuxqV+nrVSYVUVN4YOwJdvhg7Ao/C5DLVjv9Llb2oRPgs/Ys0jz2zVhV1cTqJZqxob\nDB1ABwKMTUXc6+rSmf6uLwtdXM38Vo6NIiyuZja9i5x/RRdXFxS7+1zyzFZ1Oy7166yVCquq+HDo\nAHz5WugAPIoklx47BkaSRc9izSPPtVXHHtv5upq1qrnB0AGMIuDY5LO4OuLbf+ptXxC2uPr2V3Nu\nGNm9rr797vJeq8ji6m+L23Vuea6t6nZc6tdZKxVWVfHa0AH4Mlof2CqJKJceiquIsuhJjHnkvbbq\nDV3259WsVc0Nhg6gjcBjk6/iKk+79dGEKq5Gbbc+mkiKK9/t1kdTVHEV261A8l5blWdc6sdZKxVW\nInXRUFypqUUcfHcCbEWzVn1gMHQA8Yq5qUXo0wJzi6S4Kls/NLXw3QmwlX6dtSr4xyojrJsInd+6\nw8/rSf+Yew+nz53G7CdnserFCbrXVWBLx8KjV8Ovryn+tTY5eNNYQIe8vgYzf/o0bieY190mr3rV\n87lfbuvtX59722a+wxHR3uvqut2nVPNeV7Poy3td7TO93ve6enAsPHY13FrSuLRDn41LukFwZVwC\nzAgdhAd1yQNiz2XMkzuzatzoxVXcWXSuLnlAPXLRDYJba3mD4G4M+owov11/fRiTZn08dBib5S2u\nrpr9MAfPeovnaEYqo8Ca/T2Y9TmfO/S4r25e9j6Y9b/DvDb4K65+CHzGz66CqkseukGwpNaFDsCT\nuuQBsefSaTv2uLPoXF3ygHrlIgUZDB1A4oElu4QOYZi8pwWuX7PJcyTNlXFq4Jq1nncY6LTAkg5J\nS75OC1zvZzfB1SWPomnGSqTmxjy5M7O2m81px5/JPeeEjkb6hWasWvMyYzVk0EdEvTto36tDhzBC\nrKcGQjkzV9714WmBQ+p8amC/0YyViPRkw/jlPbVjF5GIDYYOIDF/wVTmL5gaOoxh1NTCs8jasZep\nH5paiB8qrET6QY/3uhKRiA2GDuBlKq46V8niClRcibShwqoyngodgCd1yQMql0uL4qpiWbRUlzyg\nXrlISQYDve7Tq0csqmJx9ezqMG3LiiiuVpfxAVJCcbU6wot68hRXT/sPI4i65FE0FVaVcUroADyp\nSx5QyVzS4mqrE5/Z3NSiglk0VZc8oF65SIkGA7zm7Ob9K6tWXJ034/clRTKS7+JqxqDX3bVWcHE1\n4/Zi959Xt8XVWcWEUbq65FE0FVaVcVToADypSx5Q2Vzm3jOsY2BFsxihLnlAvXKRkg1SboH1udYv\nVqXiavrgpBIjGem63ad4K7AGj/Sym84UWFwNvr24ffeqm+Kq6rfOGFKXPIqmwqoy6tLVsC55QNVz\nGSquDhqlHXtVVPtoDFenXCSQwZJeZ9f2XQ2rUlxNmvyakiNpzkdxNbnsD5CCiqvJ2xWzX186La52\nKzaM0tQlj6KpsBLpY40zV2pqIVIzg6EDSMRYXKmphWd93NBCTS2kkQorkT63Yfxyxh22Xh0DRepo\nMHQACbVj705li6s+LrBEQIVVhcR388V86pIH1CeXq2vRjr0uRwPqlYtEYLDAff90Tlerx1pc3Tjn\n0cCRjJS3uJpzjedAuuWpuJqzzM9+ytKquPpJuWEUpi55FE2FVWUsDR2AJ3XJA+qTS5pHxYuruhwN\nqFcuEonBgvb7wOKuN4mxuFq2+LnQYTSVp7havKSAQLrlobhaXMH7TjQrru4vP4xC1CWPoplzLnQM\nhTGzycAdcDm6HFykQ9PfycmXncTxm77B8i3C3NtFqm8JcGjy13c757r/33eNbR6b9rwDXt2++YN3\ng+W+XDsH7RvX3OyRXBg6hJYG7r4hdAj5zA4dQBgL54aOQFq5H/h88tdCxibNWInIcHPv4XSbtrmp\nhYjUyCDRFFcxzlzFymc79lLpmivpMyqsRKSpxo6BIlIzg6EDSKi46o6Kq+pQcdWfVFiJSEsqrkRq\nbDB0AAkVV91RcVUdasfef1RYVcaxoQPwpC55QH1yaZ/HUHF1pYu7qUVdjgbUKxeJ3GCP239twEcU\nwYurOwbOGvbvKt/rauC4EgPpRpfF1cCCYsIo28CCehRXfVobd02FVWUcGjoAT+qSB9Qnl9Hz2DB+\nefQdA+tyNKBeuUgbv703dASJwR62nXqMryiC3utqx2MOarq8isXVMdNKDqQbXdzr6pi3FhpJaYby\nqHpxdXDoACpCXQFFpHNpx8DTjj+Te84JHYzETF0BW3t5bLoU+FP44HsCR5QaDB3Ay9QxsHPqGFgt\n6hgYlroCikg8Gu51peuuRDz5+e3JI7TB0AG8LPSpgVlVnLmKXp+eW1b1mStpT4WViHRH7dhFihFL\ncTUYOIaUiqvOqbiqFhVX9VVaYWVm48zsIjN7wsyeN7ObzWyPDrYzMzvczK41sxXptvea2UlmtlUZ\nscfh5tABeFKXPKA+ueTLI7aOgXU5GlCvXGIW5bgUQ3EFnRdXv5pXZBSlFVf/Pa+zn3vsxdV1u09h\nXtU+QFoUV/MeLTeMorTKo2rFVU16iRSulMLKzAz4Gckp9+cBJwATgF+Y2aRRNn8VcAnweuBfgOOA\n24FT0332iUtCB+BJXfKA+uSSP4+Yiqu6HA2oVy6xinpcqlJxdVnxF8qUUVwtm31Nx+vGXFwBzLri\nNaFD6F6T4mr2feWHUYR2eVSpuPph6AAqoqwZq08A7wX+2jl3hnPuX4APAptIBqJ2NgDvc87t45w7\nyzk3xzn3N+l2HzCz/QqNPBrbhQ7Ak7rkAfXJpbc8YmnHXpejAfXKJWJxj0tVKa5eO6GMKAovrraa\nMK6r9WNuxz5uwlbVPDUwU1xNGBsmDN9Gy6Mq97p6XegAKqKswupg4HHn3OavhJxzq4ErgL8ysy1b\nbeic2+icu63JU9cAhtr9iQRXhXbsIhnxj0tVKa5KErIdeyuxFldQ0euuumjHXjdVKK5kdGUVVnsA\nzVoaLiI5pWLXHPucmP65Om9QIuJRQ8dAFVdSAdUYl1RcjaDiqnOVLK5AxZVUVlmF1URgZZPlQ8t2\nyLHPmcAzwPy8QYmIZyqupDqqMy6pHfsIKq46V9ni6n+FDiAMFVfVtkW3G6QX/HZ0pbpzbn36162B\n9U1WWUdy2sTWXcZwIrAfcJRz7tk2q6Zntj7cze4j9TuSW25WXV3ygPrk4jmPuUs4/Y8Hc9asD3HT\ntP1ZudeL/vbdRl2OBtQjl4ZP3cKvlKjYuASbfybLu3kJ+PlS2PMd3W3j21dgWA2xZBE8EOb+z/Mf\n2Jn3TfbTAu/pRQ/yzOKHetrHbA7kEK7yEk8vHlz0DMsWD38LfpO9ef8Dzc5ejdei38HiI0nuo11h\ni1bD4j92t83WH4K7ri8mnrzuI7m5btU98vJfixmbnHNdPYD3Ay918NgE7Jpu8xxwcZN9HZSud2AX\nrz8t3ebCDtb9FOD00EMPPfQI9vhUt+NMnccljU166KGHHlE8Chmbup6xApYCh3e47sqGPyc2eX5o\n2WOd7MzMDgS+D/w7cFQHm1wPfJrka8F1nbyGiIh4MRbYmeRzuGhVGpdAY5OISCiFjk2WfntWKDO7\nAvgL59wOmeUXAdOB7ZxzG0fZx17ATcCdJN8kNjuFQ0REZFQal0RExLeymldcCbzBzDZfbWpmrwcO\nAa5rHLzMbBcz26VxYzN7G/BT4CHgoxq8RESkRxqXRETEq7JmrF4B3AL8GfANkla0/xfYEdjTOfdg\nw7rLgZecc7uk/96W5Jq5icCJjDw9Y1mL+4mIiIg0pXFJRER8K6WwAjCzccA/Ah8j6ba0CDjeOXdn\nZr2HSQawSem/dyL5RrCV7zvnZhQTtYiI1JXGJRER8am0wkpERERERKSuyrrGSkREREREpLZqVViZ\n2Tgzu8jMnjCz583sZjPbo4PtzMwON7NrzWxFuu29ZnaSmW1VYLxjzGy2mT1qZmvM7DYzO6DDbXcw\nsyvM7Ckze8bM5pnZW4qKdZRYcuVhZlPNbK6ZLTOzF8xsqZl9Iz09J4hejklmPzea2Utmdl4RcXbw\n+j3lYWbTzOzW9HfhKTNbaGYfKDDkVnH08jtyQPoZsCrN4XYz+0zRMbeIZRszO9XM5pvZk+l747Nd\nbJ/rs03ioLFJY1OvNDZt3l5jk0camwpQ9I0by3oABiwEngX+nuR+IvcCzwCTRtl2G5KbRy4EvgZ8\nHvgu8CJwU4ExXw6sB74O/A3JhdQbgPd1EO8DJPdh+QpwHMnNpB8BXhfgZ583j1XAXcAgMAP4Jsk9\nXX4PbBXofZQrl8w+ppLcfHQTcF7V8kiPx6Z0H18guaD/AuDTVckDGEhz+FUa/1HAz9Pf8+MC5LFT\n+toPk7Tn3gR8tsNtc3+26RH+obFJY1PIXDL70NgU/r2lsanmj+ABeHxzfDJ9c3y8YdnrgT8CPxxl\n2y2BvZssPzl9k+1XQLx7pfH+bcOyrYAHgVtG2XZmGtfkhmW7ARuBM0r+ufeSx75Nlh2W7m9GgPdQ\n7lwy6z8EnJTuq/TBq8djsnf63jq27Lg953E98P+BLRqWvTLd9s4AuWwJbJ/+/d1pXp0OXrk/2/QI\n/9DYpLEpZC6Z9TU2hc9DY1PNH3U6FfBg4HHn3DVDC5xzq4ErgL8ysy1bbeic2+iat8a9hqQif5vv\nYEnulfIicHFDHOuBOcB7zexP2mx7MPAb59zihm3vJ/m24ZMFxNpO7jyccwuaLB46fkX8zEfTyzEZ\nMovkPfONQiLsTC95fBlY6Zw7D5LTBIoMdBS95PEa4Cnn3IsN224iaam9tphwW0s/Y57IuXnuzzaJ\ngsYmjU290tiksakQGpv8q1NhtQewuMnyRcCrgF1z7HNi+ufqvEG18S7gAefc85nlixqeH8HMDHgn\n8NsmTy8CJpX8gZMrjzaK/JmPpqdczGxHksFrpgt7s9Be8tgP+I2ZHWdmq4DnzOwxMzu6iEBH0Use\nvwD+zMxOM7NJltzg9WSSb+TO9h9qoYr4bJPyaGzS2NQrjU0am2KksamJOhVWE0nO684aWrZDjn3O\nJDlXdH7eoNpoF6/ROt7tSKacfeeaV948WplF8k3QlT3GlUevuZwDLHbO/dh3YF3KlYeZvZZkGv8v\ngNOAM0m+Zb4TON/MvlBItK31cjxOA35MctrLg8AfSH6fD3bOzfMcZ9GK+GyT8mhs0tjUK41NGpti\npLGpiS1CB9BM+s3XmE7Wbfj2ZWuSCwmz1pG80bfuMoYTSb4hOco592w323aoXbxDz7fajpzbFiFv\nHiOY2adILhT+unNumYfYupU7FzP7IPBxknOvQ8ubx7bpn9sB05xzVwKY2VUkF6T+PQ2nPpSgl/fW\nBpKL6H8MXE1yDvsXgX8zswOcc4vabBsbr59tkp/Gps3Pt9qOnNsWQWMTGpsKorEpobGpiVhnrPYl\nOdd0tMcaMxuaalxL8m1Z1ljA0cW5q2Y2DTgd+K5z7qKcOYymXbxDz7fajpzbFiFvHsOY2V+SdLua\nT/IhGUKuXMzsFcC5wA8ary0IqNf31kbgqqGFzjkH/Ah4k5m9yVeQHejlvfXPwP9xzh3qnLvCOTcX\nOJDkm7Rz/YZZOG+fbdIzjU0am0LQ2JTQ2BQXjU1NRDljBSwFDu9w3ZUNf05s8vzQssc62ZmZHQh8\nH/h3ktaRRVlJ82nS0eL9I8k3BO1ybTY1W5S8eWxmZrsD1wL3AJ9wzr3kL7yu5M3lcJJzib9oZjul\nyyz989Xpsiecc2V9yPTy3lpHcmGtyzw3dHHr64BHe46wM7nySC+YnQHMblzunHvRzOYDR5vZls65\njT6DLZCXzzbxQmOTxqYQNDZpbIqRxqYmoiysnHP/Dfygy83uIjn/NmtvYA3J1GtbZrYXydTsIpLp\n5iI/RO8CPmBm22YugNybpNK/q9lGzjlnZvcCezZ5+j3AQ00uqCxSrjyGmNkk4D+Ax4EPO+fWFBbp\n6PLm8maSlqW3ZpY74K+Bz5KcinGd33Bb6uW9dRewp5lt0di1CBjqcrSqkIiby3s8xpN8tr2yyXNb\nkszUxzpb30zPn23ih8YmjU2BaGzS2BQjjU3NdNqXPfYHyYWMm4CpDcuG+un/W2bdXYBdMsveRvKL\neTcwroR4h+6D8HcNy8aQvBEXNix7M7BbZtt29wr5fyX/3HvJ4w3AMpJ7OuwYwXsoVy4k3wgONHm8\nRPLt8keBN8SeR7rsuPS99fmGZWPT43RPRY7HK9Lf+yUMv1fItsAK4HeB32ct7xUCvDH9XX5lw7KO\nP9v0iO+hsUljU6hcNDbFlYfGpv54BA/A4xviFSTfyjxDcvPExjtAvzWz7nKSb8+G/j30pt4InAB8\nOvMYcYNGTzH/iOTUidkkdxFfmP57n4Z1fgG8lNluW5JuMo8Dx5Pc3+GRNIfxAX72efO4K/2lPKvJ\nz/yAQO+jXLm02FeQmzD2eEzGpr8360havx5D8i35BmBKhfI4MX1v3UEyIH8FuC9ddmigY3I0SSeo\nC9L3xpXpv08CXp2uc2n63I4N23X82aZHfI9ujh8am2LJQ2NTZHmgsanIXDQ2+fx5hg7A85tjHHAR\nyTm3z5HclHCPJus9DCxr+PdO6Zu61eOSguIdk/5S/hfJtOlt2Q9t4OfAi0223SH9xX4qfRPPI/NN\nZ4k/91x5jPIzv7lKubTY1ybg3KrlQfKN0yUk35KvST84Q/1nopc8DgV+DTwJPJ/m8bEQeaTxPNzm\n/b5jus73SFo675jZtqPPNj3ifGhs0tgU8pg02ZfGprB5aGyq8cPSH4yIiIiIiIjkVKWL5ERERERE\nRKKkwkpERERERKRHKqxERERERER6pMJKRERERESkRyqsREREREREeqTCSkREREREpEcqrERERERE\nRHqkwkpERERERKRHKqxERERERER6pMJKRERERESkRyqsREREREREeqTCSkREREREpEf/A1asW++h\ncRcQAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10b65b978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x1s = np.linspace(-0.2, 1.2, 100)\n",
    "x2s = np.linspace(-0.2, 1.2, 100)\n",
    "x1, x2 = np.meshgrid(x1s, x2s)\n",
    "\n",
    "z1 = mlp_xor(x1, x2, activation=heaviside)\n",
    "z2 = mlp_xor(x1, x2, activation=sigmoid)\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.contourf(x1, x2, z1)\n",
    "plt.plot([0, 1], [0, 1], \"gs\", markersize=20)\n",
    "plt.plot([0, 1], [1, 0], \"y^\", markersize=20)\n",
    "plt.title(\"Activation function: heaviside\", fontsize=14)\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.contourf(x1, x2, z2)\n",
    "plt.plot([0, 1], [0, 1], \"gs\", markersize=20)\n",
    "plt.plot([0, 1], [1, 0], \"y^\", markersize=20)\n",
    "plt.title(\"Activation function: sigmoid\", fontsize=14)\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  1.,  1.,  1.],\n",
       "       [ 0.,  0.,  0., ...,  1.,  1.,  1.],\n",
       "       [ 0.,  0.,  0., ...,  1.,  1.,  1.],\n",
       "       ..., \n",
       "       [ 1.,  1.,  1., ...,  0.,  0.,  0.],\n",
       "       [ 1.,  1.,  1., ...,  0.,  0.,  0.],\n",
       "       [ 1.,  1.,  1., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.4155525 ,  0.41586968,  0.416187  , ...,  0.43656188,\n",
       "         0.43657038,  0.43657321],\n",
       "       [ 0.41586968,  0.416187  ,  0.41650443, ...,  0.43657038,\n",
       "         0.43657321,  0.43657038],\n",
       "       [ 0.416187  ,  0.41650443,  0.41682188, ...,  0.43657321,\n",
       "         0.43657038,  0.43656188],\n",
       "       ..., \n",
       "       [ 0.43656188,  0.43657038,  0.43657321, ...,  0.41682188,\n",
       "         0.41650443,  0.416187  ],\n",
       "       [ 0.43657038,  0.43657321,  0.43657038, ...,  0.41650443,\n",
       "         0.416187  ,  0.41586968],\n",
       "       [ 0.43657321,  0.43657038,  0.43656188, ...,  0.416187  ,\n",
       "         0.41586968,  0.4155525 ]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- MLP는 분류에 자주 사용되며 각 출력은 다른 바이너리 클래스 (예 : 스팸 / 햄, 긴급 / 비 긴급 등)에 해당합니다. 클래스가 배타적 인 경우 (예 : 숫자 이미지 분류의 경우 클래스 0-9) 출력 레이어는 일반적으로 개별 활성화 함수를 공유 softmax 함수로 대체하여 수정됩니다 (그림 10-9 참조). softmax 함수는 3 장에서 소개되었습니다. 각 뉴런의 출력은 해당 클래스의 예상 확률에 해당합니다. 신호는 한 방향 (입력에서 출력까지)으로 만 흐릅니다. 따라서이 아키텍처는 FNN (Feedforward Neural Network)의 예입니다.\n",
    "\n",
    "<img src ='./img/10_8.png'>\n",
    "\n",
    "### Training an MLP with TensorFlow’s high level API\n",
    "\n",
    "- TensorFlow를 사용하여 MLP를 학습하는 가장 간단한 방법은 Scikit-Learn의 API와 매우 유사한 상위 레벨 API TF.Learn을 사용하는 것입니다. \n",
    "\n",
    "- DNNClassifier 클래스는 임의의 수의 숨겨진 레이어로 Deep Neural Network를 학습하고 Softmax 출력 레이어를 사용하여 예상되는 클래스 확률을 산출하는 것을 쉽게 만듭니다. \n",
    "\n",
    "- 예를 들어, 다음 코드는 두 개의 숨겨진 레이어 (300 개의 뉴런이있는 레이어와 100 개의 뉴런이있는 레이어)와 10 개의 뉴런이있는 softmax 출력 레이어로 DNN을 분류합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"/tmp/data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = mnist.train.images\n",
    "X_test = mnist.test.images\n",
    "y_train = mnist.train.labels.astype(\"int\")\n",
    "y_test = mnist.test.labels.astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 784)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/b1/6r6n8ptx4r9cq1rvs075k7j00000gn/T/tmp7felyjwd\n",
      "INFO:tensorflow:Using config: {'_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_master': '', '_num_worker_replicas': 0, '_save_checkpoints_steps': None, '_environment': 'local', '_is_chief': True, '_task_id': 0, '_task_type': None, '_tf_random_seed': 42, '_model_dir': '/var/folders/b1/6r6n8ptx4r9cq1rvs075k7j00000gn/T/tmp7felyjwd', '_evaluation_master': '', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x118dae7f0>, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_session_config': None, '_keep_checkpoint_every_n_hours': 10000}\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:625: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /var/folders/b1/6r6n8ptx4r9cq1rvs075k7j00000gn/T/tmp7felyjwd/model.ckpt.\n",
      "INFO:tensorflow:step = 1, loss = 2.36404\n",
      "INFO:tensorflow:global_step/sec: 236.341\n",
      "INFO:tensorflow:step = 101, loss = 0.309677 (0.425 sec)\n",
      "INFO:tensorflow:global_step/sec: 233.446\n",
      "INFO:tensorflow:step = 201, loss = 0.254103 (0.430 sec)\n",
      "INFO:tensorflow:global_step/sec: 198.765\n",
      "INFO:tensorflow:step = 301, loss = 0.403251 (0.501 sec)\n",
      "INFO:tensorflow:global_step/sec: 182.899\n",
      "INFO:tensorflow:step = 401, loss = 0.248612 (0.547 sec)\n",
      "INFO:tensorflow:global_step/sec: 167.57\n",
      "INFO:tensorflow:step = 501, loss = 0.238972 (0.598 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.801\n",
      "INFO:tensorflow:step = 601, loss = 0.0964612 (0.486 sec)\n",
      "INFO:tensorflow:global_step/sec: 200.858\n",
      "INFO:tensorflow:step = 701, loss = 0.119384 (0.495 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.549\n",
      "INFO:tensorflow:step = 801, loss = 0.184879 (0.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 240.536\n",
      "INFO:tensorflow:step = 901, loss = 0.093465 (0.416 sec)\n",
      "INFO:tensorflow:global_step/sec: 231.749\n",
      "INFO:tensorflow:step = 1001, loss = 0.206881 (0.431 sec)\n",
      "INFO:tensorflow:global_step/sec: 179.577\n",
      "INFO:tensorflow:step = 1101, loss = 0.187316 (0.557 sec)\n",
      "INFO:tensorflow:global_step/sec: 181.293\n",
      "INFO:tensorflow:step = 1201, loss = 0.1543 (0.552 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.664\n",
      "INFO:tensorflow:step = 1301, loss = 0.163595 (0.468 sec)\n",
      "INFO:tensorflow:global_step/sec: 210.846\n",
      "INFO:tensorflow:step = 1401, loss = 0.0720562 (0.476 sec)\n",
      "INFO:tensorflow:global_step/sec: 235.117\n",
      "INFO:tensorflow:step = 1501, loss = 0.0723128 (0.424 sec)\n",
      "INFO:tensorflow:global_step/sec: 187.517\n",
      "INFO:tensorflow:step = 1601, loss = 0.121916 (0.533 sec)\n",
      "INFO:tensorflow:global_step/sec: 232.848\n",
      "INFO:tensorflow:step = 1701, loss = 0.039761 (0.430 sec)\n",
      "INFO:tensorflow:global_step/sec: 237.398\n",
      "INFO:tensorflow:step = 1801, loss = 0.152173 (0.421 sec)\n",
      "INFO:tensorflow:global_step/sec: 234.481\n",
      "INFO:tensorflow:step = 1901, loss = 0.070405 (0.426 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.987\n",
      "INFO:tensorflow:step = 2001, loss = 0.0662507 (0.437 sec)\n",
      "INFO:tensorflow:global_step/sec: 229.368\n",
      "INFO:tensorflow:step = 2101, loss = 0.0241838 (0.436 sec)\n",
      "INFO:tensorflow:global_step/sec: 229.765\n",
      "INFO:tensorflow:step = 2201, loss = 0.0292274 (0.435 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.372\n",
      "INFO:tensorflow:step = 2301, loss = 0.0513423 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 230.972\n",
      "INFO:tensorflow:step = 2401, loss = 0.0555448 (0.430 sec)\n",
      "INFO:tensorflow:global_step/sec: 233.022\n",
      "INFO:tensorflow:step = 2501, loss = 0.0884138 (0.429 sec)\n",
      "INFO:tensorflow:global_step/sec: 223.948\n",
      "INFO:tensorflow:step = 2601, loss = 0.0315207 (0.446 sec)\n",
      "INFO:tensorflow:global_step/sec: 185.018\n",
      "INFO:tensorflow:step = 2701, loss = 0.0126636 (0.540 sec)\n",
      "INFO:tensorflow:global_step/sec: 188.297\n",
      "INFO:tensorflow:step = 2801, loss = 0.0514662 (0.531 sec)\n",
      "INFO:tensorflow:global_step/sec: 169.7\n",
      "INFO:tensorflow:step = 2901, loss = 0.088122 (0.589 sec)\n",
      "INFO:tensorflow:global_step/sec: 194.791\n",
      "INFO:tensorflow:step = 3001, loss = 0.0138777 (0.518 sec)\n",
      "INFO:tensorflow:global_step/sec: 176.051\n",
      "INFO:tensorflow:step = 3101, loss = 0.044173 (0.565 sec)\n",
      "INFO:tensorflow:global_step/sec: 148.213\n",
      "INFO:tensorflow:step = 3201, loss = 0.0120668 (0.678 sec)\n",
      "INFO:tensorflow:global_step/sec: 160.766\n",
      "INFO:tensorflow:step = 3301, loss = 0.0452911 (0.618 sec)\n",
      "INFO:tensorflow:global_step/sec: 143.508\n",
      "INFO:tensorflow:step = 3401, loss = 0.152817 (0.702 sec)\n",
      "INFO:tensorflow:global_step/sec: 135.716\n",
      "INFO:tensorflow:step = 3501, loss = 0.0838171 (0.732 sec)\n",
      "INFO:tensorflow:global_step/sec: 151.514\n",
      "INFO:tensorflow:step = 3601, loss = 0.156769 (0.662 sec)\n",
      "INFO:tensorflow:global_step/sec: 170.183\n",
      "INFO:tensorflow:step = 3701, loss = 0.0343551 (0.585 sec)\n",
      "INFO:tensorflow:global_step/sec: 183.818\n",
      "INFO:tensorflow:step = 3801, loss = 0.00878235 (0.544 sec)\n",
      "INFO:tensorflow:global_step/sec: 161.663\n",
      "INFO:tensorflow:step = 3901, loss = 0.152629 (0.619 sec)\n",
      "INFO:tensorflow:global_step/sec: 133.429\n",
      "INFO:tensorflow:step = 4001, loss = 0.0950618 (0.749 sec)\n",
      "INFO:tensorflow:global_step/sec: 138.611\n",
      "INFO:tensorflow:step = 4101, loss = 0.0524628 (0.723 sec)\n",
      "INFO:tensorflow:global_step/sec: 146.598\n",
      "INFO:tensorflow:step = 4201, loss = 0.0629685 (0.680 sec)\n",
      "INFO:tensorflow:global_step/sec: 176.771\n",
      "INFO:tensorflow:step = 4301, loss = 0.166633 (0.569 sec)\n",
      "INFO:tensorflow:global_step/sec: 188.93\n",
      "INFO:tensorflow:step = 4401, loss = 0.108088 (0.526 sec)\n",
      "INFO:tensorflow:global_step/sec: 186.435\n",
      "INFO:tensorflow:step = 4501, loss = 0.0167887 (0.537 sec)\n",
      "INFO:tensorflow:global_step/sec: 202.067\n",
      "INFO:tensorflow:step = 4601, loss = 0.0170214 (0.494 sec)\n",
      "INFO:tensorflow:global_step/sec: 203.425\n",
      "INFO:tensorflow:step = 4701, loss = 0.00988497 (0.492 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.539\n",
      "INFO:tensorflow:step = 4801, loss = 0.0218255 (0.486 sec)\n",
      "INFO:tensorflow:global_step/sec: 191.174\n",
      "INFO:tensorflow:step = 4901, loss = 0.0958064 (0.523 sec)\n",
      "INFO:tensorflow:global_step/sec: 209.117\n",
      "INFO:tensorflow:step = 5001, loss = 0.032898 (0.478 sec)\n",
      "INFO:tensorflow:global_step/sec: 236.635\n",
      "INFO:tensorflow:step = 5101, loss = 0.00692303 (0.423 sec)\n",
      "INFO:tensorflow:global_step/sec: 207.101\n",
      "INFO:tensorflow:step = 5201, loss = 0.0374796 (0.483 sec)\n",
      "INFO:tensorflow:global_step/sec: 207.882\n",
      "INFO:tensorflow:step = 5301, loss = 0.0408561 (0.481 sec)\n",
      "INFO:tensorflow:global_step/sec: 225.816\n",
      "INFO:tensorflow:step = 5401, loss = 0.0703828 (0.443 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.451\n",
      "INFO:tensorflow:step = 5501, loss = 0.0597546 (0.468 sec)\n",
      "INFO:tensorflow:global_step/sec: 208.075\n",
      "INFO:tensorflow:step = 5601, loss = 0.0637175 (0.481 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.373\n",
      "INFO:tensorflow:step = 5701, loss = 0.0142295 (0.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 235.248\n",
      "INFO:tensorflow:step = 5801, loss = 0.008777 (0.425 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.306\n",
      "INFO:tensorflow:step = 5901, loss = 0.0868253 (0.464 sec)\n",
      "INFO:tensorflow:global_step/sec: 222.961\n",
      "INFO:tensorflow:step = 6001, loss = 0.109432 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 224.828\n",
      "INFO:tensorflow:step = 6101, loss = 0.0131425 (0.441 sec)\n",
      "INFO:tensorflow:global_step/sec: 226.608\n",
      "INFO:tensorflow:step = 6201, loss = 0.0240843 (0.442 sec)\n",
      "INFO:tensorflow:global_step/sec: 208.149\n",
      "INFO:tensorflow:step = 6301, loss = 0.085723 (0.480 sec)\n",
      "INFO:tensorflow:global_step/sec: 227.017\n",
      "INFO:tensorflow:step = 6401, loss = 0.0259363 (0.440 sec)\n",
      "INFO:tensorflow:global_step/sec: 225.082\n",
      "INFO:tensorflow:step = 6501, loss = 0.00852303 (0.444 sec)\n",
      "INFO:tensorflow:global_step/sec: 203.26\n",
      "INFO:tensorflow:step = 6601, loss = 0.0227815 (0.492 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.973\n",
      "INFO:tensorflow:step = 6701, loss = 0.0275877 (0.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 240.731\n",
      "INFO:tensorflow:step = 6801, loss = 0.0085514 (0.415 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.485\n",
      "INFO:tensorflow:step = 6901, loss = 0.0113093 (0.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 239.597\n",
      "INFO:tensorflow:step = 7001, loss = 0.0190613 (0.417 sec)\n",
      "INFO:tensorflow:global_step/sec: 225.399\n",
      "INFO:tensorflow:step = 7101, loss = 0.00409009 (0.446 sec)\n",
      "INFO:tensorflow:global_step/sec: 222.782\n",
      "INFO:tensorflow:step = 7201, loss = 0.0582136 (0.447 sec)\n",
      "INFO:tensorflow:global_step/sec: 224.37\n",
      "INFO:tensorflow:step = 7301, loss = 0.00672715 (0.446 sec)\n",
      "INFO:tensorflow:global_step/sec: 221.423\n",
      "INFO:tensorflow:step = 7401, loss = 0.0127499 (0.451 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.461\n",
      "INFO:tensorflow:step = 7501, loss = 0.005338 (0.466 sec)\n",
      "INFO:tensorflow:global_step/sec: 221.736\n",
      "INFO:tensorflow:step = 7601, loss = 0.0160609 (0.451 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.892\n",
      "INFO:tensorflow:step = 7701, loss = 0.00499156 (0.459 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.017\n",
      "INFO:tensorflow:step = 7801, loss = 0.00483353 (0.467 sec)\n",
      "INFO:tensorflow:global_step/sec: 212.809\n",
      "INFO:tensorflow:step = 7901, loss = 0.00696935 (0.471 sec)\n",
      "INFO:tensorflow:global_step/sec: 225.951\n",
      "INFO:tensorflow:step = 8001, loss = 0.00272221 (0.442 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.78\n",
      "INFO:tensorflow:step = 8101, loss = 0.0217708 (0.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 231.077\n",
      "INFO:tensorflow:step = 8201, loss = 0.0288787 (0.435 sec)\n",
      "INFO:tensorflow:global_step/sec: 229.671\n",
      "INFO:tensorflow:step = 8301, loss = 0.0539877 (0.433 sec)\n",
      "INFO:tensorflow:global_step/sec: 227.003\n",
      "INFO:tensorflow:step = 8401, loss = 0.00857862 (0.441 sec)\n",
      "INFO:tensorflow:global_step/sec: 226.171\n",
      "INFO:tensorflow:step = 8501, loss = 0.00668675 (0.443 sec)\n",
      "INFO:tensorflow:global_step/sec: 227.237\n",
      "INFO:tensorflow:step = 8601, loss = 0.00526417 (0.439 sec)\n",
      "INFO:tensorflow:global_step/sec: 201.677\n",
      "INFO:tensorflow:step = 8701, loss = 0.00431127 (0.496 sec)\n",
      "INFO:tensorflow:global_step/sec: 212.759\n",
      "INFO:tensorflow:step = 8801, loss = 0.00488374 (0.470 sec)\n",
      "INFO:tensorflow:global_step/sec: 218.212\n",
      "INFO:tensorflow:step = 8901, loss = 0.00250303 (0.458 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.533\n",
      "INFO:tensorflow:step = 9001, loss = 0.0148685 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.048\n",
      "INFO:tensorflow:step = 9101, loss = 0.00912793 (0.454 sec)\n",
      "INFO:tensorflow:global_step/sec: 227.836\n",
      "INFO:tensorflow:step = 9201, loss = 0.00432368 (0.439 sec)\n",
      "INFO:tensorflow:global_step/sec: 234.527\n",
      "INFO:tensorflow:step = 9301, loss = 0.0138446 (0.427 sec)\n",
      "INFO:tensorflow:global_step/sec: 233.093\n",
      "INFO:tensorflow:step = 9401, loss = 0.0518277 (0.429 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.385\n",
      "INFO:tensorflow:step = 9501, loss = 0.00607764 (0.467 sec)\n",
      "INFO:tensorflow:global_step/sec: 158.878\n",
      "INFO:tensorflow:step = 9601, loss = 0.0207135 (0.631 sec)\n",
      "INFO:tensorflow:global_step/sec: 179.842\n",
      "INFO:tensorflow:step = 9701, loss = 0.0166932 (0.555 sec)\n",
      "INFO:tensorflow:global_step/sec: 143.294\n",
      "INFO:tensorflow:step = 9801, loss = 0.00487015 (0.707 sec)\n",
      "INFO:tensorflow:global_step/sec: 181.469\n",
      "INFO:tensorflow:step = 9901, loss = 0.0185824 (0.541 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.771\n",
      "INFO:tensorflow:step = 10001, loss = 0.0240925 (0.486 sec)\n",
      "INFO:tensorflow:global_step/sec: 208.471\n",
      "INFO:tensorflow:step = 10101, loss = 0.00462607 (0.479 sec)\n",
      "INFO:tensorflow:global_step/sec: 183.911\n",
      "INFO:tensorflow:step = 10201, loss = 0.0100708 (0.544 sec)\n",
      "INFO:tensorflow:global_step/sec: 208.727\n",
      "INFO:tensorflow:step = 10301, loss = 0.00573162 (0.480 sec)\n",
      "INFO:tensorflow:global_step/sec: 210.092\n",
      "INFO:tensorflow:step = 10401, loss = 0.0101062 (0.475 sec)\n",
      "INFO:tensorflow:global_step/sec: 196.517\n",
      "INFO:tensorflow:step = 10501, loss = 0.00470994 (0.509 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.973\n",
      "INFO:tensorflow:step = 10601, loss = 0.00745281 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 197.523\n",
      "INFO:tensorflow:step = 10701, loss = 0.0220603 (0.506 sec)\n",
      "INFO:tensorflow:global_step/sec: 163.65\n",
      "INFO:tensorflow:step = 10801, loss = 0.0147888 (0.612 sec)\n",
      "INFO:tensorflow:global_step/sec: 201.353\n",
      "INFO:tensorflow:step = 10901, loss = 0.00258084 (0.500 sec)\n",
      "INFO:tensorflow:global_step/sec: 179.729\n",
      "INFO:tensorflow:step = 11001, loss = 0.0285976 (0.553 sec)\n",
      "INFO:tensorflow:global_step/sec: 186.299\n",
      "INFO:tensorflow:step = 11101, loss = 0.0044351 (0.537 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.585\n",
      "INFO:tensorflow:step = 11201, loss = 0.00119579 (0.502 sec)\n",
      "INFO:tensorflow:global_step/sec: 180.879\n",
      "INFO:tensorflow:step = 11301, loss = 0.0158182 (0.554 sec)\n",
      "INFO:tensorflow:global_step/sec: 141.651\n",
      "INFO:tensorflow:step = 11401, loss = 0.00693267 (0.706 sec)\n",
      "INFO:tensorflow:global_step/sec: 135.099\n",
      "INFO:tensorflow:step = 11501, loss = 0.0174892 (0.739 sec)\n",
      "INFO:tensorflow:global_step/sec: 126.901\n",
      "INFO:tensorflow:step = 11601, loss = 0.000888462 (0.792 sec)\n",
      "INFO:tensorflow:global_step/sec: 193.874\n",
      "INFO:tensorflow:step = 11701, loss = 0.0026345 (0.513 sec)\n",
      "INFO:tensorflow:global_step/sec: 198.029\n",
      "INFO:tensorflow:step = 11801, loss = 0.000522998 (0.504 sec)\n",
      "INFO:tensorflow:global_step/sec: 173.7\n",
      "INFO:tensorflow:step = 11901, loss = 0.0101293 (0.578 sec)\n",
      "INFO:tensorflow:global_step/sec: 162.487\n",
      "INFO:tensorflow:step = 12001, loss = 0.000120309 (0.618 sec)\n",
      "INFO:tensorflow:global_step/sec: 122.04\n",
      "INFO:tensorflow:step = 12101, loss = 0.00283077 (0.819 sec)\n",
      "INFO:tensorflow:global_step/sec: 181.931\n",
      "INFO:tensorflow:step = 12201, loss = 0.00376223 (0.546 sec)\n",
      "INFO:tensorflow:global_step/sec: 192.692\n",
      "INFO:tensorflow:step = 12301, loss = 0.00516198 (0.519 sec)\n",
      "INFO:tensorflow:global_step/sec: 151.922\n",
      "INFO:tensorflow:step = 12401, loss = 0.000395552 (0.658 sec)\n",
      "INFO:tensorflow:global_step/sec: 146.899\n",
      "INFO:tensorflow:step = 12501, loss = 0.0038692 (0.683 sec)\n",
      "INFO:tensorflow:global_step/sec: 145.935\n",
      "INFO:tensorflow:step = 12601, loss = 0.000996494 (0.683 sec)\n",
      "INFO:tensorflow:global_step/sec: 173.226\n",
      "INFO:tensorflow:step = 12701, loss = 0.00522744 (0.577 sec)\n",
      "INFO:tensorflow:global_step/sec: 207.713\n",
      "INFO:tensorflow:step = 12801, loss = 0.00650308 (0.481 sec)\n",
      "INFO:tensorflow:global_step/sec: 177.511\n",
      "INFO:tensorflow:step = 12901, loss = 0.00290468 (0.563 sec)\n",
      "INFO:tensorflow:global_step/sec: 155.058\n",
      "INFO:tensorflow:step = 13001, loss = 0.00306313 (0.646 sec)\n",
      "INFO:tensorflow:global_step/sec: 191.963\n",
      "INFO:tensorflow:step = 13101, loss = 0.0040113 (0.519 sec)\n",
      "INFO:tensorflow:global_step/sec: 122.437\n",
      "INFO:tensorflow:step = 13201, loss = 0.00749846 (0.817 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.098\n",
      "INFO:tensorflow:step = 13301, loss = 0.00422553 (0.502 sec)\n",
      "INFO:tensorflow:global_step/sec: 226.001\n",
      "INFO:tensorflow:step = 13401, loss = 0.00333589 (0.442 sec)\n",
      "INFO:tensorflow:global_step/sec: 231.332\n",
      "INFO:tensorflow:step = 13501, loss = 0.00930926 (0.433 sec)\n",
      "INFO:tensorflow:global_step/sec: 154.02\n",
      "INFO:tensorflow:step = 13601, loss = 0.00580592 (0.649 sec)\n",
      "INFO:tensorflow:global_step/sec: 148.232\n",
      "INFO:tensorflow:step = 13701, loss = 0.00158466 (0.680 sec)\n",
      "INFO:tensorflow:global_step/sec: 130.098\n",
      "INFO:tensorflow:step = 13801, loss = 0.00957848 (0.764 sec)\n",
      "INFO:tensorflow:global_step/sec: 150.749\n",
      "INFO:tensorflow:step = 13901, loss = 0.0029991 (0.667 sec)\n",
      "INFO:tensorflow:global_step/sec: 129.478\n",
      "INFO:tensorflow:step = 14001, loss = 0.00257565 (0.772 sec)\n",
      "INFO:tensorflow:global_step/sec: 173.332\n",
      "INFO:tensorflow:step = 14101, loss = 0.0051015 (0.574 sec)\n",
      "INFO:tensorflow:global_step/sec: 146.186\n",
      "INFO:tensorflow:step = 14201, loss = 0.00931561 (0.686 sec)\n",
      "INFO:tensorflow:global_step/sec: 184.136\n",
      "INFO:tensorflow:step = 14301, loss = 0.00167436 (0.541 sec)\n",
      "INFO:tensorflow:global_step/sec: 162.41\n",
      "INFO:tensorflow:step = 14401, loss = 0.00068472 (0.623 sec)\n",
      "INFO:tensorflow:global_step/sec: 156.644\n",
      "INFO:tensorflow:step = 14501, loss = 0.000823331 (0.638 sec)\n",
      "INFO:tensorflow:global_step/sec: 166.677\n",
      "INFO:tensorflow:step = 14601, loss = 0.00392992 (0.599 sec)\n",
      "INFO:tensorflow:global_step/sec: 171.619\n",
      "INFO:tensorflow:step = 14701, loss = 0.00197606 (0.583 sec)\n",
      "INFO:tensorflow:global_step/sec: 200.744\n",
      "INFO:tensorflow:step = 14801, loss = 0.00111108 (0.494 sec)\n",
      "INFO:tensorflow:global_step/sec: 184.51\n",
      "INFO:tensorflow:step = 14901, loss = 0.00252097 (0.539 sec)\n",
      "INFO:tensorflow:global_step/sec: 137.934\n",
      "INFO:tensorflow:step = 15001, loss = 0.000814515 (0.726 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.457\n",
      "INFO:tensorflow:step = 15101, loss = 0.00237104 (0.467 sec)\n",
      "INFO:tensorflow:global_step/sec: 119.596\n",
      "INFO:tensorflow:step = 15201, loss = 0.00227502 (0.837 sec)\n",
      "INFO:tensorflow:global_step/sec: 209.695\n",
      "INFO:tensorflow:step = 15301, loss = 0.00141252 (0.476 sec)\n",
      "INFO:tensorflow:global_step/sec: 210.051\n",
      "INFO:tensorflow:step = 15401, loss = 0.00455337 (0.476 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.146\n",
      "INFO:tensorflow:step = 15501, loss = 0.00491852 (0.467 sec)\n",
      "INFO:tensorflow:global_step/sec: 200.048\n",
      "INFO:tensorflow:step = 15601, loss = 0.00487903 (0.500 sec)\n",
      "INFO:tensorflow:global_step/sec: 209.971\n",
      "INFO:tensorflow:step = 15701, loss = 0.0134273 (0.477 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.773\n",
      "INFO:tensorflow:step = 15801, loss = 0.00312125 (0.468 sec)\n",
      "INFO:tensorflow:global_step/sec: 200.992\n",
      "INFO:tensorflow:step = 15901, loss = 0.000708232 (0.498 sec)\n",
      "INFO:tensorflow:global_step/sec: 185.868\n",
      "INFO:tensorflow:step = 16001, loss = 0.00560298 (0.538 sec)\n",
      "INFO:tensorflow:global_step/sec: 183.659\n",
      "INFO:tensorflow:step = 16101, loss = 0.00430737 (0.545 sec)\n",
      "INFO:tensorflow:global_step/sec: 147.35\n",
      "INFO:tensorflow:step = 16201, loss = 7.45395e-05 (0.677 sec)\n",
      "INFO:tensorflow:global_step/sec: 150.162\n",
      "INFO:tensorflow:step = 16301, loss = 0.00280412 (0.666 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.662\n",
      "INFO:tensorflow:step = 16401, loss = 0.001583 (0.454 sec)\n",
      "INFO:tensorflow:global_step/sec: 202.527\n",
      "INFO:tensorflow:step = 16501, loss = 0.00205469 (0.493 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.706\n",
      "INFO:tensorflow:step = 16601, loss = 0.00472116 (0.467 sec)\n",
      "INFO:tensorflow:global_step/sec: 203.606\n",
      "INFO:tensorflow:step = 16701, loss = 0.00300912 (0.490 sec)\n",
      "INFO:tensorflow:global_step/sec: 133.857\n",
      "INFO:tensorflow:step = 16801, loss = 0.00221508 (0.751 sec)\n",
      "INFO:tensorflow:global_step/sec: 144.378\n",
      "INFO:tensorflow:step = 16901, loss = 0.00274078 (0.696 sec)\n",
      "INFO:tensorflow:global_step/sec: 148.852\n",
      "INFO:tensorflow:step = 17001, loss = 0.00335069 (0.665 sec)\n",
      "INFO:tensorflow:global_step/sec: 154.199\n",
      "INFO:tensorflow:step = 17101, loss = 0.000582267 (0.649 sec)\n",
      "INFO:tensorflow:global_step/sec: 187.517\n",
      "INFO:tensorflow:step = 17201, loss = 0.00259225 (0.535 sec)\n",
      "INFO:tensorflow:global_step/sec: 190.148\n",
      "INFO:tensorflow:step = 17301, loss = 0.000920891 (0.529 sec)\n",
      "INFO:tensorflow:global_step/sec: 152.037\n",
      "INFO:tensorflow:step = 17401, loss = 0.00217769 (0.653 sec)\n",
      "INFO:tensorflow:global_step/sec: 177.924\n",
      "INFO:tensorflow:step = 17501, loss = 0.00163418 (0.564 sec)\n",
      "INFO:tensorflow:global_step/sec: 183.008\n",
      "INFO:tensorflow:step = 17601, loss = 0.000338328 (0.544 sec)\n",
      "INFO:tensorflow:global_step/sec: 184.217\n",
      "INFO:tensorflow:step = 17701, loss = 0.000893746 (0.557 sec)\n",
      "INFO:tensorflow:global_step/sec: 161.142\n",
      "INFO:tensorflow:step = 17801, loss = 0.000348846 (0.610 sec)\n",
      "INFO:tensorflow:global_step/sec: 151.047\n",
      "INFO:tensorflow:step = 17901, loss = 0.00200284 (0.658 sec)\n",
      "INFO:tensorflow:global_step/sec: 190.373\n",
      "INFO:tensorflow:step = 18001, loss = 0.0012488 (0.529 sec)\n",
      "INFO:tensorflow:global_step/sec: 203.952\n",
      "INFO:tensorflow:step = 18101, loss = 0.00122258 (0.486 sec)\n",
      "INFO:tensorflow:global_step/sec: 225.953\n",
      "INFO:tensorflow:step = 18201, loss = 0.00400346 (0.443 sec)\n",
      "INFO:tensorflow:global_step/sec: 129.588\n",
      "INFO:tensorflow:step = 18301, loss = 0.0154516 (0.772 sec)\n",
      "INFO:tensorflow:global_step/sec: 197.486\n",
      "INFO:tensorflow:step = 18401, loss = 0.00357402 (0.505 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.176\n",
      "INFO:tensorflow:step = 18501, loss = 0.00224499 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 208.819\n",
      "INFO:tensorflow:step = 18601, loss = 0.00348468 (0.479 sec)\n",
      "INFO:tensorflow:global_step/sec: 194.003\n",
      "INFO:tensorflow:step = 18701, loss = 0.00106254 (0.516 sec)\n",
      "INFO:tensorflow:global_step/sec: 182.237\n",
      "INFO:tensorflow:step = 18801, loss = 0.00134678 (0.548 sec)\n",
      "INFO:tensorflow:global_step/sec: 141.981\n",
      "INFO:tensorflow:step = 18901, loss = 0.00304573 (0.707 sec)\n",
      "INFO:tensorflow:global_step/sec: 150.253\n",
      "INFO:tensorflow:step = 19001, loss = 0.00137681 (0.663 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.989\n",
      "INFO:tensorflow:step = 19101, loss = 0.000547609 (0.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.64\n",
      "INFO:tensorflow:step = 19201, loss = 0.000463684 (0.486 sec)\n",
      "INFO:tensorflow:global_step/sec: 204.31\n",
      "INFO:tensorflow:step = 19301, loss = 0.00509027 (0.490 sec)\n",
      "INFO:tensorflow:global_step/sec: 208.313\n",
      "INFO:tensorflow:step = 19401, loss = 0.000722533 (0.481 sec)\n",
      "INFO:tensorflow:global_step/sec: 155.255\n",
      "INFO:tensorflow:step = 19501, loss = 0.00281473 (0.649 sec)\n",
      "INFO:tensorflow:global_step/sec: 151.498\n",
      "INFO:tensorflow:step = 19601, loss = 0.000629583 (0.657 sec)\n",
      "INFO:tensorflow:global_step/sec: 135.201\n",
      "INFO:tensorflow:step = 19701, loss = 0.000147449 (0.736 sec)\n",
      "INFO:tensorflow:global_step/sec: 204.107\n",
      "INFO:tensorflow:step = 19801, loss = 0.000430371 (0.496 sec)\n",
      "INFO:tensorflow:global_step/sec: 158.601\n",
      "INFO:tensorflow:step = 19901, loss = 0.00136521 (0.625 sec)\n",
      "INFO:tensorflow:global_step/sec: 128.239\n",
      "INFO:tensorflow:step = 20001, loss = 0.0024896 (0.779 sec)\n",
      "INFO:tensorflow:global_step/sec: 209.747\n",
      "INFO:tensorflow:step = 20101, loss = 0.000431558 (0.477 sec)\n",
      "INFO:tensorflow:global_step/sec: 204.625\n",
      "INFO:tensorflow:step = 20201, loss = 0.00192564 (0.489 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.686\n",
      "INFO:tensorflow:step = 20301, loss = 0.000940824 (0.485 sec)\n",
      "INFO:tensorflow:global_step/sec: 218.053\n",
      "INFO:tensorflow:step = 20401, loss = 0.000245953 (0.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 219.389\n",
      "INFO:tensorflow:step = 20501, loss = 0.00025361 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 143.442\n",
      "INFO:tensorflow:step = 20601, loss = 0.00130026 (0.697 sec)\n",
      "INFO:tensorflow:global_step/sec: 135.647\n",
      "INFO:tensorflow:step = 20701, loss = 0.00123567 (0.739 sec)\n",
      "INFO:tensorflow:global_step/sec: 142.616\n",
      "INFO:tensorflow:step = 20801, loss = 0.00204745 (0.702 sec)\n",
      "INFO:tensorflow:global_step/sec: 123.521\n",
      "INFO:tensorflow:step = 20901, loss = 0.00153957 (0.810 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.632\n",
      "INFO:tensorflow:step = 21001, loss = 0.00241378 (0.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 212.827\n",
      "INFO:tensorflow:step = 21101, loss = 0.00142351 (0.471 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.548\n",
      "INFO:tensorflow:step = 21201, loss = 0.00256507 (0.467 sec)\n",
      "INFO:tensorflow:global_step/sec: 229.552\n",
      "INFO:tensorflow:step = 21301, loss = 0.00106203 (0.435 sec)\n",
      "INFO:tensorflow:global_step/sec: 180.253\n",
      "INFO:tensorflow:step = 21401, loss = 0.0025859 (0.573 sec)\n",
      "INFO:tensorflow:global_step/sec: 170.246\n",
      "INFO:tensorflow:step = 21501, loss = 0.000238369 (0.569 sec)\n",
      "INFO:tensorflow:global_step/sec: 187.629\n",
      "INFO:tensorflow:step = 21601, loss = 0.00158536 (0.534 sec)\n",
      "INFO:tensorflow:global_step/sec: 141.173\n",
      "INFO:tensorflow:step = 21701, loss = 0.000727434 (0.707 sec)\n",
      "INFO:tensorflow:global_step/sec: 197.178\n",
      "INFO:tensorflow:step = 21801, loss = 0.000661301 (0.506 sec)\n",
      "INFO:tensorflow:global_step/sec: 177.274\n",
      "INFO:tensorflow:step = 21901, loss = 0.000490357 (0.564 sec)\n",
      "INFO:tensorflow:global_step/sec: 184.3\n",
      "INFO:tensorflow:step = 22001, loss = 0.000124842 (0.543 sec)\n",
      "INFO:tensorflow:global_step/sec: 157.404\n",
      "INFO:tensorflow:step = 22101, loss = 0.000445235 (0.639 sec)\n",
      "INFO:tensorflow:global_step/sec: 161.674\n",
      "INFO:tensorflow:step = 22201, loss = 0.00133724 (0.615 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.924\n",
      "INFO:tensorflow:step = 22301, loss = 0.00247763 (0.485 sec)\n",
      "INFO:tensorflow:global_step/sec: 151.571\n",
      "INFO:tensorflow:step = 22401, loss = 0.00171271 (0.661 sec)\n",
      "INFO:tensorflow:global_step/sec: 167.057\n",
      "INFO:tensorflow:step = 22501, loss = 0.00149307 (0.597 sec)\n",
      "INFO:tensorflow:global_step/sec: 211.101\n",
      "INFO:tensorflow:step = 22601, loss = 0.00392994 (0.473 sec)\n",
      "INFO:tensorflow:global_step/sec: 187.857\n",
      "INFO:tensorflow:step = 22701, loss = 0.000875101 (0.535 sec)\n",
      "INFO:tensorflow:global_step/sec: 233.03\n",
      "INFO:tensorflow:step = 22801, loss = 0.00118385 (0.427 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.344\n",
      "INFO:tensorflow:step = 22901, loss = 0.00240292 (0.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 152.499\n",
      "INFO:tensorflow:step = 23001, loss = 0.000830913 (0.656 sec)\n",
      "INFO:tensorflow:global_step/sec: 157.051\n",
      "INFO:tensorflow:step = 23101, loss = 0.00284528 (0.637 sec)\n",
      "INFO:tensorflow:global_step/sec: 143.611\n",
      "INFO:tensorflow:step = 23201, loss = 0.00224091 (0.699 sec)\n",
      "INFO:tensorflow:global_step/sec: 180.221\n",
      "INFO:tensorflow:step = 23301, loss = 0.00193402 (0.553 sec)\n",
      "INFO:tensorflow:global_step/sec: 113.507\n",
      "INFO:tensorflow:step = 23401, loss = 0.000599899 (0.886 sec)\n",
      "INFO:tensorflow:global_step/sec: 183.409\n",
      "INFO:tensorflow:step = 23501, loss = 0.000690191 (0.542 sec)\n",
      "INFO:tensorflow:global_step/sec: 192.218\n",
      "INFO:tensorflow:step = 23601, loss = 0.0006689 (0.517 sec)\n",
      "INFO:tensorflow:global_step/sec: 185.838\n",
      "INFO:tensorflow:step = 23701, loss = 0.000450027 (0.541 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.307\n",
      "INFO:tensorflow:step = 23801, loss = 0.00181704 (0.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 177.357\n",
      "INFO:tensorflow:step = 23901, loss = 0.00110625 (0.563 sec)\n",
      "INFO:tensorflow:global_step/sec: 168.481\n",
      "INFO:tensorflow:step = 24001, loss = 0.000971603 (0.593 sec)\n",
      "INFO:tensorflow:global_step/sec: 201.818\n",
      "INFO:tensorflow:step = 24101, loss = 0.000599703 (0.496 sec)\n",
      "INFO:tensorflow:global_step/sec: 187.713\n",
      "INFO:tensorflow:step = 24201, loss = 0.00103672 (0.532 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.134\n",
      "INFO:tensorflow:step = 24301, loss = 0.000316926 (0.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 219.217\n",
      "INFO:tensorflow:step = 24401, loss = 0.00197788 (0.456 sec)\n",
      "INFO:tensorflow:global_step/sec: 218.515\n",
      "INFO:tensorflow:step = 24501, loss = 0.000518455 (0.457 sec)\n",
      "INFO:tensorflow:global_step/sec: 189.033\n",
      "INFO:tensorflow:step = 24601, loss = 0.000293449 (0.529 sec)\n",
      "INFO:tensorflow:global_step/sec: 207.98\n",
      "INFO:tensorflow:step = 24701, loss = 0.00114909 (0.481 sec)\n",
      "INFO:tensorflow:global_step/sec: 201.961\n",
      "INFO:tensorflow:step = 24801, loss = 0.00152487 (0.495 sec)\n",
      "INFO:tensorflow:global_step/sec: 196.621\n",
      "INFO:tensorflow:step = 24901, loss = 0.00201351 (0.509 sec)\n",
      "INFO:tensorflow:global_step/sec: 202.229\n",
      "INFO:tensorflow:step = 25001, loss = 0.000152594 (0.495 sec)\n",
      "INFO:tensorflow:global_step/sec: 208.784\n",
      "INFO:tensorflow:step = 25101, loss = 0.00193388 (0.478 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.177\n",
      "INFO:tensorflow:step = 25201, loss = 0.00282617 (0.502 sec)\n",
      "INFO:tensorflow:global_step/sec: 219.338\n",
      "INFO:tensorflow:step = 25301, loss = 0.000192127 (0.456 sec)\n",
      "INFO:tensorflow:global_step/sec: 225.073\n",
      "INFO:tensorflow:step = 25401, loss = 0.000797401 (0.445 sec)\n",
      "INFO:tensorflow:global_step/sec: 224.073\n",
      "INFO:tensorflow:step = 25501, loss = 0.00124578 (0.446 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.964\n",
      "INFO:tensorflow:step = 25601, loss = 0.00119779 (0.468 sec)\n",
      "INFO:tensorflow:global_step/sec: 225.402\n",
      "INFO:tensorflow:step = 25701, loss = 0.000874612 (0.442 sec)\n",
      "INFO:tensorflow:global_step/sec: 196.697\n",
      "INFO:tensorflow:step = 25801, loss = 0.00136518 (0.512 sec)\n",
      "INFO:tensorflow:global_step/sec: 191.198\n",
      "INFO:tensorflow:step = 25901, loss = 0.00184243 (0.521 sec)\n",
      "INFO:tensorflow:global_step/sec: 180.526\n",
      "INFO:tensorflow:step = 26001, loss = 7.84672e-05 (0.551 sec)\n",
      "INFO:tensorflow:global_step/sec: 146.162\n",
      "INFO:tensorflow:step = 26101, loss = 0.00103029 (0.684 sec)\n",
      "INFO:tensorflow:global_step/sec: 173.344\n",
      "INFO:tensorflow:step = 26201, loss = 0.000715368 (0.577 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.452\n",
      "INFO:tensorflow:step = 26301, loss = 0.000957418 (0.455 sec)\n",
      "INFO:tensorflow:global_step/sec: 196.814\n",
      "INFO:tensorflow:step = 26401, loss = 0.00165632 (0.508 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.416\n",
      "INFO:tensorflow:step = 26501, loss = 0.00100959 (0.486 sec)\n",
      "INFO:tensorflow:global_step/sec: 143.588\n",
      "INFO:tensorflow:step = 26601, loss = 0.000594357 (0.698 sec)\n",
      "INFO:tensorflow:global_step/sec: 182.041\n",
      "INFO:tensorflow:step = 26701, loss = 3.75124e-05 (0.547 sec)\n",
      "INFO:tensorflow:global_step/sec: 192.668\n",
      "INFO:tensorflow:step = 26801, loss = 0.000775705 (0.520 sec)\n",
      "INFO:tensorflow:global_step/sec: 174.691\n",
      "INFO:tensorflow:step = 26901, loss = 0.000904265 (0.575 sec)\n",
      "INFO:tensorflow:global_step/sec: 209.658\n",
      "INFO:tensorflow:step = 27001, loss = 0.000553487 (0.474 sec)\n",
      "INFO:tensorflow:global_step/sec: 174.305\n",
      "INFO:tensorflow:step = 27101, loss = 0.00042911 (0.579 sec)\n",
      "INFO:tensorflow:global_step/sec: 191.072\n",
      "INFO:tensorflow:step = 27201, loss = 0.000641743 (0.519 sec)\n",
      "INFO:tensorflow:global_step/sec: 225.124\n",
      "INFO:tensorflow:step = 27301, loss = 0.00113445 (0.444 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.554\n",
      "INFO:tensorflow:step = 27401, loss = 0.000147887 (0.488 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.7\n",
      "INFO:tensorflow:step = 27501, loss = 0.00149474 (0.468 sec)\n",
      "INFO:tensorflow:global_step/sec: 174.143\n",
      "INFO:tensorflow:step = 27601, loss = 0.00099866 (0.577 sec)\n",
      "INFO:tensorflow:global_step/sec: 165.073\n",
      "INFO:tensorflow:step = 27701, loss = 0.000368925 (0.603 sec)\n",
      "INFO:tensorflow:global_step/sec: 153.241\n",
      "INFO:tensorflow:step = 27801, loss = 0.000700521 (0.660 sec)\n",
      "INFO:tensorflow:global_step/sec: 162.966\n",
      "INFO:tensorflow:step = 27901, loss = 0.000367836 (0.606 sec)\n",
      "INFO:tensorflow:global_step/sec: 140.165\n",
      "INFO:tensorflow:step = 28001, loss = 0.00131156 (0.719 sec)\n",
      "INFO:tensorflow:global_step/sec: 111.07\n",
      "INFO:tensorflow:step = 28101, loss = 0.000550622 (0.895 sec)\n",
      "INFO:tensorflow:global_step/sec: 198.612\n",
      "INFO:tensorflow:step = 28201, loss = 0.00143182 (0.503 sec)\n",
      "INFO:tensorflow:global_step/sec: 224.526\n",
      "INFO:tensorflow:step = 28301, loss = 0.000660615 (0.445 sec)\n",
      "INFO:tensorflow:global_step/sec: 218.031\n",
      "INFO:tensorflow:step = 28401, loss = 0.00102658 (0.460 sec)\n",
      "INFO:tensorflow:global_step/sec: 127.98\n",
      "INFO:tensorflow:step = 28501, loss = 0.000680939 (0.780 sec)\n",
      "INFO:tensorflow:global_step/sec: 193.067\n",
      "INFO:tensorflow:step = 28601, loss = 0.000403072 (0.521 sec)\n",
      "INFO:tensorflow:global_step/sec: 166.959\n",
      "INFO:tensorflow:step = 28701, loss = 0.000918623 (0.601 sec)\n",
      "INFO:tensorflow:global_step/sec: 157.226\n",
      "INFO:tensorflow:step = 28801, loss = 0.000993003 (0.630 sec)\n",
      "INFO:tensorflow:global_step/sec: 157.164\n",
      "INFO:tensorflow:step = 28901, loss = 0.000232585 (0.637 sec)\n",
      "INFO:tensorflow:global_step/sec: 172.285\n",
      "INFO:tensorflow:step = 29001, loss = 0.00192796 (0.580 sec)\n",
      "INFO:tensorflow:global_step/sec: 160.443\n",
      "INFO:tensorflow:step = 29101, loss = 0.00101591 (0.631 sec)\n",
      "INFO:tensorflow:global_step/sec: 140.403\n",
      "INFO:tensorflow:step = 29201, loss = 0.00169011 (0.714 sec)\n",
      "INFO:tensorflow:global_step/sec: 170.602\n",
      "INFO:tensorflow:step = 29301, loss = 0.00108807 (0.577 sec)\n",
      "INFO:tensorflow:global_step/sec: 209.684\n",
      "INFO:tensorflow:step = 29401, loss = 0.00101428 (0.477 sec)\n",
      "INFO:tensorflow:global_step/sec: 204.819\n",
      "INFO:tensorflow:step = 29501, loss = 0.000796202 (0.489 sec)\n",
      "INFO:tensorflow:global_step/sec: 166.604\n",
      "INFO:tensorflow:step = 29601, loss = 0.000337627 (0.601 sec)\n",
      "INFO:tensorflow:global_step/sec: 179.916\n",
      "INFO:tensorflow:step = 29701, loss = 0.000258813 (0.554 sec)\n",
      "INFO:tensorflow:global_step/sec: 235.111\n",
      "INFO:tensorflow:step = 29801, loss = 0.000616941 (0.426 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.438\n",
      "INFO:tensorflow:step = 29901, loss = 0.00074321 (0.486 sec)\n",
      "INFO:tensorflow:global_step/sec: 209.912\n",
      "INFO:tensorflow:step = 30001, loss = 6.01432e-05 (0.475 sec)\n",
      "INFO:tensorflow:global_step/sec: 141.273\n",
      "INFO:tensorflow:step = 30101, loss = 0.000580716 (0.708 sec)\n",
      "INFO:tensorflow:global_step/sec: 190.62\n",
      "INFO:tensorflow:step = 30201, loss = 0.000218506 (0.525 sec)\n",
      "INFO:tensorflow:global_step/sec: 134.221\n",
      "INFO:tensorflow:step = 30301, loss = 0.000837331 (0.752 sec)\n",
      "INFO:tensorflow:global_step/sec: 143.458\n",
      "INFO:tensorflow:step = 30401, loss = 0.00138102 (0.691 sec)\n",
      "INFO:tensorflow:global_step/sec: 184.728\n",
      "INFO:tensorflow:step = 30501, loss = 0.000929428 (0.540 sec)\n",
      "INFO:tensorflow:global_step/sec: 142.633\n",
      "INFO:tensorflow:step = 30601, loss = 0.00146183 (0.704 sec)\n",
      "INFO:tensorflow:global_step/sec: 175.783\n",
      "INFO:tensorflow:step = 30701, loss = 0.000773375 (0.566 sec)\n",
      "INFO:tensorflow:global_step/sec: 203.895\n",
      "INFO:tensorflow:step = 30801, loss = 0.00110586 (0.490 sec)\n",
      "INFO:tensorflow:global_step/sec: 155.189\n",
      "INFO:tensorflow:step = 30901, loss = 0.00121131 (0.648 sec)\n",
      "INFO:tensorflow:global_step/sec: 197.554\n",
      "INFO:tensorflow:step = 31001, loss = 0.00107659 (0.504 sec)\n",
      "INFO:tensorflow:global_step/sec: 164.426\n",
      "INFO:tensorflow:step = 31101, loss = 0.00138425 (0.609 sec)\n",
      "INFO:tensorflow:global_step/sec: 188.331\n",
      "INFO:tensorflow:step = 31201, loss = 0.000538949 (0.534 sec)\n",
      "INFO:tensorflow:global_step/sec: 142.422\n",
      "INFO:tensorflow:step = 31301, loss = 0.000428765 (0.701 sec)\n",
      "INFO:tensorflow:global_step/sec: 188.757\n",
      "INFO:tensorflow:step = 31401, loss = 0.000609493 (0.527 sec)\n",
      "INFO:tensorflow:global_step/sec: 185.832\n",
      "INFO:tensorflow:step = 31501, loss = 0.00025601 (0.537 sec)\n",
      "INFO:tensorflow:global_step/sec: 198.101\n",
      "INFO:tensorflow:step = 31601, loss = 8.65842e-05 (0.507 sec)\n",
      "INFO:tensorflow:global_step/sec: 174.038\n",
      "INFO:tensorflow:step = 31701, loss = 0.000604256 (0.573 sec)\n",
      "INFO:tensorflow:global_step/sec: 196.377\n",
      "INFO:tensorflow:step = 31801, loss = 9.59904e-05 (0.510 sec)\n",
      "INFO:tensorflow:global_step/sec: 212.313\n",
      "INFO:tensorflow:step = 31901, loss = 0.00079322 (0.470 sec)\n",
      "INFO:tensorflow:global_step/sec: 198.834\n",
      "INFO:tensorflow:step = 32001, loss = 0.000262161 (0.504 sec)\n",
      "INFO:tensorflow:global_step/sec: 182.364\n",
      "INFO:tensorflow:step = 32101, loss = 0.000368648 (0.549 sec)\n",
      "INFO:tensorflow:global_step/sec: 188.08\n",
      "INFO:tensorflow:step = 32201, loss = 0.00113988 (0.531 sec)\n",
      "INFO:tensorflow:global_step/sec: 184.35\n",
      "INFO:tensorflow:step = 32301, loss = 0.00038782 (0.544 sec)\n",
      "INFO:tensorflow:global_step/sec: 182.769\n",
      "INFO:tensorflow:step = 32401, loss = 0.000149349 (0.545 sec)\n",
      "INFO:tensorflow:global_step/sec: 198.102\n",
      "INFO:tensorflow:step = 32501, loss = 0.000642526 (0.504 sec)\n",
      "INFO:tensorflow:global_step/sec: 188.632\n",
      "INFO:tensorflow:step = 32601, loss = 0.000118947 (0.531 sec)\n",
      "INFO:tensorflow:global_step/sec: 170.969\n",
      "INFO:tensorflow:step = 32701, loss = 0.00136909 (0.589 sec)\n",
      "INFO:tensorflow:global_step/sec: 187.113\n",
      "INFO:tensorflow:step = 32801, loss = 0.00105548 (0.530 sec)\n",
      "INFO:tensorflow:global_step/sec: 210.662\n",
      "INFO:tensorflow:step = 32901, loss = 0.0003802 (0.477 sec)\n",
      "INFO:tensorflow:global_step/sec: 172.849\n",
      "INFO:tensorflow:step = 33001, loss = 0.000608995 (0.576 sec)\n",
      "INFO:tensorflow:global_step/sec: 185.058\n",
      "INFO:tensorflow:step = 33101, loss = 0.0019107 (0.541 sec)\n",
      "INFO:tensorflow:global_step/sec: 186.275\n",
      "INFO:tensorflow:step = 33201, loss = 0.000916178 (0.537 sec)\n",
      "INFO:tensorflow:global_step/sec: 212.533\n",
      "INFO:tensorflow:step = 33301, loss = 0.000244862 (0.470 sec)\n",
      "INFO:tensorflow:global_step/sec: 196.638\n",
      "INFO:tensorflow:step = 33401, loss = 0.00129239 (0.509 sec)\n",
      "INFO:tensorflow:global_step/sec: 174.287\n",
      "INFO:tensorflow:step = 33501, loss = 0.000242947 (0.576 sec)\n",
      "INFO:tensorflow:global_step/sec: 168.569\n",
      "INFO:tensorflow:step = 33601, loss = 0.000883703 (0.591 sec)\n",
      "INFO:tensorflow:global_step/sec: 150.886\n",
      "INFO:tensorflow:step = 33701, loss = 0.000904791 (0.670 sec)\n",
      "INFO:tensorflow:global_step/sec: 186.526\n",
      "INFO:tensorflow:step = 33801, loss = 0.00107614 (0.530 sec)\n",
      "INFO:tensorflow:global_step/sec: 155.071\n",
      "INFO:tensorflow:step = 33901, loss = 0.00107961 (0.644 sec)\n",
      "INFO:tensorflow:global_step/sec: 212.628\n",
      "INFO:tensorflow:step = 34001, loss = 0.000613074 (0.470 sec)\n",
      "INFO:tensorflow:global_step/sec: 209.47\n",
      "INFO:tensorflow:step = 34101, loss = 0.00085227 (0.478 sec)\n",
      "INFO:tensorflow:global_step/sec: 184.8\n",
      "INFO:tensorflow:step = 34201, loss = 0.00112095 (0.541 sec)\n",
      "INFO:tensorflow:global_step/sec: 192.841\n",
      "INFO:tensorflow:step = 34301, loss = 0.000104322 (0.522 sec)\n",
      "INFO:tensorflow:global_step/sec: 134.156\n",
      "INFO:tensorflow:step = 34401, loss = 0.000506521 (0.742 sec)\n",
      "INFO:tensorflow:global_step/sec: 202.907\n",
      "INFO:tensorflow:step = 34501, loss = 0.000799231 (0.493 sec)\n",
      "INFO:tensorflow:global_step/sec: 182.842\n",
      "INFO:tensorflow:step = 34601, loss = 0.000381998 (0.547 sec)\n",
      "INFO:tensorflow:global_step/sec: 193.183\n",
      "INFO:tensorflow:step = 34701, loss = 0.00197285 (0.518 sec)\n",
      "INFO:tensorflow:global_step/sec: 191.031\n",
      "INFO:tensorflow:step = 34801, loss = 0.00050132 (0.525 sec)\n",
      "INFO:tensorflow:global_step/sec: 200.765\n",
      "INFO:tensorflow:step = 34901, loss = 0.000430059 (0.496 sec)\n",
      "INFO:tensorflow:global_step/sec: 194.674\n",
      "INFO:tensorflow:step = 35001, loss = 0.000284109 (0.515 sec)\n",
      "INFO:tensorflow:global_step/sec: 222.426\n",
      "INFO:tensorflow:step = 35101, loss = 0.0012278 (0.450 sec)\n",
      "INFO:tensorflow:global_step/sec: 195.044\n",
      "INFO:tensorflow:step = 35201, loss = 0.000280491 (0.513 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.509\n",
      "INFO:tensorflow:step = 35301, loss = 0.000161269 (0.499 sec)\n",
      "INFO:tensorflow:global_step/sec: 162.089\n",
      "INFO:tensorflow:step = 35401, loss = 0.00105551 (0.628 sec)\n",
      "INFO:tensorflow:global_step/sec: 126.497\n",
      "INFO:tensorflow:step = 35501, loss = 0.000203097 (0.779 sec)\n",
      "INFO:tensorflow:global_step/sec: 202.277\n",
      "INFO:tensorflow:step = 35601, loss = 0.000242335 (0.495 sec)\n",
      "INFO:tensorflow:global_step/sec: 166.981\n",
      "INFO:tensorflow:step = 35701, loss = 0.00086094 (0.598 sec)\n",
      "INFO:tensorflow:global_step/sec: 182.908\n",
      "INFO:tensorflow:step = 35801, loss = 0.000918586 (0.547 sec)\n",
      "INFO:tensorflow:global_step/sec: 222.44\n",
      "INFO:tensorflow:step = 35901, loss = 0.000671677 (0.450 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.685\n",
      "INFO:tensorflow:step = 36001, loss = 0.000370165 (0.502 sec)\n",
      "INFO:tensorflow:global_step/sec: 147.789\n",
      "INFO:tensorflow:step = 36101, loss = 0.00120145 (0.676 sec)\n",
      "INFO:tensorflow:global_step/sec: 208.581\n",
      "INFO:tensorflow:step = 36201, loss = 0.000768125 (0.480 sec)\n",
      "INFO:tensorflow:global_step/sec: 189.123\n",
      "INFO:tensorflow:step = 36301, loss = 0.000106661 (0.528 sec)\n",
      "INFO:tensorflow:global_step/sec: 164.88\n",
      "INFO:tensorflow:step = 36401, loss = 0.000681248 (0.611 sec)\n",
      "INFO:tensorflow:global_step/sec: 148.579\n",
      "INFO:tensorflow:step = 36501, loss = 0.000214154 (0.669 sec)\n",
      "INFO:tensorflow:global_step/sec: 163.743\n",
      "INFO:tensorflow:step = 36601, loss = 0.000239673 (0.610 sec)\n",
      "INFO:tensorflow:global_step/sec: 166.603\n",
      "INFO:tensorflow:step = 36701, loss = 0.000405055 (0.600 sec)\n",
      "INFO:tensorflow:global_step/sec: 211.384\n",
      "INFO:tensorflow:step = 36801, loss = 0.000852568 (0.474 sec)\n",
      "INFO:tensorflow:global_step/sec: 190.995\n",
      "INFO:tensorflow:step = 36901, loss = 0.000667005 (0.524 sec)\n",
      "INFO:tensorflow:global_step/sec: 198.084\n",
      "INFO:tensorflow:step = 37001, loss = 0.000488099 (0.505 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.847\n",
      "INFO:tensorflow:step = 37101, loss = 0.000311534 (0.482 sec)\n",
      "INFO:tensorflow:global_step/sec: 137.141\n",
      "INFO:tensorflow:step = 37201, loss = 0.000358862 (0.729 sec)\n",
      "INFO:tensorflow:global_step/sec: 176.969\n",
      "INFO:tensorflow:step = 37301, loss = 0.000707558 (0.565 sec)\n",
      "INFO:tensorflow:global_step/sec: 194.922\n",
      "INFO:tensorflow:step = 37401, loss = 0.000318062 (0.513 sec)\n",
      "INFO:tensorflow:global_step/sec: 176.448\n",
      "INFO:tensorflow:step = 37501, loss = 0.000298998 (0.568 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.565\n",
      "INFO:tensorflow:step = 37601, loss = 0.000414938 (0.500 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.56\n",
      "INFO:tensorflow:step = 37701, loss = 0.000145852 (0.487 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.723\n",
      "INFO:tensorflow:step = 37801, loss = 0.000346428 (0.483 sec)\n",
      "INFO:tensorflow:global_step/sec: 189.979\n",
      "INFO:tensorflow:step = 37901, loss = 0.0015781 (0.527 sec)\n",
      "INFO:tensorflow:global_step/sec: 168.246\n",
      "INFO:tensorflow:step = 38001, loss = 0.000307783 (0.594 sec)\n",
      "INFO:tensorflow:global_step/sec: 185.32\n",
      "INFO:tensorflow:step = 38101, loss = 0.00120952 (0.539 sec)\n",
      "INFO:tensorflow:global_step/sec: 195.911\n",
      "INFO:tensorflow:step = 38201, loss = 0.000719946 (0.510 sec)\n",
      "INFO:tensorflow:global_step/sec: 153.341\n",
      "INFO:tensorflow:step = 38301, loss = 9.19537e-05 (0.653 sec)\n",
      "INFO:tensorflow:global_step/sec: 180.301\n",
      "INFO:tensorflow:step = 38401, loss = 0.000204637 (0.555 sec)\n",
      "INFO:tensorflow:global_step/sec: 154.679\n",
      "INFO:tensorflow:step = 38501, loss = 0.000502236 (0.653 sec)\n",
      "INFO:tensorflow:global_step/sec: 158.169\n",
      "INFO:tensorflow:step = 38601, loss = 0.000743682 (0.628 sec)\n",
      "INFO:tensorflow:global_step/sec: 147.676\n",
      "INFO:tensorflow:step = 38701, loss = 0.000451052 (0.674 sec)\n",
      "INFO:tensorflow:global_step/sec: 182.601\n",
      "INFO:tensorflow:step = 38801, loss = 0.000246905 (0.548 sec)\n",
      "INFO:tensorflow:global_step/sec: 117.129\n",
      "INFO:tensorflow:step = 38901, loss = 0.00129647 (0.856 sec)\n",
      "INFO:tensorflow:global_step/sec: 143.227\n",
      "INFO:tensorflow:step = 39001, loss = 0.000217024 (0.703 sec)\n",
      "INFO:tensorflow:global_step/sec: 170.023\n",
      "INFO:tensorflow:step = 39101, loss = 0.000741188 (0.583 sec)\n",
      "INFO:tensorflow:global_step/sec: 139.532\n",
      "INFO:tensorflow:step = 39201, loss = 0.000570652 (0.718 sec)\n",
      "INFO:tensorflow:global_step/sec: 141.798\n",
      "INFO:tensorflow:step = 39301, loss = 0.000307514 (0.704 sec)\n",
      "INFO:tensorflow:global_step/sec: 178.597\n",
      "INFO:tensorflow:step = 39401, loss = 0.00066551 (0.561 sec)\n",
      "INFO:tensorflow:global_step/sec: 181.208\n",
      "INFO:tensorflow:step = 39501, loss = 0.000248625 (0.551 sec)\n",
      "INFO:tensorflow:global_step/sec: 142.848\n",
      "INFO:tensorflow:step = 39601, loss = 0.000750375 (0.702 sec)\n",
      "INFO:tensorflow:global_step/sec: 115.437\n",
      "INFO:tensorflow:step = 39701, loss = 0.000224784 (0.865 sec)\n",
      "INFO:tensorflow:global_step/sec: 145.846\n",
      "INFO:tensorflow:step = 39801, loss = 0.00105966 (0.683 sec)\n",
      "INFO:tensorflow:global_step/sec: 136.104\n",
      "INFO:tensorflow:step = 39901, loss = 0.00136582 (0.739 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 40000 into /var/folders/b1/6r6n8ptx4r9cq1rvs075k7j00000gn/T/tmp7felyjwd/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.00045437.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SKCompat()"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "config = tf.contrib.learn.RunConfig(tf_random_seed=42) # not shown in the config\n",
    "\n",
    "feature_cols = tf.contrib.learn.infer_real_valued_columns_from_input(X_train)\n",
    "dnn_clf = tf.contrib.learn.DNNClassifier(hidden_units=[300,100], n_classes=10,\n",
    "                                         feature_columns=feature_cols, config=config)\n",
    "dnn_clf = tf.contrib.learn.SKCompat(dnn_clf) # if TensorFlow >= 1.1\n",
    "dnn_clf.fit(X_train, y_train, batch_size=50, steps=40000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /var/folders/b1/6r6n8ptx4r9cq1rvs075k7j00000gn/T/tmp7felyjwd/model.ckpt-40000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.98240000000000005"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = dnn_clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred['classes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.071563045266568537"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "\n",
    "y_pred_proba = y_pred['probabilities']\n",
    "log_loss(y_test, y_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Log Loss Scoring function [http://wiki.fast.ai/index.php/Log_Loss]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이 코드를 MNIST 데이터 세트에서 실행하면 (예 : Scikit-Learn의 StandardScaler를 사용하여 스케일링 한 후) 실제로 테스트 세트에서 98.1 % 이상의 정확도를 달성하는 모델을 얻을 수 있습니다! 3 장에서 훈련 한 최고의 모델보다 낫습니다.\n",
    "\n",
    "- TF.Learn 라이브러리는 모델을 평가할 수있는 편리한 함수를 제공합니다.\n",
    "\n",
    "- DNNClassifier 클래스는 ReLU 활성화 함수 (activation_fn 하이퍼 파라미터를 설정하여 변경할 수 있음)를 기반으로 모든 뉴런 레이어를 만듭니다. 출력 계층은 softmax 함수에 의존하고 비용 함수는 교차 엔트로피 (4 장에서 소개함)입니다.\n",
    "\n",
    "- TF.Learn API (및 TensorFlow는 일반적으로)가 아직 완전히 새롭기 때문에이 예제에서 사용 된 일부 이름과 함수는이 책을 읽을 때 조금 발전 할 수 있습니다. 그러나 일반적인 생각은 변하지 않아야 합니다.\n",
    "\n",
    "### Training a DNN using plain TensorFlow\n",
    "\n",
    "- 네트워크 아키텍처를보다 잘 제어하려면 TensorFlow의 하위 레벨 Python API (9 장에서 소개 함)를 사용하는 것이 좋습니다. 이 섹션에서는이 API를 사용하여 위와 동일한 모델을 구축하고 Mini-batch Gradient Descent를 구현하여 MNIST 데이터 세트에서이를 학습합니다. \n",
    "\n",
    "- 첫 번째 단계는 TensorFlow 그래프를 작성하는 것입니다. 이것이 건설 단계입니다. 두 번째 단계는 실행 단계입니다. 여기서 실제로 그래프를 실행하여 모델을 교육합니다.\n",
    "\n",
    "\n",
    "#### Construction phase\n",
    "- 시작하자. 먼저 tensorflow 라이브러리를 가져와야합니다. 그런 다음 입력 및 출력 수를 지정하고 각 계층에서 숨겨진 뉴런 수를 설정해야합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_inputs = 28*28  # MNIST\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_outputs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 다음으로 9 장에서했던 것처럼 자리 표시 자 노드를 사용하여 훈련 데이터와 대상을 나타낼 수 있습니다. X의 모양은 부분적으로 만 정의됩니다. 2D 텐서 (즉, 행렬)이고, 첫 번째 차원을 따라 인스턴스가 있고 두 번째 차원을 따라 특징이 있음을 알 수 있습니다.\n",
    "\n",
    "- 피쳐 수가 28x28이 될 것입니다. (픽셀 당 하나의 기능) 그러나 각 훈련 배치에 얼마나 많은 인스턴스가 포함되는지는 아직 알 수 없습니다. 그래서 X의 모양은 (None, n_inputs)입니다. \n",
    "\n",
    "- 마찬가지로 y는 인스턴스 당 하나의 엔트리를 가진 1D 텐서가되지만이 시점에서 트레이닝 배치의 크기를 알 수 없기 때문에 모양은 (없음)입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int64, shape=(None), name=\"y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이제 실제 신경망을 만들어 보겠습니다. 자리 표시 자 X는 입력 레이어로 작동합니다. 실행 단계에서 한 번에 하나의 훈련 배치로 대체됩니다 (훈련 배치의 모든 인스턴스는 신경 네트워크에서 동시에 처리됩니다). \n",
    "\n",
    "- 이제 두 개의 숨겨진 레이어와 출력 레이어를 만들어야합니다. 숨겨진 두 레이어는 거의 동일합니다. 연결되는 입력과 포함 된 뉴런의 수에 따라 다릅니다. \n",
    "\n",
    "- 출력 계층도 매우 유사하지만 ReLU 활성화 기능 대신 softmax 활성화 기능을 사용합니다. 한 번에 하나의 레이어를 만드는 데 사용할 neuron_layer() 함수를 만듭니다. 입력, 뉴런 수, 활성화 함수 및 레이어 이름을 지정하는 매개 변수가 필요합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def neuron_layer(X, n_neurons, name, activation=None):\n",
    "    with tf.name_scope(name):\n",
    "        n_inputs = int(X.get_shape()[1])\n",
    "        stddev = 2 / np.sqrt(n_inputs)\n",
    "        init = tf.truncated_normal((n_inputs, n_neurons), stddev=stddev)\n",
    "        W = tf.Variable(init, name=\"kernel\")\n",
    "        b = tf.Variable(tf.zeros([n_neurons]), name=\"bias\")\n",
    "        Z = tf.matmul(X, W) + b\n",
    "        if activation is not None:\n",
    "            return activation(Z)\n",
    "        else:\n",
    "            return Z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 먼저 계층 이름을 사용하여 이름 범위를 만듭니다. 이름 영역에는 신경 층에 대한 모든 계산 노드가 포함됩니다. 이것은 선택 사항이지만 노드가 잘 구성되어 있으면 그래프가 TensorBoard에서 훨씬 더 멋지게 보입니다.\n",
    "\n",
    "- 다음으로 입력 행렬의 모양을 찾고 두 번째 차원의 크기를 가져 와서 입력 수를 얻습니다 (첫 번째 차원은 인스턴스 용입니다).\n",
    "\n",
    "- 다음 세 줄은 가중치 행렬을 저장할 W 변수를 만듭니다. 그것은 각 입력과 각 뉴런 사이의 모든 연결 가중치를 포함하는 2D 텐서가 될 것이므로 그 모양은 (n_inputs, n_neurons)가 될 것입니다. \n",
    "\n",
    "- 표준 편차가 2 / ninputs 인 잘린 일반 (가우스) 분포를 사용하여 임의로 초기화됩니다. 특정 표준 편차를 사용하면 알고리즘이 훨씬 빨리 수렴하는 데 도움이됩니다 (11 장에서 더 자세히 논의 할 것입니다. 효율성에 엄청난 영향을 미친 신경망에 대한 작은 조정 중 하나입니다.)\n",
    "\n",
    "- Gradient Descent 알고리즘이 깨질 수 없는 대칭을 피하려면 모든 숨겨진 레이어에 대해 연결 가중치를 임의로 초기화하는 것이 중요합니다.\n",
    "\n",
    "- 다음 줄은 바이어스에 대한 b 변수를 만듭니다.이 변수는 뉴런 당 하나의 바이어스 매개 변수를 사용하여 0으로 초기화됩니다 (이 경우 대칭 문제 없음).\n",
    "\n",
    "- 그런 다음 우리는 == +를 계산할 부분 그래프를 만듭니다. 이 벡터화 된 구현은 한 번에 배치의 모든 인스턴스에 대해 입력의 가중치 합계와 레이어의 각 뉴런에 대한 바이어스 조건을 효율적으로 계산합니다.\n",
    "\n",
    "- 마지막으로 활성화 매개 변수가 \"relu\"로 설정된 경우 relu(z) (즉, max 0,)를 반환하거나 아니면 z를 반환합니다.\n",
    "\n",
    "- 자, 이제 당신은 뉴런 레이어를 생성하는 좋은 기능을 가지고 있습니다. 딥 뉴럴 네트워크 (Deep Neural Network)를 만드는 데 사용합시다! 첫 번째 숨겨진 계층은 X를 입력으로 사용합니다. 두 번째는 첫 번째 숨겨진 레이어의 출력을 입력으로 사용합니다. 마지막으로 출력 레이어는 두 번째 숨겨진 레이어의 출력을 입력으로 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = neuron_layer(X, n_hidden1, name=\"hidden1\",\n",
    "                           activation=tf.nn.relu)\n",
    "    hidden2 = neuron_layer(hidden1, n_hidden2, name=\"hidden2\",\n",
    "                           activation=tf.nn.relu)\n",
    "    logits = neuron_layer(hidden2, n_outputs, name=\"outputs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 다시 한번 우리는 명확성을 위해 이름 범위를 사용했습니다. 또한 logits는 softmax 활성화 함수를 거치기 전에 신경망의 출력입니다. 최적화를 위해 나중에 softmax 계산을 처리 할 것입니다.\n",
    "\n",
    "- 예상대로 TensorFlow에는 표준 신경망 레이어를 만드는 데 유용한 많은 기능이 있습니다. 우리가 방금 한 것처럼 자신의 neuron_layer() 함수를 정의 할 필요가 없는 경우가 종종 있습니다. 예를 들어, TensorFlow의 fully_connected() 함수는 완전히 연결된 레이어를 만듭니다. \n",
    "\n",
    "- 여기서 모든 입력은 레이어의 모든 뉴런에 연결됩니다. 적절한 초기화 전략을 사용하여 가중치 및 바이어스 변수를 작성하고 기본으로 ReLU 활성화 기능을 사용합니다 (activation_fn 인수를 사용하여 변경할 수 있음).\n",
    "\n",
    "- 11 장에서 볼 수 있듯이 정규화 및 정규화 매개 변수도 지원합니다. neuron_layer() 함수 대신에 fully_connected() 함수를 사용하기 위해 위의 코드를 조정 해보자. 함수를 가져 와서 dnn 생성 섹션을 다음 코드로 바꿉니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이제 우리는 신경망 모델을 사용할 준비가되었습니다. 우리는 이를 훈련시키는 데 사용할 비용 함수를 정의해야합니다.\n",
    "\n",
    "- 우리가 제 4 장에서 softmax 회귀를했던 것과 마찬가지로 교차 엔트로피를 사용할 것입니다. 앞서 논의한 것처럼 교차 엔트로피는 목표 클래스에 대한 낮은 확률을 추정하는 모델에 불이익을줍니다. \n",
    "\n",
    "- TensorFlow는 교차 엔트로피를 계산하는 몇 가지 기능을 제공합니다. \n",
    "\n",
    "- 우리는 sparse_soft max_cross_entropy_with_logits()를 사용할 것입니다 : \"logits\"(즉, softmax 활성화 함수를 거치기 전에 네트워크의 출력)를 기준으로 교차 엔트로피를 계산합니다. \n",
    "\n",
    "- 그리고 0에서부터 클래스 수 - 1 (우리의 경우 0에서 9). 이것은 각 인스턴스에 대해 교차 엔트로피를 포함하는 1D 텐서를 제공합니다. 그런 다음 TensorFlow의 reduce_mean() 함수를 사용하여 모든 인스턴스에 대한 평균 교차 엔트로피를 계산할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y,\n",
    "                                                              logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- sparse_softmax_cross_entropy_with_logits() 함수는 softmax 활성화 함수를 적용한 다음 크로스 엔트로피를 계산하는 것과 같습니다.\n",
    "\n",
    "- 하지만 더 효율적이며 0 인 로그와 같은 모서리 사례를 적절히 처리합니다. 따라서 softmax 활성화 함수를 적용하지 않은 이유가 여기에 있습니다 일찍이. softmax_cross_entropy_with_logits ()라는 또 다른 함수가 있습니다.이 함수는 0에서부터 클래스 수 -1까지의 int 대신에 하나의 핫 벡터 형식으로 레이블을 사용합니다.\n",
    "\n",
    "- 우리는 신경망 모델을 가지고 있고 비용 함수를 가지고 있습니다. 이제 비용 함수를 최소화하기 위해 모델 매개 변수를 조정할 GradientDescentOptimizer를 정의해야 합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 구축 단계의 마지막 중요한 단계는 모델을 평가하는 방법을 지정하는 것입니다. \n",
    "\n",
    "- 우리는 단순히 성능 척도로서 정확도를 사용합니다.\n",
    "\n",
    "- 첫째, 각 인스턴스에 대해 가장 높은 로짓이 목표 클래스에 해당하는지 여부를 확인하여 신경망의 예측이 올바른지 확인합니다. 이를 위해 in_top_k () 함수를 사용할 수 있습니다. 부울 값으로 가득 찬 1D 텐서를 반환합니다.\n",
    "\n",
    "- 이 부울을 부동 소수점에 캐스팅 한 다음 평균을 계산해야합니다. 이렇게하면 네트워크의 전체적인 정확성을 얻을 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 평소처럼 모든 변수를 초기화하는 노드를 만들어야하며 훈련 된 모델 매개 변수를 디스크에 저장하는 Saver도 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 휴! 이것으로 건설 단계가 끝납니다. 이것은 40 줄 미만의 코드 였지만 입력 및 대상에 대한 자리 표시자를 만들고 뉴런 층을 작성하는 함수를 만들고 DNN을 만들기 위해 사용했으며 비용 함수를 정의했습니다. \n",
    "\n",
    "- 최적화 도구를 만들고 마지막으로 성능 측정 값을 정의했습니다. 이제 실행 단계로 넘어갑니다.\n",
    "\n",
    "### Execution phase\n",
    "\n",
    "- 이 부분은 훨씬 더 짧고 간단합니다. 우선, MNIST를로드 해 봅시다. 우리는 이전 장에서했던 것처럼 Scikit- Learn를 사용할 수 있었지만 TensorFlow는 데이터를 가져오고 (0에서 1 사이의) 크기를 조정하고 셔플 링하며 하나의 미니 배치를로드하는 간단한 함수를 제공하는 자체 도우미를 제공합니다. 시간. 그래서 대신 사용하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_epochs = 40\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train accuracy: 0.9 Test accuracy: 0.9128\n",
      "1 Train accuracy: 0.94 Test accuracy: 0.9291\n",
      "2 Train accuracy: 0.92 Test accuracy: 0.9398\n",
      "3 Train accuracy: 0.96 Test accuracy: 0.945\n",
      "4 Train accuracy: 0.92 Test accuracy: 0.9513\n",
      "5 Train accuracy: 0.94 Test accuracy: 0.9543\n",
      "6 Train accuracy: 0.98 Test accuracy: 0.9556\n",
      "7 Train accuracy: 0.96 Test accuracy: 0.9593\n",
      "8 Train accuracy: 0.92 Test accuracy: 0.9625\n",
      "9 Train accuracy: 0.96 Test accuracy: 0.9645\n",
      "10 Train accuracy: 0.98 Test accuracy: 0.9651\n",
      "11 Train accuracy: 0.94 Test accuracy: 0.967\n",
      "12 Train accuracy: 1.0 Test accuracy: 0.9691\n",
      "13 Train accuracy: 0.94 Test accuracy: 0.9684\n",
      "14 Train accuracy: 1.0 Test accuracy: 0.9697\n",
      "15 Train accuracy: 1.0 Test accuracy: 0.9714\n",
      "16 Train accuracy: 1.0 Test accuracy: 0.9714\n",
      "17 Train accuracy: 0.98 Test accuracy: 0.9715\n",
      "18 Train accuracy: 1.0 Test accuracy: 0.973\n",
      "19 Train accuracy: 1.0 Test accuracy: 0.973\n",
      "20 Train accuracy: 0.98 Test accuracy: 0.9736\n",
      "21 Train accuracy: 1.0 Test accuracy: 0.974\n",
      "22 Train accuracy: 1.0 Test accuracy: 0.9745\n",
      "23 Train accuracy: 1.0 Test accuracy: 0.9749\n",
      "24 Train accuracy: 1.0 Test accuracy: 0.975\n",
      "25 Train accuracy: 1.0 Test accuracy: 0.9756\n",
      "26 Train accuracy: 1.0 Test accuracy: 0.975\n",
      "27 Train accuracy: 1.0 Test accuracy: 0.9759\n",
      "28 Train accuracy: 0.98 Test accuracy: 0.976\n",
      "29 Train accuracy: 1.0 Test accuracy: 0.9768\n",
      "30 Train accuracy: 1.0 Test accuracy: 0.9766\n",
      "31 Train accuracy: 1.0 Test accuracy: 0.9769\n",
      "32 Train accuracy: 0.98 Test accuracy: 0.9768\n",
      "33 Train accuracy: 0.98 Test accuracy: 0.9764\n",
      "34 Train accuracy: 0.98 Test accuracy: 0.9788\n",
      "35 Train accuracy: 0.98 Test accuracy: 0.9776\n",
      "36 Train accuracy: 0.98 Test accuracy: 0.977\n",
      "37 Train accuracy: 1.0 Test accuracy: 0.9785\n",
      "38 Train accuracy: 1.0 Test accuracy: 0.9784\n",
      "39 Train accuracy: 1.0 Test accuracy: 0.9782\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(mnist.train.num_examples // batch_size):\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_train = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_test = accuracy.eval(feed_dict={X: mnist.test.images,\n",
    "                                            y: mnist.test.labels})\n",
    "        print(epoch, \"Train accuracy:\", acc_train, \"Test accuracy:\", acc_test)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이제 실행하려는 에포크의 수와 미니 배치의 크기를 정의합니다.\n",
    "\n",
    "- 이 코드는 TensorFlow 세션을 열고 모든 변수를 초기화하는 init 노드를 실행합니다. 그런 다음 기본 교육 루프를 실행합니다. \n",
    "\n",
    "- 각 신기원에서 코드는 훈련 세트 크기에 해당하는 여러 가지 미니 배치를 반복합니다. \n",
    "\n",
    "- 각 미니 배치는 next_batch() 메소드를 사용하여 가져오고, 코드는 현재 트레이닝 작업을 실행하고 현재 미니 배치 입력 데이터와 대상을 제공합니다. 다음으로, 각 에포크의 끝에서 코드는 마지막 미니 배치 및 전체 학습 세트에서 모델을 평가하고 결과를 인쇄합니다. 마지막으로 모델 매개 변수가 디스크에 저장됩니다.\n",
    "\n",
    "### Using the neural network\n",
    "\n",
    "- 신경 네트워크가 훈련되었으므로 예측을 위해 사용할 수 있습니다. 그렇게하기 위해 동일한 구성 단계를 재사용 할 수 있지만 다음과 같이 실행 단계를 변경하십시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_model_final.ckpt\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./my_model_final.ckpt\") # or better, use save_path\n",
    "    X_new_scaled = mnist.test.images[:20]\n",
    "    Z = logits.eval(feed_dict={X: X_new_scaled})\n",
    "    y_pred = np.argmax(Z, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 먼저 코드는 디스크에서 모델 매개 변수를 로드합니다. 다음 분류 할 새 이미지를 로드합니다. 트레이닝 데이터와 동일한 피쳐 스케일링을 적용해야합니다 (이 경우, 0에서 1로 스케일).\n",
    "\n",
    "- 그런 다음 코드는 logits 노드를 평가합니다. 모든 예상 클래스 확률을 알고 싶다면 softmax () 함수를 logits에 적용해야하지만 클래스를 예측하려는 경우 가장 높은 logit 값을 가진 클래스를 선택할 수 있습니다 ( argmax () 함수는 트릭을 수행한다. 신경망 하이퍼 매개 변수 미세 조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted classes: [7 2 1 0 4 1 4 9 6 9 0 6 9 0 1 5 9 7 3 4]\n",
      "Actual classes:    [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4]\n"
     ]
    }
   ],
   "source": [
    "print(\"Predicted classes:\", y_pred)\n",
    "print(\"Actual classes:   \", mnist.test.labels[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output, Image, display, HTML\n",
    "\n",
    "def strip_consts(graph_def, max_const_size=32):\n",
    "    \"\"\"Strip large constant values from graph_def.\"\"\"\n",
    "    strip_def = tf.GraphDef()\n",
    "    for n0 in graph_def.node:\n",
    "        n = strip_def.node.add() \n",
    "        n.MergeFrom(n0)\n",
    "        if n.op == 'Const':\n",
    "            tensor = n.attr['value'].tensor\n",
    "            size = len(tensor.tensor_content)\n",
    "            if size > max_const_size:\n",
    "                tensor.tensor_content = b\"<stripped %d bytes>\"%size\n",
    "    return strip_def\n",
    "\n",
    "def show_graph(graph_def, max_const_size=32):\n",
    "    \"\"\"Visualize TensorFlow graph.\"\"\"\n",
    "    if hasattr(graph_def, 'as_graph_def'):\n",
    "        graph_def = graph_def.as_graph_def()\n",
    "    strip_def = strip_consts(graph_def, max_const_size=max_const_size)\n",
    "    code = \"\"\"\n",
    "        <script>\n",
    "          function load() {{\n",
    "            document.getElementById(\"{id}\").pbtxt = {data};\n",
    "          }}\n",
    "        </script>\n",
    "        <link rel=\"import\" href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\" onload=load()>\n",
    "        <div style=\"height:600px\">\n",
    "          <tf-graph-basic id=\"{id}\"></tf-graph-basic>\n",
    "        </div>\n",
    "    \"\"\".format(data=repr(str(strip_def)), id='graph'+str(np.random.rand()))\n",
    "\n",
    "    iframe = \"\"\"\n",
    "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"{}\"></iframe>\n",
    "    \"\"\".format(code.replace('\"', '&quot;'))\n",
    "    display(HTML(iframe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"\n",
       "        <script>\n",
       "          function load() {\n",
       "            document.getElementById(&quot;graph0.08185155632074148&quot;).pbtxt = 'node {\\n  name: &quot;X&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: -1\\n        }\\n        dim {\\n          size: 784\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;y&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        unknown_rank: true\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/kernel/Initializer/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\020\\\\003\\\\000\\\\000,\\\\001\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/kernel/Initializer/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -0.07439795136451721\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/kernel/Initializer/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.07439795136451721\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;hidden1/kernel/Initializer/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 42\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 5\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/kernel/Initializer/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;hidden1/kernel/Initializer/random_uniform/max&quot;\\n  input: &quot;hidden1/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/kernel/Initializer/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;hidden1/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  input: &quot;hidden1/kernel/Initializer/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/kernel/Initializer/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;hidden1/kernel/Initializer/random_uniform/mul&quot;\\n  input: &quot;hidden1/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/kernel&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 784\\n        }\\n        dim {\\n          size: 300\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/kernel/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden1/kernel&quot;\\n  input: &quot;hidden1/kernel/Initializer/random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/kernel/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;hidden1/kernel&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/bias/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 300\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/bias&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 300\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/bias/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden1/bias&quot;\\n  input: &quot;hidden1/bias/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/bias/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;hidden1/bias&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden1/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;X&quot;\\n  input: &quot;hidden1/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden1/BiasAdd&quot;\\n  op: &quot;BiasAdd&quot;\\n  input: &quot;dnn/hidden1/MatMul&quot;\\n  input: &quot;hidden1/bias/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden1/Relu&quot;\\n  op: &quot;Relu&quot;\\n  input: &quot;dnn/hidden1/BiasAdd&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/kernel/Initializer/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;,\\\\001\\\\000\\\\000d\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/kernel/Initializer/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -0.12247448414564133\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/kernel/Initializer/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.12247448414564133\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;hidden2/kernel/Initializer/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 42\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 22\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/kernel/Initializer/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;hidden2/kernel/Initializer/random_uniform/max&quot;\\n  input: &quot;hidden2/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/kernel/Initializer/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;hidden2/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  input: &quot;hidden2/kernel/Initializer/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/kernel/Initializer/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;hidden2/kernel/Initializer/random_uniform/mul&quot;\\n  input: &quot;hidden2/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/kernel&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 300\\n        }\\n        dim {\\n          size: 100\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/kernel/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden2/kernel&quot;\\n  input: &quot;hidden2/kernel/Initializer/random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/kernel/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;hidden2/kernel&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/bias/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 100\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/bias&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 100\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/bias/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden2/bias&quot;\\n  input: &quot;hidden2/bias/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/bias/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;hidden2/bias&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden2/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;dnn/hidden1/Relu&quot;\\n  input: &quot;hidden2/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden2/BiasAdd&quot;\\n  op: &quot;BiasAdd&quot;\\n  input: &quot;dnn/hidden2/MatMul&quot;\\n  input: &quot;hidden2/bias/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden2/Relu&quot;\\n  op: &quot;Relu&quot;\\n  input: &quot;dnn/hidden2/BiasAdd&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/kernel/Initializer/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;d\\\\000\\\\000\\\\000\\\\n\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/kernel/Initializer/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -0.23354968428611755\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/kernel/Initializer/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.23354968428611755\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;outputs/kernel/Initializer/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 42\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 39\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/kernel/Initializer/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;outputs/kernel/Initializer/random_uniform/max&quot;\\n  input: &quot;outputs/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/kernel/Initializer/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;outputs/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  input: &quot;outputs/kernel/Initializer/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/kernel/Initializer/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;outputs/kernel/Initializer/random_uniform/mul&quot;\\n  input: &quot;outputs/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/kernel&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 100\\n        }\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/kernel/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;outputs/kernel&quot;\\n  input: &quot;outputs/kernel/Initializer/random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/kernel/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;outputs/kernel&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/bias/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 10\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/bias&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/bias/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;outputs/bias&quot;\\n  input: &quot;outputs/bias/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/bias/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;outputs/bias&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/outputs/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;dnn/hidden2/Relu&quot;\\n  input: &quot;outputs/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/outputs/BiasAdd&quot;\\n  op: &quot;BiasAdd&quot;\\n  input: &quot;dnn/outputs/MatMul&quot;\\n  input: &quot;outputs/bias/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/SparseSoftmaxCrossEntropyWithLogits/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits&quot;\\n  op: &quot;SparseSoftmaxCrossEntropyWithLogits&quot;\\n  input: &quot;dnn/outputs/BiasAdd&quot;\\n  input: &quot;y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tlabels&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/loss&quot;\\n  op: &quot;Mean&quot;\\n  input: &quot;loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits&quot;\\n  input: &quot;loss/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Fill&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;train/gradients/Shape&quot;\\n  input: &quot;train/gradients/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Reshape/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/Fill&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Reshape/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Tile&quot;\\n  op: &quot;Tile&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Reshape&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tmultiples&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Shape_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Prod&quot;\\n  op: &quot;Prod&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Shape_1&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Prod_1&quot;\\n  op: &quot;Prod&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Shape_2&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Const_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Maximum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Maximum&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Prod_1&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Maximum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/floordiv&quot;\\n  op: &quot;FloorDiv&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Prod&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Maximum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Cast&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;train/gradients/loss/loss_grad/floordiv&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/truediv&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Tile&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Cast&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/zeros_like&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/PreventGradient&quot;\\n  op: &quot;PreventGradient&quot;\\n  input: &quot;loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;message&quot;\\n    value {\\n      s: &quot;Currently there is no way to take the second derivative of sparse_softmax_cross_entropy_with_logits due to the fused implementation\\\\\\'s interaction with tf.gradients()&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;train/gradients/loss/loss_grad/truediv&quot;\\n  input: &quot;train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims&quot;\\n  input: &quot;train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/PreventGradient&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/outputs/BiasAdd_grad/BiasAddGrad&quot;\\n  op: &quot;BiasAddGrad&quot;\\n  input: &quot;train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/outputs/BiasAdd_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/mul&quot;\\n  input: &quot;^train/gradients/dnn/outputs/BiasAdd_grad/BiasAddGrad&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/outputs/BiasAdd_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/mul&quot;\\n  input: &quot;^train/gradients/dnn/outputs/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/outputs/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dnn/outputs/BiasAdd_grad/BiasAddGrad&quot;\\n  input: &quot;^train/gradients/dnn/outputs/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dnn/outputs/BiasAdd_grad/BiasAddGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/outputs/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;train/gradients/dnn/outputs/BiasAdd_grad/tuple/control_dependency&quot;\\n  input: &quot;outputs/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/outputs/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;dnn/hidden2/Relu&quot;\\n  input: &quot;train/gradients/dnn/outputs/BiasAdd_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/outputs/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/dnn/outputs/MatMul_grad/MatMul&quot;\\n  input: &quot;^train/gradients/dnn/outputs/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/outputs/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dnn/outputs/MatMul_grad/MatMul&quot;\\n  input: &quot;^train/gradients/dnn/outputs/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dnn/outputs/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/outputs/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dnn/outputs/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^train/gradients/dnn/outputs/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dnn/outputs/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/Relu_grad/ReluGrad&quot;\\n  op: &quot;ReluGrad&quot;\\n  input: &quot;train/gradients/dnn/outputs/MatMul_grad/tuple/control_dependency&quot;\\n  input: &quot;dnn/hidden2/Relu&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/BiasAdd_grad/BiasAddGrad&quot;\\n  op: &quot;BiasAddGrad&quot;\\n  input: &quot;train/gradients/dnn/hidden2/Relu_grad/ReluGrad&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/BiasAdd_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/dnn/hidden2/Relu_grad/ReluGrad&quot;\\n  input: &quot;^train/gradients/dnn/hidden2/BiasAdd_grad/BiasAddGrad&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/BiasAdd_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dnn/hidden2/Relu_grad/ReluGrad&quot;\\n  input: &quot;^train/gradients/dnn/hidden2/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dnn/hidden2/Relu_grad/ReluGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dnn/hidden2/BiasAdd_grad/BiasAddGrad&quot;\\n  input: &quot;^train/gradients/dnn/hidden2/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dnn/hidden2/BiasAdd_grad/BiasAddGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;train/gradients/dnn/hidden2/BiasAdd_grad/tuple/control_dependency&quot;\\n  input: &quot;hidden2/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;dnn/hidden1/Relu&quot;\\n  input: &quot;train/gradients/dnn/hidden2/BiasAdd_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/dnn/hidden2/MatMul_grad/MatMul&quot;\\n  input: &quot;^train/gradients/dnn/hidden2/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dnn/hidden2/MatMul_grad/MatMul&quot;\\n  input: &quot;^train/gradients/dnn/hidden2/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dnn/hidden2/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dnn/hidden2/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^train/gradients/dnn/hidden2/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dnn/hidden2/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/Relu_grad/ReluGrad&quot;\\n  op: &quot;ReluGrad&quot;\\n  input: &quot;train/gradients/dnn/hidden2/MatMul_grad/tuple/control_dependency&quot;\\n  input: &quot;dnn/hidden1/Relu&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/BiasAdd_grad/BiasAddGrad&quot;\\n  op: &quot;BiasAddGrad&quot;\\n  input: &quot;train/gradients/dnn/hidden1/Relu_grad/ReluGrad&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/BiasAdd_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/dnn/hidden1/Relu_grad/ReluGrad&quot;\\n  input: &quot;^train/gradients/dnn/hidden1/BiasAdd_grad/BiasAddGrad&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/BiasAdd_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dnn/hidden1/Relu_grad/ReluGrad&quot;\\n  input: &quot;^train/gradients/dnn/hidden1/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dnn/hidden1/Relu_grad/ReluGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dnn/hidden1/BiasAdd_grad/BiasAddGrad&quot;\\n  input: &quot;^train/gradients/dnn/hidden1/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dnn/hidden1/BiasAdd_grad/BiasAddGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;train/gradients/dnn/hidden1/BiasAdd_grad/tuple/control_dependency&quot;\\n  input: &quot;hidden1/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;X&quot;\\n  input: &quot;train/gradients/dnn/hidden1/BiasAdd_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/dnn/hidden1/MatMul_grad/MatMul&quot;\\n  input: &quot;^train/gradients/dnn/hidden1/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dnn/hidden1/MatMul_grad/MatMul&quot;\\n  input: &quot;^train/gradients/dnn/hidden1/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dnn/hidden1/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dnn/hidden1/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^train/gradients/dnn/hidden1/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dnn/hidden1/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/GradientDescent/learning_rate&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.009999999776482582\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/GradientDescent/update_hidden1/kernel/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;hidden1/kernel&quot;\\n  input: &quot;train/GradientDescent/learning_rate&quot;\\n  input: &quot;train/gradients/dnn/hidden1/MatMul_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/GradientDescent/update_hidden1/bias/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;hidden1/bias&quot;\\n  input: &quot;train/GradientDescent/learning_rate&quot;\\n  input: &quot;train/gradients/dnn/hidden1/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/GradientDescent/update_hidden2/kernel/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;hidden2/kernel&quot;\\n  input: &quot;train/GradientDescent/learning_rate&quot;\\n  input: &quot;train/gradients/dnn/hidden2/MatMul_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/GradientDescent/update_hidden2/bias/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;hidden2/bias&quot;\\n  input: &quot;train/GradientDescent/learning_rate&quot;\\n  input: &quot;train/gradients/dnn/hidden2/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/GradientDescent/update_outputs/kernel/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;outputs/kernel&quot;\\n  input: &quot;train/GradientDescent/learning_rate&quot;\\n  input: &quot;train/gradients/dnn/outputs/MatMul_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/GradientDescent/update_outputs/bias/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;outputs/bias&quot;\\n  input: &quot;train/GradientDescent/learning_rate&quot;\\n  input: &quot;train/gradients/dnn/outputs/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/GradientDescent&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/GradientDescent/update_hidden1/kernel/ApplyGradientDescent&quot;\\n  input: &quot;^train/GradientDescent/update_hidden1/bias/ApplyGradientDescent&quot;\\n  input: &quot;^train/GradientDescent/update_hidden2/kernel/ApplyGradientDescent&quot;\\n  input: &quot;^train/GradientDescent/update_hidden2/bias/ApplyGradientDescent&quot;\\n  input: &quot;^train/GradientDescent/update_outputs/kernel/ApplyGradientDescent&quot;\\n  input: &quot;^train/GradientDescent/update_outputs/bias/ApplyGradientDescent&quot;\\n}\\nnode {\\n  name: &quot;eval/InTopK&quot;\\n  op: &quot;InTopK&quot;\\n  input: &quot;dnn/outputs/BiasAdd&quot;\\n  input: &quot;y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;k&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;eval/Cast&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;eval/InTopK&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;eval/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;eval/Mean&quot;\\n  op: &quot;Mean&quot;\\n  input: &quot;eval/Cast&quot;\\n  input: &quot;eval/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;init&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^hidden1/kernel/Assign&quot;\\n  input: &quot;^hidden1/bias/Assign&quot;\\n  input: &quot;^hidden2/kernel/Assign&quot;\\n  input: &quot;^hidden2/bias/Assign&quot;\\n  input: &quot;^outputs/kernel/Assign&quot;\\n  input: &quot;^outputs/bias/Assign&quot;\\n}\\nnode {\\n  name: &quot;save/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;model&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/SaveV2/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 6\\n          }\\n        }\\n        string_val: &quot;hidden1/bias&quot;\\n        string_val: &quot;hidden1/kernel&quot;\\n        string_val: &quot;hidden2/bias&quot;\\n        string_val: &quot;hidden2/kernel&quot;\\n        string_val: &quot;outputs/bias&quot;\\n        string_val: &quot;outputs/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/SaveV2/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 6\\n          }\\n        }\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/SaveV2&quot;\\n  op: &quot;SaveV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/SaveV2/tensor_names&quot;\\n  input: &quot;save/SaveV2/shape_and_slices&quot;\\n  input: &quot;hidden1/bias&quot;\\n  input: &quot;hidden1/kernel&quot;\\n  input: &quot;hidden2/bias&quot;\\n  input: &quot;hidden2/kernel&quot;\\n  input: &quot;outputs/bias&quot;\\n  input: &quot;outputs/kernel&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;^save/SaveV2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@save/Const&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;hidden1/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2/tensor_names&quot;\\n  input: &quot;save/RestoreV2/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden1/bias&quot;\\n  input: &quot;save/RestoreV2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_1/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_1/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_1&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_1/tensor_names&quot;\\n  input: &quot;save/RestoreV2_1/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_1&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden1/kernel&quot;\\n  input: &quot;save/RestoreV2_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_2/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;hidden2/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_2/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_2&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_2/tensor_names&quot;\\n  input: &quot;save/RestoreV2_2/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_2&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden2/bias&quot;\\n  input: &quot;save/RestoreV2_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_3/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_3/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_3&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_3/tensor_names&quot;\\n  input: &quot;save/RestoreV2_3/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_3&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden2/kernel&quot;\\n  input: &quot;save/RestoreV2_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_4/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;outputs/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_4/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_4&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_4/tensor_names&quot;\\n  input: &quot;save/RestoreV2_4/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_4&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;outputs/bias&quot;\\n  input: &quot;save/RestoreV2_4&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_5/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;outputs/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_5/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_5&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_5/tensor_names&quot;\\n  input: &quot;save/RestoreV2_5/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_5&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;outputs/kernel&quot;\\n  input: &quot;save/RestoreV2_5&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/restore_all&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^save/Assign&quot;\\n  input: &quot;^save/Assign_1&quot;\\n  input: &quot;^save/Assign_2&quot;\\n  input: &quot;^save/Assign_3&quot;\\n  input: &quot;^save/Assign_4&quot;\\n  input: &quot;^save/Assign_5&quot;\\n}\\nnode {\\n  name: &quot;loss_1/SparseSoftmaxCrossEntropyWithLogits/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_1/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits&quot;\\n  op: &quot;SparseSoftmaxCrossEntropyWithLogits&quot;\\n  input: &quot;dnn/outputs/BiasAdd&quot;\\n  input: &quot;y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tlabels&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_1/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_1/loss&quot;\\n  op: &quot;Mean&quot;\\n  input: &quot;loss_1/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits&quot;\\n  input: &quot;loss_1/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\n';\n",
       "          }\n",
       "        </script>\n",
       "        <link rel=&quot;import&quot; href=&quot;https://tensorboard.appspot.com/tf-graph-basic.build.html&quot; onload=load()>\n",
       "        <div style=&quot;height:600px&quot;>\n",
       "          <tf-graph-basic id=&quot;graph0.08185155632074148&quot;></tf-graph-basic>\n",
       "        </div>\n",
       "    \"></iframe>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_graph(tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tuning neural network hyperparameters\n",
    "\n",
    "- 신경 네트워크의 유연성 또한 주요 단점 중 하나입니다. 조정할 수 있는 많은 하이퍼 파라미터가 있습니다. \n",
    "\n",
    "- 상상할 수있는 네트워크 토폴로지 (뉴런 상호 연결 방식)를 사용할 수 있을 뿐만 아니라 간단한 MLP에서도 레이어 수, 레이어 당 뉴런 수, 각 레이어에서 사용할 활성화 함수의 유형, 가중치 초기화 로직 등을 제공합니다. 하이퍼 매개 변수의 조합이 작업에 가장 적합한 방법을 어떻게 알 수 있습니까?\n",
    "\n",
    "- 물론 이전 교차 장에서 했던 것처럼 교차 검증과 함께 그리드 검색을 사용하여 올바른 하이퍼 매개 변수를 찾을 수 있지만 대규모 데이터 세트에서 신경 네트워크를 학습하는 데는 많은 시간이 걸리기 때문에 합리적인 시간 내에 하이퍼 매개 변수 공간의 작은 부분을 탐색하십시오.\n",
    "\n",
    "- 검색 속도를 높이는 한 가지 방법은 매우 거친 그리드 검색으로 시작한 다음 점진적으로 가장 잘 작동하는 하이퍼 매개 변수 공간 부분을 확대하는 것입니다.\n",
    "\n",
    "- 각 하이퍼 매개 변수에 대해 합리적인 값이 무엇인지 생각하는 데 도움이되므로 검색 공간을 제한 할 수 있습니다. 숨겨진 레이어의 수부터 시작해 보겠습니다.\n",
    "\n",
    "\n",
    "### Number of hidden layers\n",
    "- 많은 문제들에 대해, 당신은 단지 하나의 숨겨진 레이어로 시작할 수 있으며, 합리적인 결과를 얻을 것입니다. 실제로 하나의 숨겨진 레이어가 있는 MLP가 충분한 뉴런을 제공한다면 가장 복잡한 기능조차도 모델링 할 수 있다는 사실이 실제로 나타났습니다. \n",
    "\n",
    "- 오랜 세월 동안 이러한 사실은 연구자들이 더 깊은 신경 네트워크를 조사 할 필요가 없다고 확신 시켰습니다. 그러나 깊은 네트워크는 얕은 네트워크보다 훨씬 더 높은 매개 변수 효율성을 간과했다. 얕은 네트워크보다 지수 적으로 적은 뉴런을 사용하여 복잡한 함수를 모델링 할 수 있으므로 훈련이 훨씬 빨라진다.\n",
    "\n",
    "- 이유를 이해하려면 드로잉 소프트웨어를 사용하여 포리스트를 그리도록 요청 받았지만 복사 / 붙여 넣기를 사용하는 것은 금지되어 있습니다. \n",
    "\n",
    "- 각 트리를 개별적으로 그려야 하고, 분기마다 분기하고 리프마다 리프를 그려야합니다. 하나의 잎을 그릴 수 있다면 그것을 복사하여 붙여 넣기를하고 그 지점을 복사 / 붙여 넣기하여 나무를 만들고 마지막으로이 나무를 복사하여 붙여 넣어 숲을 만들면 곧 마칠 수 있습니다. 실제 데이터는 종종 계층 적 방식으로 구조화되며 DNN은 자동으로이 사실을 이용합니다. 숨겨진 계층 모델을 하위 수준 구조 (예 : 다양한 모양 및 방향의 선분)로 모델링하고 숨겨진 계층은 이러한 저급 구조를 모델 중간 레벨 구조 (예 : 사각형, 원), 가장 높은 숨겨진 레이어와 출력 레이어는 이러한 중간 구조를 결합하여 상위 수준 구조 (예 : 면)를 모델링합니다.\n",
    "\n",
    "- 이 계층적 아키텍처는 DNN이보다 신속하게 좋은 솔루션으로 수렴 할 수 있을 뿐 아니라 새로운 데이터 세트로 일반화 할 수 있는 능력을 향상시킵니다.\n",
    "\n",
    "- 예를 들어 사진에서 얼굴을 인식하도록 모델을 이미 훈련했으며 새 신경망을 학습하여 헤어 스타일을 인식하려면 첫 번째 네트워크의 하위 레이어를 재사용하여 시작 교육을 시작할 수 있습니다. \n",
    "\n",
    "- 임의로 초기화 하는 대신 새로운 신경 네트워크의 처음 몇 개의 레이어의 가중치와 편차를 이용하여 첫 번째 네트워크의 하위 레이어의 가중치와 바이어스 값으로 초기화 할 수 있습니다. 이 방법으로 네트워크는 대부분의 사진에서 발생하는 모든 저수준 구조를 처음부터 배우지 않아도되며 더 높은 수준의 구조 (예 : 헤어 스타일) 만 학습하면 됩니다.\n",
    "\n",
    "- 요약하면, 많은 문제들에 대해, 하나 또는 두 개의 숨겨진 레이어로 시작할 수 있습니다. (즉, 수백 개의 뉴런을 가진 숨겨진 레이어 하나만 사용하여 MNIST 데이터 세트에서 97 % 이상의 정확도를 쉽게 얻을 수 있습니다. \n",
    "\n",
    "- 대략 동일한 양의 뉴런을 가진 2 개의 숨겨진 레이어를 사용하여 대략 98 %의 정확도를 제공합니다. 좀 더 복잡한 문제의 경우, 교육 세트를 과도하게 시작할 때까지 숨겨진 레이어의 수를 점차적으로 늘릴 수 있습니다. \n",
    "\n",
    "- 큰 이미지 분류 또는 음성 인식과 같은 매우 복잡한 작업에는 일반적으로 수십 개의 레이어가있는 네트워크가 필요하지만 (13 장에서 볼 수 있듯이 완전히 연결되지는 않음) 많은 양의 교육 데이터가 필요합니다. \n",
    "\n",
    "- 그러나 그러한 네트워크를 처음부터 교육 할 필요는 거의 없습니다. 유사한 작업을 수행하는 사전 교육 된 최첨단 네트워크의 일부를 재사용하는 것이 훨씬 더 일반적입니다. \n",
    "\n",
    "- 훈련은 훨씬 빨라지고 훨씬 적은 데이터가 필요합니다 (11 장에서 이에 대해 논의 할 것입니다)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of neurons per hidden layer\n",
    "\n",
    "- 숨겨진 레이어 당 뉴런의 수에 대한 합리적인 시작점은 대략 입력 레이어와 출력 레이어 사이의 뉴런 수를 보간하는 것입니다.\n",
    "- 예를 들어, MNIST 작업에는 784 개의 입력 뉴런과 10 개의 출력 뉴런이 있으므로 하나의 숨겨진 레이어 만 사용하기로 결정한 경우 400 개의 뉴런 (대략 784와 10의 평균)을 시작으로 사용할 수 있습니다. \n",
    "- 2 개의 숨겨진 레이어를 사용하면 첫 번째 레이어에 300 개의 뉴런과 두 번째 레이어에 100 개의 뉴런을 배치하는 것이 합리적인 선택입니다. \n",
    "\n",
    "- 레이어 수와 마찬가지로 네트워크가 지나치게 시작될 때까지 점차적으로 뉴런의 수를 늘릴 수 있습니다.\n",
    "- 불행히도, 당신이 볼 수 있듯이, 완벽한 양의 뉴런을 찾는 것은 여전히 다소 black art입니다.\n",
    "\n",
    "- 더 간단한 접근법은 실제로 필요한 것보다 더 많은 레이어와 뉴런을 가진 모델을 선택한 다음 조기 정지를 사용하여 오버 피팅을 방지합니다 (11 장에서 볼 수 있듯이 드롭 아웃과 같은 다른 정규화 기법). \n",
    "\n",
    "- 이것은 \"stretch pants\" 접근법이라고 불립니다. 크기와 완벽하게 맞는 바지를 찾는 데 시간을 낭비하는 대신 올바른 크기로 줄어들 수있는 큰 stretch pants를 사용하십시오.\n",
    "\n",
    "### Activation functions\n",
    "\n",
    "- 대부분의 경우 숨겨진 레이어 (또는 11 장에서 볼 수있는 변형 중 하나)에서 ReLU 활성화 함수를 사용할 수 있습니다.\n",
    "\n",
    "- 다른 활성화 함수보다 계산 속도가 훨씬 빠르며 그래디언트 디센트 (Gradient Descent)가 많이 걸리지 않습니다. (로지스틱 함수 또는 쌍곡선 탄젠트 함수가 1로 포화하는 것과는 대조적으로) \n",
    "\n",
    "- 큰 입력 값에 대해 포화 상태가 아니기 때문에 고원에 놓이게 됩니다.\n",
    "\n",
    "- 출력 레이어의 경우 softmax 활성화 기능은 일반적으로 분류 작업 (클래스가 상호 배타적 인 경우)에 적합한 선택입니다. 회귀 작업의 경우 정품 인증 기능을 전혀 사용하지 않아도됩니다.\n",
    "\n",
    "- 이것으로 인공 신경망에 대한 소개를 마칩니다. 다음 장에서 우리는 매우 깊은 그물을 훈련시키고, 여러 서버와 GPU에 걸쳐 훈련을 배포하는 기술을 논의한 다음, 다른 많은 대중적인 신경망 구조, Convolutional Neural Networks, Recurrent Neural Networks and Autoencoders를 탐구할 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using dense() instead of neuron_layer()\n",
    "\n",
    "- 이 책은 `tf.layers.dense()`(이 장을 쓸 때 없었던) 대신 `tensorflow.contrib.layers.fully_connected()`를 사용합니다. \n",
    "- contrib 모듈의 내용은 예고없이 변경되거나 삭제 될 수 있으므로 `tf.layers.dense()`를 사용하는 것이 더 바람직합니다. \n",
    "- `dense()`함수는 몇 가지 사소한 차이점을 제외하면 `fully_connected()` 함수와 거의 동일합니다 :\n",
    "- 여러 매개 변수의 이름이 바뀌 었습니다 :`scope`는`name`이되고,`activation_fn`은 `activation`이 됩니다. (마찬가지로`_fn` 접미사는`normalizer_fn` 같은 다른 매개 변수에서 제거됩니다),`weights_initializer`는 `kernel_initializer` 등이 됩니다.)\n",
    "- 디폴트`activation`은`tf.nn.relu`보다는`None`입니다.\n",
    "- 더 많은 차이점이 11 장에 제시되어있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_inputs = 28*28  # MNIST\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_outputs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int64, shape=(None), name=\"y\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, name=\"hidden1\",\n",
    "                              activation=tf.nn.relu)\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, name=\"hidden2\",\n",
    "                              activation=tf.nn.relu)\n",
    "    logits = tf.layers.dense(hidden2, n_outputs, name=\"outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train accuracy: 0.9 Test accuracy: 0.9053\n",
      "1 Train accuracy: 0.88 Test accuracy: 0.9206\n",
      "2 Train accuracy: 0.94 Test accuracy: 0.9301\n",
      "3 Train accuracy: 0.94 Test accuracy: 0.9397\n",
      "4 Train accuracy: 0.92 Test accuracy: 0.945\n",
      "5 Train accuracy: 0.94 Test accuracy: 0.9476\n",
      "6 Train accuracy: 0.92 Test accuracy: 0.9514\n",
      "7 Train accuracy: 0.98 Test accuracy: 0.9547\n",
      "8 Train accuracy: 0.96 Test accuracy: 0.9569\n",
      "9 Train accuracy: 0.94 Test accuracy: 0.9605\n",
      "10 Train accuracy: 0.92 Test accuracy: 0.962\n",
      "11 Train accuracy: 0.96 Test accuracy: 0.9631\n",
      "12 Train accuracy: 1.0 Test accuracy: 0.966\n",
      "13 Train accuracy: 0.94 Test accuracy: 0.9656\n",
      "14 Train accuracy: 1.0 Test accuracy: 0.967\n",
      "15 Train accuracy: 0.94 Test accuracy: 0.9682\n",
      "16 Train accuracy: 0.96 Test accuracy: 0.97\n",
      "17 Train accuracy: 0.98 Test accuracy: 0.9695\n",
      "18 Train accuracy: 1.0 Test accuracy: 0.97\n",
      "19 Train accuracy: 1.0 Test accuracy: 0.9708\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 20\n",
    "n_batches = 50\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(mnist.train.num_examples // batch_size):\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_train = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_test = accuracy.eval(feed_dict={X: mnist.test.images, y: mnist.test.labels})\n",
    "        print(epoch, \"Train accuracy:\", acc_train, \"Test accuracy:\", acc_test)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"\n",
       "        <script>\n",
       "          function load() {\n",
       "            document.getElementById(&quot;graph0.7224827313584268&quot;).pbtxt = 'node {\\n  name: &quot;X&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: -1\\n        }\\n        dim {\\n          size: 784\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;y&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        unknown_rank: true\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/kernel/Initializer/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\020\\\\003\\\\000\\\\000,\\\\001\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/kernel/Initializer/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -0.07439795136451721\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/kernel/Initializer/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.07439795136451721\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;hidden1/kernel/Initializer/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 42\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 5\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/kernel/Initializer/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;hidden1/kernel/Initializer/random_uniform/max&quot;\\n  input: &quot;hidden1/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/kernel/Initializer/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;hidden1/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  input: &quot;hidden1/kernel/Initializer/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/kernel/Initializer/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;hidden1/kernel/Initializer/random_uniform/mul&quot;\\n  input: &quot;hidden1/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/kernel&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 784\\n        }\\n        dim {\\n          size: 300\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/kernel/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden1/kernel&quot;\\n  input: &quot;hidden1/kernel/Initializer/random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/kernel/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;hidden1/kernel&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/bias/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 300\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/bias&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 300\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/bias/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden1/bias&quot;\\n  input: &quot;hidden1/bias/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/bias/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;hidden1/bias&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden1/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;X&quot;\\n  input: &quot;hidden1/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden1/BiasAdd&quot;\\n  op: &quot;BiasAdd&quot;\\n  input: &quot;dnn/hidden1/MatMul&quot;\\n  input: &quot;hidden1/bias/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden1/Relu&quot;\\n  op: &quot;Relu&quot;\\n  input: &quot;dnn/hidden1/BiasAdd&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/kernel/Initializer/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;,\\\\001\\\\000\\\\000d\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/kernel/Initializer/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -0.12247448414564133\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/kernel/Initializer/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.12247448414564133\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;hidden2/kernel/Initializer/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 42\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 22\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/kernel/Initializer/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;hidden2/kernel/Initializer/random_uniform/max&quot;\\n  input: &quot;hidden2/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/kernel/Initializer/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;hidden2/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  input: &quot;hidden2/kernel/Initializer/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/kernel/Initializer/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;hidden2/kernel/Initializer/random_uniform/mul&quot;\\n  input: &quot;hidden2/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/kernel&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 300\\n        }\\n        dim {\\n          size: 100\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/kernel/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden2/kernel&quot;\\n  input: &quot;hidden2/kernel/Initializer/random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/kernel/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;hidden2/kernel&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/bias/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 100\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/bias&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 100\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/bias/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden2/bias&quot;\\n  input: &quot;hidden2/bias/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/bias/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;hidden2/bias&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden2/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;dnn/hidden1/Relu&quot;\\n  input: &quot;hidden2/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden2/BiasAdd&quot;\\n  op: &quot;BiasAdd&quot;\\n  input: &quot;dnn/hidden2/MatMul&quot;\\n  input: &quot;hidden2/bias/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden2/Relu&quot;\\n  op: &quot;Relu&quot;\\n  input: &quot;dnn/hidden2/BiasAdd&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/kernel/Initializer/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;d\\\\000\\\\000\\\\000\\\\n\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/kernel/Initializer/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -0.23354968428611755\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/kernel/Initializer/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.23354968428611755\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;outputs/kernel/Initializer/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 42\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 39\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/kernel/Initializer/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;outputs/kernel/Initializer/random_uniform/max&quot;\\n  input: &quot;outputs/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/kernel/Initializer/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;outputs/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  input: &quot;outputs/kernel/Initializer/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/kernel/Initializer/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;outputs/kernel/Initializer/random_uniform/mul&quot;\\n  input: &quot;outputs/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/kernel&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 100\\n        }\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/kernel/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;outputs/kernel&quot;\\n  input: &quot;outputs/kernel/Initializer/random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/kernel/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;outputs/kernel&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/bias/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 10\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/bias&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/bias/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;outputs/bias&quot;\\n  input: &quot;outputs/bias/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/bias/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;outputs/bias&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/outputs/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;dnn/hidden2/Relu&quot;\\n  input: &quot;outputs/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/outputs/BiasAdd&quot;\\n  op: &quot;BiasAdd&quot;\\n  input: &quot;dnn/outputs/MatMul&quot;\\n  input: &quot;outputs/bias/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/SparseSoftmaxCrossEntropyWithLogits/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits&quot;\\n  op: &quot;SparseSoftmaxCrossEntropyWithLogits&quot;\\n  input: &quot;dnn/outputs/BiasAdd&quot;\\n  input: &quot;y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tlabels&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/loss&quot;\\n  op: &quot;Mean&quot;\\n  input: &quot;loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits&quot;\\n  input: &quot;loss/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Fill&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;train/gradients/Shape&quot;\\n  input: &quot;train/gradients/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Reshape/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/Fill&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Reshape/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Tile&quot;\\n  op: &quot;Tile&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Reshape&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tmultiples&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Shape_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Prod&quot;\\n  op: &quot;Prod&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Shape_1&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Prod_1&quot;\\n  op: &quot;Prod&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Shape_2&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Const_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Maximum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Maximum&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Prod_1&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Maximum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/floordiv&quot;\\n  op: &quot;FloorDiv&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Prod&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Maximum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Cast&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;train/gradients/loss/loss_grad/floordiv&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/truediv&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Tile&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Cast&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/zeros_like&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/PreventGradient&quot;\\n  op: &quot;PreventGradient&quot;\\n  input: &quot;loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;message&quot;\\n    value {\\n      s: &quot;Currently there is no way to take the second derivative of sparse_softmax_cross_entropy_with_logits due to the fused implementation\\\\\\'s interaction with tf.gradients()&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;train/gradients/loss/loss_grad/truediv&quot;\\n  input: &quot;train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims&quot;\\n  input: &quot;train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/PreventGradient&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/outputs/BiasAdd_grad/BiasAddGrad&quot;\\n  op: &quot;BiasAddGrad&quot;\\n  input: &quot;train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/outputs/BiasAdd_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/mul&quot;\\n  input: &quot;^train/gradients/dnn/outputs/BiasAdd_grad/BiasAddGrad&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/outputs/BiasAdd_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/mul&quot;\\n  input: &quot;^train/gradients/dnn/outputs/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/outputs/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dnn/outputs/BiasAdd_grad/BiasAddGrad&quot;\\n  input: &quot;^train/gradients/dnn/outputs/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dnn/outputs/BiasAdd_grad/BiasAddGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/outputs/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;train/gradients/dnn/outputs/BiasAdd_grad/tuple/control_dependency&quot;\\n  input: &quot;outputs/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/outputs/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;dnn/hidden2/Relu&quot;\\n  input: &quot;train/gradients/dnn/outputs/BiasAdd_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/outputs/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/dnn/outputs/MatMul_grad/MatMul&quot;\\n  input: &quot;^train/gradients/dnn/outputs/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/outputs/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dnn/outputs/MatMul_grad/MatMul&quot;\\n  input: &quot;^train/gradients/dnn/outputs/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dnn/outputs/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/outputs/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dnn/outputs/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^train/gradients/dnn/outputs/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dnn/outputs/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/Relu_grad/ReluGrad&quot;\\n  op: &quot;ReluGrad&quot;\\n  input: &quot;train/gradients/dnn/outputs/MatMul_grad/tuple/control_dependency&quot;\\n  input: &quot;dnn/hidden2/Relu&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/BiasAdd_grad/BiasAddGrad&quot;\\n  op: &quot;BiasAddGrad&quot;\\n  input: &quot;train/gradients/dnn/hidden2/Relu_grad/ReluGrad&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/BiasAdd_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/dnn/hidden2/Relu_grad/ReluGrad&quot;\\n  input: &quot;^train/gradients/dnn/hidden2/BiasAdd_grad/BiasAddGrad&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/BiasAdd_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dnn/hidden2/Relu_grad/ReluGrad&quot;\\n  input: &quot;^train/gradients/dnn/hidden2/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dnn/hidden2/Relu_grad/ReluGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dnn/hidden2/BiasAdd_grad/BiasAddGrad&quot;\\n  input: &quot;^train/gradients/dnn/hidden2/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dnn/hidden2/BiasAdd_grad/BiasAddGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;train/gradients/dnn/hidden2/BiasAdd_grad/tuple/control_dependency&quot;\\n  input: &quot;hidden2/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;dnn/hidden1/Relu&quot;\\n  input: &quot;train/gradients/dnn/hidden2/BiasAdd_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/dnn/hidden2/MatMul_grad/MatMul&quot;\\n  input: &quot;^train/gradients/dnn/hidden2/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dnn/hidden2/MatMul_grad/MatMul&quot;\\n  input: &quot;^train/gradients/dnn/hidden2/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dnn/hidden2/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dnn/hidden2/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^train/gradients/dnn/hidden2/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dnn/hidden2/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/Relu_grad/ReluGrad&quot;\\n  op: &quot;ReluGrad&quot;\\n  input: &quot;train/gradients/dnn/hidden2/MatMul_grad/tuple/control_dependency&quot;\\n  input: &quot;dnn/hidden1/Relu&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/BiasAdd_grad/BiasAddGrad&quot;\\n  op: &quot;BiasAddGrad&quot;\\n  input: &quot;train/gradients/dnn/hidden1/Relu_grad/ReluGrad&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/BiasAdd_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/dnn/hidden1/Relu_grad/ReluGrad&quot;\\n  input: &quot;^train/gradients/dnn/hidden1/BiasAdd_grad/BiasAddGrad&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/BiasAdd_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dnn/hidden1/Relu_grad/ReluGrad&quot;\\n  input: &quot;^train/gradients/dnn/hidden1/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dnn/hidden1/Relu_grad/ReluGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dnn/hidden1/BiasAdd_grad/BiasAddGrad&quot;\\n  input: &quot;^train/gradients/dnn/hidden1/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dnn/hidden1/BiasAdd_grad/BiasAddGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;train/gradients/dnn/hidden1/BiasAdd_grad/tuple/control_dependency&quot;\\n  input: &quot;hidden1/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;X&quot;\\n  input: &quot;train/gradients/dnn/hidden1/BiasAdd_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/dnn/hidden1/MatMul_grad/MatMul&quot;\\n  input: &quot;^train/gradients/dnn/hidden1/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dnn/hidden1/MatMul_grad/MatMul&quot;\\n  input: &quot;^train/gradients/dnn/hidden1/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dnn/hidden1/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dnn/hidden1/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^train/gradients/dnn/hidden1/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dnn/hidden1/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/GradientDescent/learning_rate&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.009999999776482582\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/GradientDescent/update_hidden1/kernel/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;hidden1/kernel&quot;\\n  input: &quot;train/GradientDescent/learning_rate&quot;\\n  input: &quot;train/gradients/dnn/hidden1/MatMul_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/GradientDescent/update_hidden1/bias/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;hidden1/bias&quot;\\n  input: &quot;train/GradientDescent/learning_rate&quot;\\n  input: &quot;train/gradients/dnn/hidden1/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/GradientDescent/update_hidden2/kernel/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;hidden2/kernel&quot;\\n  input: &quot;train/GradientDescent/learning_rate&quot;\\n  input: &quot;train/gradients/dnn/hidden2/MatMul_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/GradientDescent/update_hidden2/bias/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;hidden2/bias&quot;\\n  input: &quot;train/GradientDescent/learning_rate&quot;\\n  input: &quot;train/gradients/dnn/hidden2/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/GradientDescent/update_outputs/kernel/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;outputs/kernel&quot;\\n  input: &quot;train/GradientDescent/learning_rate&quot;\\n  input: &quot;train/gradients/dnn/outputs/MatMul_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/GradientDescent/update_outputs/bias/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;outputs/bias&quot;\\n  input: &quot;train/GradientDescent/learning_rate&quot;\\n  input: &quot;train/gradients/dnn/outputs/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/GradientDescent&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/GradientDescent/update_hidden1/kernel/ApplyGradientDescent&quot;\\n  input: &quot;^train/GradientDescent/update_hidden1/bias/ApplyGradientDescent&quot;\\n  input: &quot;^train/GradientDescent/update_hidden2/kernel/ApplyGradientDescent&quot;\\n  input: &quot;^train/GradientDescent/update_hidden2/bias/ApplyGradientDescent&quot;\\n  input: &quot;^train/GradientDescent/update_outputs/kernel/ApplyGradientDescent&quot;\\n  input: &quot;^train/GradientDescent/update_outputs/bias/ApplyGradientDescent&quot;\\n}\\nnode {\\n  name: &quot;eval/InTopK&quot;\\n  op: &quot;InTopK&quot;\\n  input: &quot;dnn/outputs/BiasAdd&quot;\\n  input: &quot;y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;k&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;eval/Cast&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;eval/InTopK&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;eval/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;eval/Mean&quot;\\n  op: &quot;Mean&quot;\\n  input: &quot;eval/Cast&quot;\\n  input: &quot;eval/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;init&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^hidden1/kernel/Assign&quot;\\n  input: &quot;^hidden1/bias/Assign&quot;\\n  input: &quot;^hidden2/kernel/Assign&quot;\\n  input: &quot;^hidden2/bias/Assign&quot;\\n  input: &quot;^outputs/kernel/Assign&quot;\\n  input: &quot;^outputs/bias/Assign&quot;\\n}\\nnode {\\n  name: &quot;save/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;model&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/SaveV2/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 6\\n          }\\n        }\\n        string_val: &quot;hidden1/bias&quot;\\n        string_val: &quot;hidden1/kernel&quot;\\n        string_val: &quot;hidden2/bias&quot;\\n        string_val: &quot;hidden2/kernel&quot;\\n        string_val: &quot;outputs/bias&quot;\\n        string_val: &quot;outputs/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/SaveV2/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 6\\n          }\\n        }\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/SaveV2&quot;\\n  op: &quot;SaveV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/SaveV2/tensor_names&quot;\\n  input: &quot;save/SaveV2/shape_and_slices&quot;\\n  input: &quot;hidden1/bias&quot;\\n  input: &quot;hidden1/kernel&quot;\\n  input: &quot;hidden2/bias&quot;\\n  input: &quot;hidden2/kernel&quot;\\n  input: &quot;outputs/bias&quot;\\n  input: &quot;outputs/kernel&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;^save/SaveV2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@save/Const&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;hidden1/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2/tensor_names&quot;\\n  input: &quot;save/RestoreV2/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden1/bias&quot;\\n  input: &quot;save/RestoreV2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_1/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_1/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_1&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_1/tensor_names&quot;\\n  input: &quot;save/RestoreV2_1/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_1&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden1/kernel&quot;\\n  input: &quot;save/RestoreV2_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_2/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;hidden2/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_2/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_2&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_2/tensor_names&quot;\\n  input: &quot;save/RestoreV2_2/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_2&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden2/bias&quot;\\n  input: &quot;save/RestoreV2_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_3/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_3/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_3&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_3/tensor_names&quot;\\n  input: &quot;save/RestoreV2_3/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_3&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden2/kernel&quot;\\n  input: &quot;save/RestoreV2_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_4/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;outputs/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_4/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_4&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_4/tensor_names&quot;\\n  input: &quot;save/RestoreV2_4/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_4&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;outputs/bias&quot;\\n  input: &quot;save/RestoreV2_4&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_5/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;outputs/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_5/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_5&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_5/tensor_names&quot;\\n  input: &quot;save/RestoreV2_5/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_5&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;outputs/kernel&quot;\\n  input: &quot;save/RestoreV2_5&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/restore_all&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^save/Assign&quot;\\n  input: &quot;^save/Assign_1&quot;\\n  input: &quot;^save/Assign_2&quot;\\n  input: &quot;^save/Assign_3&quot;\\n  input: &quot;^save/Assign_4&quot;\\n  input: &quot;^save/Assign_5&quot;\\n}\\n';\n",
       "          }\n",
       "        </script>\n",
       "        <link rel=&quot;import&quot; href=&quot;https://tensorboard.appspot.com/tf-graph-basic.build.html&quot; onload=load()>\n",
       "        <div style=&quot;height:600px&quot;>\n",
       "          <tf-graph-basic id=&quot;graph0.7224827313584268&quot;></tf-graph-basic>\n",
       "        </div>\n",
       "    \"></iframe>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_graph(tf.get_default_graph())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
